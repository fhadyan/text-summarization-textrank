 the wise Cliff .  Stolcke and Omohundro start with a first order HMM where every state represents a single occurrence of a word in a corpus, and the goal is to maximize the a posteriori probability of the model..  The probability of cliff being a common noun is the product of the respective contextual and lexical probabilities , regardless of other information provided by the actual words (a sheer cliff vs..  Can we use a similarity measure of probability distributions to identify optimal clusters? How far can we reduce the tagset without losing accuracy? . 