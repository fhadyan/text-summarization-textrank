 The algorithm runs essentially in time and space linear in the size of the training data, so larger domains are within our reach..  The goal of grammar induction is taken to be finding the grammar with the largest a posteriori probability given the training data, that is, finding the grammar G' where and where we denote the training data as O, for observations..  Our move set includes the following moves: Move 1: Create a rule of the form Move 2: Create a rule of the form For any context-free grammar, it is possible to express a weakly equivalent grammar using only rules of these forms..  We repeat this process, parsing the next sentence using the best grammar found on the previous sentences and then searching for the best grammar taking into account this new sentence, until the entire training corpus is covered..  In other words, instead of using the naive rule to attach symbols together in parsing data, we now use the Xi rules and depend on the Inside-Outside algorithm to train these randomly initialized rules intelligently.. 