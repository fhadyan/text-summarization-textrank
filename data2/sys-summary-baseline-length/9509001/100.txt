 Statistical approaches to natural language processing are becoming increasingly popular, being applied to a wide variety of tasks.  For example, Weischedel et al.  (1993) explores part-of-speech tagging, parsing and acquisition of lexical frames.  Nonetheless, all these tasks share some important characteristics, not the least of which is the requirement for a sizable corpus of training data.  In this paper, I present the first steps towards the development of such a theory.  Statistical NLP systems are designed to make choices; hopefully in an informed manner. 