 In applications such as speech recognition, handwriting recognition, and spelling correction, performance is limited by the quality of the language model utilized , , , .  However, static language modeling performance has remained basically unchanged since the advent of n-gram language models forty years ago .  Yet, n-gram language models can only capture dependencies within an n-word window, where currently the largest practical n for natural language is three, and many dependencies in natural language occur beyond a three-word window.  An appealing alternative is grammar-based language models. 