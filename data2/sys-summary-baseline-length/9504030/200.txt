 Parsing a natural language sentence can be viewed as making a sequence of disambiguation decisions: determining the part-of-speech of the words, choosing between possible constituent structures, and selecting labels for the constituents.  Traditionally, disambiguation problems in parsing have been addressed by enumerating possibilities and explicitly declaring knowledge which might aid the disambiguation process.  However, these approaches have proved too brittle for most interesting natural language problems.  This work addresses the problem of automatically discovering the disambiguation criteria for all of the decisions made during the parsing process, given the set of possible features which can act as disambiguators.  The candidate disambiguators are the words in the sentence, relationships among the words, and relationships among constituents already constructed in the parsing process.  Since most natural language rules are not absolute, the disambiguation criteria discovered in this work are never applied deterministically.  Instead, all decisions are pursued non-deterministically according to the probability of each choice.  These probabilities are estimated using statistical decision tree models.  This will be the subject of future experiments.  For instance, consider the part-of-speech tagging problem. 