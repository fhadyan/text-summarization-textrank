 Many, diverse tagged and parsed corpora have been developed.  Amongst the applications of annotated corpora are as training sets for the extraction of models used in speech and handwriting recognition.  Such training sets need to be as large as possible and there is anecdotal evidence that even the largest on its own is too small for a general statistical model of higher-level syntactic structure.  As annotating corpora using hand-crafted markup or some semi-automated process followed by correction by linguistic experts is slow and expensive , it would be preferable if some other method of building a large annotated corpus could be found.  Existing corpora were not designed to a specific framework of annotations so corpora can not easily be collated into a single large training set.  The tagsets of two languages usually differ in the features they cover. 