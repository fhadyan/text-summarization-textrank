 Data sparseness is an inherent problem in statistical methods for natural language processing.  Such methods use statistics on the relative frequencies of configurations of elements in a training corpus to evaluate alternative analyses or interpretations of new samples of text or speech.  The most likely analysis will be taken to be the one that contains the most frequent configurations.  The problem of data sparseness arises when analyses contain configurations that never occurred in the training corpus.  Then it is not possible to estimate probabilities from observed frequencies, and some other estimation scheme has to be used.  We focus here on a particular kind of configuration, word cooccurrence.  Examples of such cooccurrences include relationships between head words in syntactic constructions (verb-object or adjective-noun, for example) and word sequences (n-grams   In commonly used models, the probability estimate for a previously unseen cooccurrence is a function of the probability estimates for the words in the cooccurrence.  Class-based and similarity-based models provide an alternative to the independence assumption.  suggest a class-based n-gram model in which words with similar cooccurrence distributions are clustered in word classes. 