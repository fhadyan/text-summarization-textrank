 Data sparseness is an inherent problem in statistical methods for natural language processing.  Such methods use statistics on the relative frequencies of configurations of elements in a training corpus to evaluate alternative analyses or interpretations of new samples of text or speech.  The most likely analysis will be taken to be the one that contains the most frequent configurations.  The problem of data sparseness arises when analyses contain configurations that never occurred in the training corpus.  Then it is not possible to estimate probabilities from observed frequencies, and some other estimation scheme has to be used.  We focus here on a particular kind of configuration, word cooccurrence.  Examples of such cooccurrences include relationships between head words in syntactic constructions (verb-object or adjective-noun, for example) and word sequences (n-grams   Their similarity-based model avoids clustering altogether. 