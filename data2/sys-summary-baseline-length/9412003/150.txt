 It is well known that statistical language models often suffer from a lack of training data.  This is true for standard tasks and even more so when one tries to build a language model for a new domain, because a large corpus of texts from that domain is usually not available.  One frequently used approach to alleviate this problem is to construct a clustered language model.  Because it has fewer parameters, it needs less training data.  The main advantage of a clustered model are its robustness, even in the face of little or sparse training data, and its compactness.  Particularly when a language model is used during the acoustic search in a speech recogniser, having a more compact, e.g.  less complex model, can be of considerable importance.  Its main idea is as follows. 