 Statistical part-of-speech disambiguation can be efficiently done with n-gram models , .  These models are equivalent to Hidden Markov Models (HMMs) of order n-1.  The states represent parts of speech (categories, tags there is exactly one state for each category, and each state outputs words of a particular category.  The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus.  Generally, the categories for part-of-speech tagging are linguistically motivated and do not reflect the probability distributions or co-occurrence probabilities of words belonging to that category.  It is an implicit assumption for statistical part-of-speech tagging that words belonging to the same category have similar probability distributions.  But this assumption does not hold in many of the cases.  the wise Cliff   There are two contradicting requirements.  Output the resulting tagset. 