 Statistical part-of-speech disambiguation can be efficiently done with n-gram models , .  These models are equivalent to Hidden Markov Models (HMMs) of order n-1.  The states represent parts of speech (categories, tags there is exactly one state for each category, and each state outputs words of a particular category.  The transition and output probabilities of the HMM are derived from smoothed frequency counts in a text corpus.  It is an implicit assumption for statistical part-of-speech tagging that words belonging to the same category have similar probability distributions.  the wise Cliff  