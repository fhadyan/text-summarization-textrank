 This is important evidence for the main hypothesis of this paper: that enhancing a language model with clustering, which once the software is in place can be done largely automatically, can give us important clues about whether it is worth expending research, programming, data-collection and machine resources on hand-coded improvements to the way in which the language model in question models context, or whether those resources are best devoted to different, additional kinds of language model.  It also differs from Iyer et al's work by clustering at the utterance rather than the paragraph level, and by using a training corpus of thousands, rather than millions, of sentences; in many speech applications, available training data is likely to be quite limited, and may not always be chunked into paragraphs.  (See e.g. 