 Methods for automatically classifying words according to their contexts of use have both scientific and practical interest..  The splitting procedure can then be repeated to achieve the desired number of clusters or model cross-entropy..  All our experiments involve the asymmetric model described in the previous section..  The second split then further refines the weaponry sense into a projectile sense (cluster 3) and a gun sense (cluster 4 .  Unsurprisingly, the training set relative entropy decreases monotonically..  Instead, the only information about the objects is the statistics of their joint appearance..  These statistics can thus be seem as a weak form of object labelling analogous to supervision..  For the maximum likelihood argument, we start by estimating the likelihood of the sequence S of N independent observations of pairs (ni , vi .  At this point we need to specify the clustering model in more detail..  While variations of p(n|c) and p(v|c) in equation ( are not independent, we can treat them separately..  The free energy determines both the distortion and the membership entropy through with temperature .. 