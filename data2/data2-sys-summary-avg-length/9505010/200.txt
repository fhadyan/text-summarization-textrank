 These models are equivalent to Hidden Markov Models (HMMs) of order n-1..  There are two contradicting requirements..  Let be the set of words, the set of clusters (i.e..  So, the original tag can be restored any time and no information from the original tagset is lost..  The categories are combined to {JJR,JJT .  When processing a text, the word easier is tagged as {JJR,JJT .  We chose (3) for our first experiments, since it was the easiest one to implement..  All parts are mutually disjunct..  First, part A and B were used for training, and part C for testing..  Then, part A and C were used for training, and part B for testing..  Clustering was applied in the next steps..  The two previous words are a determiner (AT) and an adjective (JJ .  The improvement in the tagging result is too small to be significant..  Additionally, tagging accuracy slightly increased, but the improvement was not significant..  Further investigation will focus on criteria for cluster selection.. 