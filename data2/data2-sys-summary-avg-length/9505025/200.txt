 To quantify algorithm performance, we use the information retrieval metrics shown in Fig..  Type b errors (cf..  Other changes pertained to sentence fragments, unexpected clausal arguments, and embedded speech..  So does an implicit argument, as in Fig..  C type errors (cf..  ) are specified..  This decision tree was learned under the following conditions: all of the features shown in Fig..  While this method does not make sense for humans, computers can truly ignore previous iterations..  section which itself has practical import..  We have been engaged in a study addressing this gap..  Performance of individual speakers varies widely as shown by the high standard deviations in our tables..  To quantify their findings, these studies use notions of agreement and/or reliability ..  The bracketed numbers will be explained below..  FICs are tensed clauses that are neither verb arguments nor restrictive relatives..  illustrates how the first boundary site in Fig..  would be coded using the features in Fig..  The prosodic and cue phrase features were motivated by previous results in the literature.. 