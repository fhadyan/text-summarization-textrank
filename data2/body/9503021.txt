  Although a universal feature theory does not exist, there is a general understanding of its objects.
 The objects of feature theories are abstract linguistic objects, e.g., an object ``sentence,'' an object ``masculine third person singular,'' an object ``verb,'' an object ``noun phrase.'' These abstract objects have properties like ``tense,'' ``number,'' ``predicate,'' ``subject.'' The values of these properties are either atomic, like ``present'' and ``singular,'' or abstract objects, like ``verb'' and ``noun-phrase.'' The abstract objects are fully described by their properties and their values.
 Multiple descriptions for the properties and values of the abstract linguistic objects are presented in the literature.
 Examples are:   1.
 Feature graphs, which are labeled rooted directed acyclic graphs G=(V,A), where F is a collection of labels, a sink in the graph represents an atomic value and the labeling function is an injective function   .
 2.
 Attribute-value matrices, which are matrices in which the entries consist of an attribute and a value or a reentrance symbol.
 The values are either atomic or attribute-value matrices.
   From a computational point of view, all descriptions that are used in practical problems are equivalent.
 Though there exist some theories with a considerably higher expressive power .
 For this paper we adopt the feature graph description, which we will define somewhat more formal in the next section.
 Attribute Value Languages(AVL) consist of sets of logical formulas that describe classes of feature graphs, by expressing constraints on the type of paths that can exist within the graphs.
 To wit: In a sentence like ``a man walks'' the edges labeled with ``person'' that leave the nodes labeled ``a man'' and ``walks'' should both end in a node labeled ``singular.'' Such a constraint is called a ``path equation'' in the attribute-value language.
   A rewrite grammar can be enriched with an AVL to construct an Attribute Value Grammar(AVG), which consists of pairs of rewrite-rules and logical formulas.
 The rewrite rule is applicable to a production (nonterminal) only if the logical formula that expresses the relation between left- and right-hand side of the rule evaluates to true.
 The recognition problem for attribute-value grammars can be stated as: Given a grammar G and a string w does there exist a derivation in G, that respects the constraints given by its AVL, and that ends in w.
 As the intermediate productions correspond to feature graphs this question can also be formulated as a question about the existence of a consistent sequence of feature graphs that results in a feature graph describing w.
 For the rewrite grammar, any formalism in the Chomsky hierarchy (from regular to type 0) can be chosen.
 From a computational point of view it is of course most desirable to restrict oneself to a formalism that on the one hand gives enough expressibility to describe a large fragment of the (natural) language, and on the other hand is restrictive enough to preserve feasibility.
 For a discussion on the linguistic significance of such restrictions, see .
   Johnson proved that attribute-value grammars that are as restrictive as being equipped with a rewrite grammar that is regular can already give rise to an undecidable recognition problem.
 Obviously, to be of any practical use, the rewrite grammar or the attribute-value language must be more restrictive.
 Johnson proposed to add the off-line parsability constraint, which is respected if the rewrite grammar has no chain- or   -rules.
 Then, the number of applications in a production is linear and the size of the structure corresponding to the partial productions is polynomial.
 Hence as by a modification of Smolka's algorithm consistency of intermediate steps can be checked in quadratic time, the complexity of the recognition problem can at most be (nondeterministic) polynomial time.
 This observation was made in , which also has an   -hardness proof of the recognition problem.
   We further investigate the properties of these restricted AVGs (R-AVGs).
 In the next section, we give some more formal definitions and notations.
 In Section we show that the class of languages generated by an R-AVG (R-AVGL) includes the class of context free languages (CFL).
 It follows that any easily parsable class of languages (like CFL) is a proper subset of R-AVGL, unless   .
 Likewise, R-AVGL is a proper subset of the class of context sensitive languages, unless   .
 In Section we propose a further refinement on the off-line parsability constraint, which allows R-AVGs that respect this constraint to capture precisely complexity classes like   or   .
 That is, for any language L that has an   -parser, there exists an R-AVG, say G, such that L=L(G).
 Though our refinement, the honest parsability constraint is probably not a property that can be decided for arbitrary R-AVGs, we show that R-AVGs can be equipped with restricting mechanisms that enforce this property.
 The techniques that prove Theorem and Theorem result from Johnson's work.
 Therefore, the proofs of these theorems are deferred to the appendices.
   The definitions in this section are in the spirit of , Section 3.2] and , Sections 3-4].
 Consider three sets of pairwise disjoint symbols.
 A, the finite set of constants, denoted ( ) V, the countable set of variables, denoted ( ) L, the finite set of attributes, also called features, denoted ( )   Definition thedefctr: An f-edge from x to s is a triple (x,f,s) such that x is a variable, f is an attribute, and s is a constant or a variable.
 A path, p, is a, possibly empty, sequence of f-edges   in which the xi are variables and s is either a variable or a constant.
 Often a path is denoted by the sequence of its edges' attributes, in reversed order, e.g.,   .
 Let p be a path, ps denotes the path that starts from s, where s is a constant only if p is the empty path.
 If the path is nonempty,   , then s is a variable.
 For paths ps and qt we write   iff p and q start in sand t respectively and end in the same variable or constant.
 The expression   is called a path equation.
 A feature graph is either a pair   , or a pair (x,E) where x is the root and E a finite set of f-edges such that: 1.
 if (y,f,s) and (y,f,t) are in E, then s=t; 2.
 if (y,f,s) is in E, then there is a path from x to y in E.
   Definition thedefctr: An attribute-value language   consists of sets of logical formulas that describe feature graphs, by expressing constraints on the type of paths that can exist within the graphs.
 The terms of an attribute-value language are the constants and the variables .
 The formulas of an attribute-value language are path equations and Boolean combinations of path equations.
 Thus all formulas are either , where ps and qt are paths, or , , or , where and are formulas.
   Assume a finite set   (of lexical forms) and a finite set   (of categories).
   will play the role of the set of terminals and   will play the role of the set of nonterminals in the productions.
   Definition thedefctr: A constituent structure tree (CST) is a labeled tree in which the internal nodes are labeled with elements of Cat and the leaves are labeled with elements of Lex.
   Definition thedefctr: Let T be a constituent structure tree and F be a set of formulas in an attribute-value language   .
 An annotated constituent structure tree is a triple   , where h is a function that maps internal nodes in T onto variables in F.
   Definition thedefctr: A lexicon is a finite subset of   A set of syntactic rules is a finite subset of   .
 An attribute-value grammar is a triple   &gt;, where lexicon is a lexicon, rules is a set of syntactic rules and start is an element of   .
   Definition thedefctr: 1.
 , p .150] A class   of sets is recursively presentable iff there is an effective enumeration   of deterministic Turing machines which halt on all their inputs, and such that   2.
 We say that a class of grammars   is recursively presentable iff the class of sets   is recursively presentable.
   The only formulas that are allowed in the attribute-value language of restricted attribute-value grammars (R-AVGs) are path-equations and conjunctions of path-equations (i.e.
 disjunctions and negations are out).
 We will denote the attribute-value language of an R-AVG by   to make the distinction clear.
 The CST of an R-AVG is produced by a chain- and   -rule free regular grammar.
 The CST of an R-AVG can be either a left-branching or a right-branching tree, since the grammar contains at most one nonterminal in each rule.
 Definition thedefctr: The set of syntactic rules of a restricted attribute-value grammar is a subset of   &gt;.
 A restricted attribute-value grammar is a pair   &gt;, where rules is a set of syntactic rules and start is an element of   .
   Definition thedefctr: An R-AVG   &gt; generates an annotated constituent structure tree   iff 1.
 the root node of T is start, and 2.
 every internal node of T is licensed by a syntactic rule, and 3.
 the set F is consistent, i.e., describes a feature graph.
 Let   stand for the formula   in which all variable y is substituted for variable x.
 An internal node v of an annotated constituent structure tree is licensed by a syntactic rule   iff 1.
 the node v is labeled with category c0, h(v) = n0, and 2.
 all daughters of v are leaves, which are labeled with   , and 3.
   is in the set F.
 An internal node v of an annotated constituent structure tree is licensed by a syntactic rule   iff 1.
 the node v is labeled with category c0, h(v) = n0, and 2.
 one of v's daughters is an internal node, v1, which is labeled with category c1, and h(v1) = n1, and 3.
 the daughters of v that are leaves are labeled with   , and 4.
   is in the set F.
   In , it is shown that the recognition problem for R-AVGs is   -complete.
 This seems to indicate that although the mechanism for generating CSTs in R-AVGs is extremely simple, the generative capacity of R-AVGs is different from the generative capacity of e.g., context free languages (CFLs), which have a polynomial time parsing algorithm .
 Yet, a priori, there may exist CFLs that do not have an R-AVG.
   Let L be a context free language.
 There exists an R-AVG G such that L=L(G).
   Proof.\nIf L is a context free language, then there exists a context free grammar G' in Greibach normal form such that L=L(G').
 From this grammar G', we can construct a pushdown store M that accepts exactly the words in L(G')=L.
 Such a pushdown store M is actually a finite state automaton M' with a stack S.
 The finite state automaton M' may be simulated by a chain- and   -rule free regular grammar.
 Furthermore, we can construct an attribute-value language   that simulates the stack S.
 Thus it should be clear that there exists an R-AVG G that produces word w iff   .
 Details of this construction are deferred to Appendix .
   According to Theorem , it is unlikely that the languages generated by R-AVGs can be limited to those languages with a polynomial time recognition algorithm.
 Trautwein showed that all R-AVGs have nondeterministic polynomial time algorithms.
 Is it perhaps the case that any language that has a nondeterministic polynomial time recognition algorithm can be generated by an R-AVG.
 Does there exist a tight relation between time bounded machines and R-AVGs as e.g., between LBAs and CSLs? The answer is that the off-line parsability constraint that forces the R-AVG to have no chain- or   -rules is just too restrictive to allow such a connection.
 The following trick to alleviate this problem has been observed earlier in complexity theory.
 The off-line parsability constraint(OLP) relates the amount of ``work'' done by the grammar to produce a string linearly to the number of terminal symbols produced.
 It is therefore a sort of honesty constraint that is also demanded of functions that are used in e.g., cryptography.
 There the deal is, for each polynomial amount of work done to compute the function at least one bit of output must be produced.
 In such a way, for polynomial time computable functions one can guarantee that the inverse of the function is computable in nondeterministic polynomial time.
   As a more liberal constraint on R-AVGs we propose an analogous variation on the OLP Definition thedefctr: A grammar G satisfies the Honest Parsability Constraint(HPC) iff there exists a polynomial p s.t.
 for each win L(G) there exists a derivation with at most   steps.
   From Smolka's algorithm and Trautwein's observation it trivially follows that any attribute-value grammar that satisfies the HPC (HP-AVG) has an   recognition algorithm.
 The problem with the HPC is of course that it is not a syntactic property of grammars.
 The question whether a given AVG satisfies the HPC (or the OLP for that matter) may well be undecidable.
 Nonetheless, we can produce a set of rules that, when added to an attribute-value grammar enforces the HPC.
 The newly produced language is then a subset of the old produced language with an   recognition algorithm.
 Because of the fact that our addition may simulate any polynomial restriction, we regain the full class of AVG's that satisfy the HPC.
 In fact   Theorem 4.1 The class, P-AVGL, of languages produced by the HP-AVGs is recursively presentable.
   We will give a detailed construction of such a set of rules in Appendix .
 The existence of such a set of rules and the work of Johnson now gives the following theorem.
   For any language L that has an   recognition algorithm, there exists a restricted attribute-value grammar G that respects the HPC and such that L=L(G).
   Proof.(Sketch) Let M be the Turing machine that decides   .
 Use a variation of Johnson's construction of a Turing machine to create an R-AVG that can produce any string w that is recognized by M.
 Add the set of rules that guarantee that only strings that can be produced with a polynomial number of rules can be produced by the grammar.
   Instead of creating a counter of logarithmic size as we do in Appendix , it is quite straightforward to construct a counter of linear size (or exponential size if there is enough time).
 In fact, for well-behaved functions, the construction of a counter gives a method to enforce any desired time bound constraint on the recognition problem for attribute-value grammars.
 For instance, for nondeterministic exponential time we could define the Linear Dishonest Parsability Constraint (LDP) (allowing a linear exponential number of steps) which would give.
   Theorem 5.1 The class of languages generated by R-AVGs obeying the LDP condition is exactly   .
 