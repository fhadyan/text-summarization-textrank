  The introduction of two-level morphology and subsequent developments has made implementing computational-morphology models a feasible task.
 Yet, two-level formalisms fell short from providing elegant means for the description of non-linear operations such as infixation, circumfixation and root-and-pattern morphology.
 As a result, two-level implementations - e.g.
 , , , - have always been biased towards linear morphology.
   The past decade has seen a number of proposals for handling non-linear morphology; however, none (apart from Beesley's work) seem to have been implemented over large descriptions, nor have they provided means by which the grammarian can develop non-linear descriptions using higher level notation.
   To test the validity of one's proposal or formalism, minimally a medium-scale description is a desideratum.
 SemHe fulfils this requirement.
 It is a generalised multi-tape two-level system which is being used in developing non-linear grammars.
   This paper (1) presents the algorithms behind SemHe; (2) discusses the issues involved in compiling non-linear descriptions; and (3) proposes extension/solutions to make writing non-linear rules easier and more elegant.
 The paper assumes knowledge of multi-tape two-level morphology , .
   Listing 1   The linguist provides SemHe with three pieces of data: a lexicon, two-level rules and word formation grammar.
 All entries take the form of Prolog terms.
 (Identifiers starting with an uppercase letter denote variables, otherwise they are instantiated symbols.) A lexical entry is described by the term     Categories are of the form #4\t\t \t\t a notational variant of the PATR-II category formalism .
   A two-level rule is described using a syntactic variant of the formalism described by , , including the extensions by ,   #8\t\t \t\t The arguments are: (1) a rule identifier, id; (2) the left-lexical-context, LLC, the lexical center, Lex, and the right-lexical-context, RLC, each in the form of a list-of-lists, where the ith list represents the ith lexical tape; (3) an operator, =] for optional rules or [=] for obligatory rules; (4) the left-surface-context, LSC, the surface center, Surf, and the right-surface-context, RSC, each in the form of a list; (5) a list of the variables used in the lexical and surface expressions, each member in the form of a predicate indicating the set identifier (see infra) and an argument indicating the variable in question; and (6) a set of features (i.e.
 category forms) in the form of a list-of-lists, where the ith item must unify with the feature-structure of the morpheme affected by the rule on the ith lexical tape.
   A lexical string maps to a surface string iff (1) they can be partitioned into pairs of lexical-surface subsequences, where each pair is licenced by a rule, and (2) no partition violates an obligatory rule.
   Alphabet declarations take the form tl_alphabet( tape, symbol_list), and variable sets are described by the predicate tl_set(id, symbol_list).
 Word formation rules take the form of unification-based CFG rules,     The following example illustrates the derivation of Syriac /ktab/ `he wrote' (in the simple p`al measure) from the pattern morpheme {cvcvc} `verbal pattern', root {ktb} `notion of writing', and vocalism {a}.
 The three morphemes produce the underlying form */katab/, which surfaces as /ktab/ since short vowels in open unstressed syllables are deleted.
 The process is illustrated in +1.
     The pa``el measure of the same verb, viz.
 /katteb/, is derived by the gemination of the middle consonant (i.e.
 t) and applying the appropriate vocalism {ae}.
   The two-level grammar (Listing 1) assumes three lexical tapes.
 Uninstantiated contexts are denoted by an empty list.
 R1 is the morpheme boundary (= ) rule.
 R2 and R3 sanction stem consonants and vowels, respectively.
 R4 is the obligatory vowel deletion rule.
 R5 and R6 map the second radical, [t], for p`al and pa``el forms, respectively.
 In this example, the lexicon contains the entries in +1.
 Note that the value of `measure' in the root entry is uninstantiated; it is determined from the feature values in R5, R6 and/or the word grammar (see infra, ).
   There are two current methods for implementing two-level rules (both implemented in SemHe): (1) compiling rules into finite-state automata (multi-tape transducers in our case), and (2) interpreting rules directly.
 The former provides better performance, while the latter facilitates the debugging of grammars (by tracing and by providing debugging utilities along the lines of ).
 Additionally, the interpreter facilitates the incremental compilation of rules by simply allowing the user to toggle rules on and off.
   The compilation of the above formalism into automata is described by .
 The following is a description of the interpreter.
   The word grammar is compiled into a shift-reduce parser.
 In addition, a first-and-follow algorithm, based on , is applied to compute the feasible follow categories for each category type.
 The set of feasible follow categories, NextCats, of a particular category Cat is returned by the predicate FOLLOW(+Cat, -NextCats).
 Additionally, FOLLOW(bos, NextCats) returns the set of category symbols at the beginning of strings, and eos NextCats indicates that Cat may occur at the end of strings.
   The lexical component is implemented as character tries , one per tape.
 Given a list of lexical strings, Lex, and a list of lexical pointers, LexPtrs, the predicate #17\t\t succeeds iff there are transitions on Lex from LexPtrs; it returns NewLexPtrs, and the categories, LexCats, at the end of morphemes, if any.
   Two-level predicates are converted into an internal representation: (1) every left-context expression is reversed and appended to an uninstantiated tail; (2) every right-context expression is appended to an uninstantiated tail; and (3) each rule is assigned a 6-bit `precedence value' where every bit represents one of the six lexical and surface expressions.
 If an expression is not an empty list (i.e.
 context is specified), the relevant bit is set.
 In analysis, surface expressions are assigned the most significant bits, while lexical expressions are assigned the least significant ones.
 In generation, the opposite state of affairs holds.
 Rules are then reasserted in the order of their precedence value.
 This ensures that rules which contain the most specified expressions are tested first resulting in better performance.
   Listing 2   Listing 3   Listing 4   Listing 5   Listing 6   The algorithms presented below are given in terms of prolog-like non-deterministic operations.
 A clause is satisfied iff all the conditions under it are satisfied.
 The predicates are depicted top-down in +1.
 (SemHe makes use of an earlier implementation by .)     In order to minimise accumulator-passing arguments, we assume the following initially-empty stacks: ParseStack accumulates the category structures of the morphemes identified, and FeatureStack maintains the rule features encountered so far.
 (`+' indicates concatenation.)   PARTITION partitions a two-level analysis into sequences of lexical-surface pairs, each licenced by a rule.
 The base case of the predicate is given in Listing 2, and the recursive case in Listing 3.
   The recursive COERCE predicate ensures that no partition is violated by an obligatory rule.
 It takes three arguments: Result is the output of PARTITION (usually reversed by the calling predicate, hence, COERCE deals with the last partition first), PrevCats is a register which keeps track of the last morpheme category encountered, and Partition returns selected elements from Result.
 The base case of the predicate is simply COERCE([], _, []) - i.e., no more partitions.
 The recursive case is shown in Listing 4.
 CurrentCats keeps track of the category of the morpheme which occures in the current partition.
 The invalidity of a partition is determined by INVALID-PARTITION (Listing 5).
   TWO-LEVEL-ANALYSIS (Listing 6) is the main predicate.
 It takes a surface string or lexical string(s) and returns a list of partitions and a morphosyntactic parse tree.
 To analyse a surface form, one calls TWO-LEVEL-ANALYSIS(+Surf, -Lex, -Partition, -Parse).
 To generate a surface form, one calls TWO-LEVEL-ANALYSIS(-Surf, +Lex, -Partition, -Parse).
   Listing 7   When developing Semitic grammars, one comes across various issues and problems which normally do not arise with linear grammars.
 Some can be solved by known methods or `tricks'; others require extensions in order to make developing grammars easier and more elegant.
 This section discuss issues which normally do not arise when compiling linear grammars.
   In Semitic languages, non-linearity occurs only in stems.
 Hence, lexical descriptions of stems make use of three lexical tapes (pattern, root vocalism), while those of prefixes and suffixes use the first lexical tape.
 This requires duplicating rules when stating lexical constraints.
 Consider rule R4 (Listing 1).
 It allows the deletion of the first stem vowel by the virtue of RLC (even if was not indexed); hence /katab/ /ktab/.
 Now consider adding the suffix {eh} `him/it': /katab/+{eh} /katbeh/, where the second stem vowel is deleted since deletion applies right-to-left; however, RLC can only cope with stem vowels.
 Rule R7 (Listing 7) is required.
 One might suggest placing constraints on surface expressions instead.
 However, doing so causes surface expressions to be dependent on other rules.
   Additionally, Lex in R4 and R7 deletes stem vowels.
 Consider adding the prefix {wa} `and': {wa} + /katab/ + {eh} /wkatbeh/, where the prefix vowel is also deleted.
 To cope with this, two additional rules like R4 and R7 are required, but with Lex = [[V],[],[]].
   We resolve this by allowing the user to write expansion rules of the from     In our example, the expansion rules in +1 are needed.
 The linguist can then rewrite R4 as R8 (Listing 7), and expand it with the command expand(R8).
 This produces four rules of the form of R4, but with the following expressions for Lex and RLC:   Orthographically, Semitic texts are written without short vowels.
 It was suggested by , et.
 seq.] and to allow short vowels to be optionally deleted.
 This, however, puts a constraint on the grammar: no surface expression can contain a vowel, lest the vowel is optionally deleted.
   We assume full vocalisation in writing rules.
 A second set of rules can allow the deletion of vowels.
 The whole grammar can be taken as the composition of the two grammars: e.g.
 {cvcvc},{ktb},{aa} /ktab/ [ktab, ktb].
   Listing 8   Finite-state models of two-level morphology implement morphotactics in two ways: using `continuation patterns/classes' , , or unification-based grammars , .
 The former fails to provide elegant morphosyntactic parsing for Semitic languages, as will be illustrated in this section.
   A pattern, a root and a vocalism do not alway produce a free stem which can stand on its own.
 In Syriac, for example, some verbal forms are bound: they require a stem morpheme which indicates the measure in question, e.g.
 the prefix {a} for af`el stems.
 Additionally, passive forms are marked by the reflexive morpheme {et}, while active forms are not marked at all.
   This structure of stems can be handled hierarchically using -theory.
 A stem whose stem morpheme is known is assigned =-2 (Rules 1-2 in Listing 8).
 Rules which indicate mood can apply only to stems whose measure has been identified (i.e.
 they have =-2).
 The resulting stems are assigned =-1 (Rules 3-4 in Listing 8).
 The parsing of Syriac /etkteb/ (from { et}+/kateb/ after the deletion of /a/ by R4) appears in +1.
   Now free stems which may stand on their own can be assigned =0.
 However, some stems require verbal inflectional markers.
   Table 1   With respect to verbal inflexional markers (VIMs), there are various types of Semitic verbs: those which do not require a VIM (e.g.
 sing.
 3rd masc.), and those which require a VIM in the form of a prefix (e.g.
 perfect), suffix (e.g.
 some imperfect forms), or circumfix (e.g.
 other imperfect forms).
   Each VIM is lexically marked inter alia with two features: `type' which states whether it is a prefix or a suffix, and `circum' which denotes whether it is a circumfix.
 Rules 5-8 (Listing 8) handle this.
   The parsing of Syriac /netkatbun/ (from {ne}+ { et}+/katab/+{un}) appears in +1.
   handle this problem by finding a logical expression for the prefix and suffix portions of circumfix morphemes, and use unification to generate only the correct forms - see , p.
 158].
 This approach, however, cannot be used here since, unlike Arabic, not all Syriac VIMs are in the form of circumfixes.
   A Semitic `word' (string separated by word boundary) may in fact be a clause or a sentence.
 Therefore, a morphosyntactic parsing of a `word' may be a (partial) syntactic parsing of a sentence in the form of a (partial) tree.
 The output of a morphological analyser can be structured in a manner suitable for syntactic processing.
 Using tree-adjoining grammars might be a possibility.
   To test the integrity, robustness and performance of the implementation, a two-level grammar of the most frequent words in the Syriac New Testament was compiled based on the data in .
 The grammar covers most classes of verbal and nominal forms, in addition to prepositions, proper nouns and words of Greek origin.
 A wider coverage would involve enlarging the lexicon (currently there are 165 entries) and might triple the number of two-level rules (currently there are c.
 50 rules).
   Table 1 provides the results of analysing verbal classes.
 The test for each class represents analysing most of its inflexions.
 The test was executed on a Sparc ELC computer.
   By constructing a corpus which consists only of the most frequent words, one can estimate the performance of analysing the corpus as follows,     where n is the number of distinct words in the corpus and fi is the frequency of occurrence of the ith word.
 The SEDRA database provides such data.
 All occurrences of the 100 most frequent lexemes in their various inflections (a total of 72,240 occurrences) can be analysed at the rate of 16.35 words/sec.
 (Performance will be less if additional rules are added for larger coverage.)   The results may not seem satisfactory when compared with other prolog implementations of the same formalism (cf.
 50 words/sec, in ).
 One should, however, keep in mind the complexity of Syriac morphology.
 In addition to morphological non-linearity, phonological conditional changes - consonantal and vocalic - occur in all stems, and it is not unusual to have more than five such changes per word.
 Once developed, a grammar is usually compiled into automata which provides better performance.
   This paper has presented a computational morphology system which is adequate for handling non-linear grammars.
 We are currently expanding the grammar to cover the whole of New Testament Syriac.
 One of our future goals is to optimise the prolog implementation for speedy processing and to add debugging facilities along the lines of .
   For useful results, a Semitic morphological analyser needs to interact with a syntactic parser in order to resolve ambiguities.
 Most non-vocalised strings give more than one solution, and some inflectional forms are homographs even if fully vocalised (e.g.
 in Syriac imperfect verbs: sing.
 3rd masc.
 = plural 1st common, and sing.
 3rd fem.
 = sing.
 2nd masc.).
 We mentioned earlier the possibility of using TAGs.
 