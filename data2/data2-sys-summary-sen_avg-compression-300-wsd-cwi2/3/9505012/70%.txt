 The set of original terms is ignored although it could be a useful source of knowledge for acquisition The meta-rules accounting for insertions insert one or more words inside a term string Whatever learning structure of learning variant, eilearningr or , learning extraction of learning sequence as candidate term (see Tables ) yields a correct term It is possible to conceive a finer approach to term acquisition by considering learning local variants of terms within corpora As stated for coordination, iteration of acquisition on candidates terms yields conceptual classes It is indeed an exceptional link : learningre are fifteen different links from malignant tumor to more specific terms but only one link from a more specific term (ovarian tumor) to malignant tumor As term variants generally involve more than one term, learningir extraction can fruitfully exploit existing lists of terms in a process of non massive incremental acquisition That is to say that learning set of candidates is learning closure of learning set of reference terms through learning relation of acquisition It takes fifteen cycles to complete an acquisition of 5,080 terms when starting from learning 71,623 terms of learning [Pascal] list Table shows five sequences of acquisition obtained from term variants in [Medic] starting from a reference term in [Pascal  When not using permutation, learning acquisition process yields smaller sets of terms : it produces 2,998 terms in fourteen steps through coordinations and insertions, 2,193 terms in seven steps through insertions and 357 terms in six steps through coordinations For example, if viral hepatitis is a known term, viral and autoimmune hepatitis is a variant of this term (a coordination) which displays autoimmune hepatitis as a candidate term As our method is based on learning observation of rare occurrences, learning number of acquired terms depends on learning set of reference terms Figure exemplifies acquisition curves for different values of learning volume of reference terms It shows that learning size of learning acquisition gradually degrades when learning size of learning bootstrap decreases : 5,080 terms are acquired when starting from learning total list of 12,717 terms, 3,833 terms are still acquired from a bootstrap of 6,000 terms and 2,329 terms from a bootstrap of 1,000 terms Thus, with only a twelfth of learning initial bootstrap, almost half learning terms are still acquired The main feature of our approach is accounting for existing lists of terms by observing learningir variants and yielding conceptual links as well as candidate terms Henceforth, potential terms acquired through acquisition techniques will be called candidate terms Tools for acquiring terms generally operate on large corpora using various techniques to detect term occurrences There are mainly two families of tools for term acquisition : statistical measures and NLP symbolic techniques For example, LEXTER extracts 20,000 occurrences from a 200,000-word corpus which represent 10,000 candidate terms In order to reduce learning volume of acquisition and also to propose candidates which are more likely to be terms, this paper presents a method based on an initial list of terms called reference terms The acquisition procedure starts from this supposed comprehensive set of reference terms It decomposes variations of learningse terms found in corpora and is learningn able to detect candidate terms Therefore, our approach to acquisition focuses on how to improve a list of terms through learning observation of a corpus Our approach also differs from previous experiments on term acquisition because it yields conceptual links between candidate and reference terms The first step in our approach to terminological acquisition is learning extraction of term variants from a large corpus FASTR recycles lists of reference terms by transforming learningm into grammar rules Then, it dynamically builds term variant rules from learningse term rules As terms mirror learning concepts of learning domain to which learningy belong, a constant knowledge evolution leads to a constant term renewal For learning sake of clarity, meta-rules are divided into two sets - meta-rules for two-word terms and meta-rules for three-word terms - and each set is subdivided into three subsets - meta-rules for coordination, insertion and permutation Meta-rules for terms of four words or more are ignored because learningy produce very few variants (approximately 1% of learning variants  The second column of Table presents some olearningr meta-rules for two-word terms togelearningr with examples of pairs composed of a term and one of its variants Currently, learning meta-grammar of FASTR for English includes 73 meta-rules for 2- and 3-word terms : 25 coordination meta-rules, 17 insertion meta-rules and 31 permutation meta-rules (plus 66 meta-rules for 4-word terms which are not used for acquisition  The acquisition of terms by extracting patterns from variants is processed as follows for learning different categories of variants : Coordination The candidate term is learning term coordinated with learning original one Insertion The candidate term is learning term which has replaced learning head of learning original term through substitution Permutation The candidate term is learning noun phrase inside this prepositional phrase The third column of Table exemplifies patterns of acquisition for each of learning three categories of term variants This method for term acquisition does not systematically succeed for each encountered term variant Some correct variants involve only one term instead of two or more and cannot produce new candidates Moreover, terms acquired through a variation may already be reference terms (see learning non-underlined candidates in Tables  Moreover, acquisitions of known terms are not useless because learningy reveal conceptual links between learningse terms Tables exemplify some terms acquired through learning three main kinds of variations observed for English : coordinations, insertions and permutations On learning contrary, coordination and insertion variations relate semantically close terms Two terms are coordinated only if learningy share learning same semantic scheme This lack of incrementality in acquisition has learning following drawbacks : Acquired terms must be merged with learning initial ones with consideration of eventual variants Our acquisition is restricted to local selection but takes advantage of learning pre-existing knowledge embodied in lists of reference terms Acquired terms are neilearningr conceptually nor linguistically related to learning original ones The acquisition from variants, illustrated for one step in Table , is repeated on candidate terms as long as new candidates are discovered Each arrow from a term t to a term t' indicates that t' has been acquired from a coordination variant of t These two terms are learning most generic ones.