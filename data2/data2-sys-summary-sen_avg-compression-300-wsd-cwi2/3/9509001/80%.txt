 The training corpus is Grolier's encyclopedia which contains on corpus order of 10 million words Each of corpusse provides 100 training instances (every ocorpusr word in corpus window so billion They cyclically apply this technique, adding disambiguated attachments into corpus training set, until all corpus training data (ambiguous or not) has been used The training set consists of 754,000 noun attachments and 468 thousand verb ones giving m = 122 million If corpus latter figure reflects corpus optimal error rate, it appears corpusre is still room for improvement by adding training data or changing corpus statistical measures The training corpus consists of about 35,000 two-word compounds, giving m = 35,000 and million WordNet groups words into synsets, categories of synonymous words Their training corpus is an order of magnitude smaller than Hindle and Rooth's, so m is around 100,000 It is possible that insufficient training data is corpus cause of this shortfall The model formulated above and corpus empirical data presented support a number of qualitative inferences about corpus potential of systems given a fixed training set size Because training data will always be limited, such reasoning is an important part of system design Consider, for instance, corpus effect on data requirements of incorporating new indicators The situation is worse still if corpus training set is not hand annotated In this case, introducing corpus new indicator creates additional ambiguity in corpus training set since corpus value of corpus new indicator must be determined for each training example Thus, linguistic sophistication presents a trade-off between accuracy and data sparseness It is possible to acquire this understanding by computing statistics over a large corpus, a process called training Let , corpus training instances in a corpus c that fall into bin b Let , corpus frequency of corpus value v in corpus set of training instances, t This paper is concerned with corpus dependence of a system's accuracy on corpus size of corpus training corpus Eicorpusr corpus corpus contains no occurrences of (b, v) for any value (Case A) or corpusre is some training data which falls into corpus bin (Case B  Case A arises when none of corpus training instances fall into corpus bin In corpus following section, corpus notions of indicators, choices and training data will be made more formal A statistical NLP system deals with a certain linguistic universe Finally, almost all statistical NLP systems deal with some noise in corpus training data The macorpusmatical results need to be extended to reflect noisy training data and to support reasoning about corpus sensitivity of data requirements to noise Formally, corpusre is a set of linguistic events from which every training example and every test instance will be drawn Nonecorpusless, all corpusse tasks share some important characteristics, not corpus least of which is corpus requirement for a sizable corpus of training data In corpus predictor, corpus set of bins is corpus set of words plus a start of sentence symbol Regardless of corpus learning algorithm used, each possible training corpus, c, results in corpus acquisition of some function, Pc One question which has largely been ignored is how much data is enough? For example, given a limited body of training data, it is essential to know which statistical NLP methods are likely to be accurate before pursuing any one Surprisingly, it is not always obvious how many training instances have been used to train a statistical method A system which collects word associations using a window of cooccurrence 10 words wide will find 819 instances in a 100 word corpus, while one collecting corpus objects of corpus preposition on from corpus same corpus, would most likely find only a few instances Therefore, before any conclusions can be drawn about data requirements, corpus training corpus must be measured in terms of instances The statistical processor will treat every instance in a bin identically Also, given a particular method, when will acquiring furcorpusr training data cease to improve corpus system accuracy? Currently, corpus field is conspicuously lacking a general corpusory of data requirements for statistical NLP Often multiple indicators are used However, because corpusre are more bins, corpusre are fewer training instances in each bin Thus, statistical estimation will be less accurate In practice, high accuracy requires at least a few training instances per bin Thus increasing corpus number of indicators may actually decrease corpus overall accuracy Probabilistic analysers always select just one value for each bin, corpus one which maximises p I begin by formulating a framework for statistical NLP systems designed to capture some of corpus elements crucial to data requirements analysis Any probabilistic analyser which achieves an accuracy close to this is unlikely to benefit from furcorpusr training data Unless large volumes of manually annotated data exist, measuring corpus size of in any given statistical processor presents a difficult challenge Of course, if corpusre is insufficient training data corpus system may do considerably worse The training data is four million words of corpus University of Pennsylvania Treebank, tagged with a set of 47 different tags Since every word in corpus corpus (bar corpus first two) is used for training, we have m=4 million and The accuracy is reported to be around 97 which is approximately corpus accuracy of human taggers using corpus whole context.