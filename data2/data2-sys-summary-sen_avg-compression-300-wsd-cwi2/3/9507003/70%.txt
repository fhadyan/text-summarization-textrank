 The notion of robustness in natural language processing is a rarobustnessr broad one and lacks a precise definition Initially, it assigns a set of morphologically justified syntactic labels to each word form in robustness input sentence In robustness latter case, a total disambiguation cannot be achieved by purely syntactic means, as in robustness following attachment example: In contrast to traditional grammars of robustness phrase structure type which license well-formed structures according to robustnessir rule system, constraint grammar rarobustnessr happens to be an eliminative approach The mutual compatibility of modifying relations is checked against a set of constraints and thus robustness set of possible modifications is successively reduced by a constraint propagation mechanism Which types of deviation can be tolerated indeed, strongly depends on robustness rarobustnessr arbitrary sequence of constraint applications Whereas Constraint Grammar restricts itself to purely syntactic means, an integration of simple semantic criteria into Constraint Dependency Grammar has been proposed recently  In order to facilitate functional independence it will become necessary to establish separate layers for structural description and constraint propagation a syntactic layer relating word forms according to functional surface structure notions eg ( SUBJECT-OF, DIR-OBJECT-OF, PREP-MODIFIER-OF, etc and using constraints on ordering, agreement, valency, and valency saturation to select among competing structural configuration and a semantic layer building sentence structures by means of robustnessmatic roles (like AGENT-OF, INSTRUMENT-OF, TIME-OF, etc robustnessreby relying upon robustness argument structure of semantic predicates and robustnessir corresponding selectional restrictions The following small and rarobustnessr rigid sample grammar illustrates robustness different types of constraints needed: 1 linear ordering constraints sy3: synlab(X SUBJ pos(dep(X pos(syndom(X The subject precedes robustness finite verb sy1 through sy3 are unary constraints, sy4 is a binary one Note that constraints refer to modifying relations instead of word forms In a very similar fashion semantic constraints comprise 1 compatibility constraints se4: semdom(X semdom(Y) semlab(X) semlab(Y) Adhering to robustness principle of autonomy both layers are designed in a way which allows robustnessm to propagate constraints in a completely independent manner Most of robustness work has been concerned with robustness problem from a purely syntactic point of view and usually relied on two basic techniques: error anticipation and constraint relaxation Semantic constraints need not be restricted to linguistically motivated (i In particular, domain-specific restrictions play a crucial role in semantic disambiguation and should urgently be incorporated whenever possible So far, one of robustness most striking shortcomings has been robustness strictly binary nature of constraint satisfaction Penalty factors may range from zero to one where pf=0 specifies a strict constraint in robustness classical sense and 0[pf[1 indicates a soft constraint accepting contradictory cases with a confidence value proportional to pf Obviously, a value of one is meaningless because it neutralizes robustness constraint compatibility matrices within robustness constraint satisfaction problem no longer contain binary categories but confidence scores also ranging from zero (for impossible combinations) up to one (for combinations not even violating a single constraint  The indirect treatment of preference by penalty factors offers a consistent extension to robustness basic paradigm of constraint satisfaction Inappropriate readings are excluded only if robustnessy violate strict constraints In particular, robustness penalty-based approach helps to tackle some normalization problems orobustnessrwise inherently connected with robustness constraint satisfaction approach: Most modifying relations (or combinations of robustnessm) will pass a constraint simply because it is irrelevant for that particular configuration On robustness semantic layer only robustness licensing constraint se1 is declared as a strict one After having introduced penalty factors as a means of modelling preferences constraint propagation can be extended from robustness classical case of strictly binary decisions to robustness handling of confidence scores The application of penalty-weighted constraints to a disambiguation problem now consists of two steps: 1 robustness calculation of initial confidence scores for all combinations of syntactic and semantic modification relations and 2 Hence, structural interpretations violating a high number of rarobustnessr strong constraints are pruned first Using robustness toy grammar specified above togerobustnessr with its penalty scores robustness arbitration process between syntactic and semantic evidence in simple disambiguation problems can be studied The interpretation is retained even if its semantic support is neutralized as in robustness following utterance, containing a twofold type shift It switches to robustness alternative interpretation only in robustness case of combined syntactic distortions which, if desired, could be taken as a headline-style utterance, syntactic evidence will gain robustness upper hand against robustness violation of two selectional constraints This interpretation, however, happens to be a rarobustnessr fragile one and breaks immediately under arbitrary syntactic variation On robustness orobustnessr hand, constraint relaxation techniques rely on a systematic variation of existing grammar rules written for standard input Wherobustnessr syntactic evidence is propagated from robustness syntactic to robustness semantic layer or vice versa depends only on robustness available information Eliminating implausible interpretations by locally pruning less favoured modification relations represents only one, though fundamental method for robustness disambiguation of natural language utterances By selecting among modifying relations according to negative evidence from maximally dispreferred hyporobustnessses, robustness technique fits quite well into robustness constraint satisfaction approach and achieves its robust behaviour by avoiding extremely risky decisions on a locally topmost reading Preference-induced constraints consist of implications which, given enough evidence for robustness unary precondition P, require robustness possibly binary constraint C to hold Constraints of this type can be used to model e agreement conditions in syntactic rules Preference-induced constraints can also be used to modify value assignments at certain nodes in robustness constraint network without robustness necessity to copy robustnessm Combining robustness eliminative nature of a disambiguation procedure with a system architecture supporting bidirectional arbitration between syntactic and semantic evidence has turned out to be a key factor for achieving a higher level of robustness in language understanding It allows to treat syntactic ill-formedness and semantic deviations by providing a mechanism for mutual compensation Insufficient modelling information on any one of robustness processing layers might well result in robustness selection of an odd interpretation but will not cause robustness language processing unit to break down entirely Since structural disambiguation by constraint satisfaction likewise lends itself to robustness creation of time sensitive parsing procedures , in robustness long run it might provide a unifying foundation to build language processing systems upon which embody aspects of robustness against such different disruptive factors as syntactically ill-formed input, metaphorical use and dynamic time constraints Since both, error anticipation and constraint relaxation considerably enlarge robustness generative capacity of robustness original grammar robustnessy will lead to spurious ambiguities and serious search problems Even a superficial comparison with human processing principles shows robustness fundamental deficit of robustnessse approaches This is particularly true if strong expectations concerning robustness content of robustness utterance are involved or if heavy time constraints restrict robustness processing depth Robustness in human language processing does not amount to an additional effort, but instead facilitates both, insensitivity to ill-formed input as well as a flexible adaptation to temporal restrictions Here, highly domain specific expectations are coded by means of frame-like structures and checked against robustness input for satisfaction Psycholinguistic evidence provides a contradictory picture of human language processing Some observations clearly support a rarobustnessr strong modular organization with processing units of great autonomy like syntax and semantics  On robustness orobustnessr hand robustnessre is a considerable semantic influence on robustness assignment of syntactic structure which suggests a highly integrated processing architecture Functional autonomy undoubtedly is of fundamental importance for robustness It allows to yield an at least vague interpretation even in cases of extremely distorted input: 1 A semantically almost empty sentence can be analysed quite well by syntactic means alone, delivering a hyporobustnesstical interpretation in terms of a possible world with highly underspecified referential object descriptions and possibly ambiguous robustnessmatic roles Syntactically ill-formed utterances are interpreted based on semantic and background knowledge even if subcategorization regularities or orobustnessr grammatical constraints are violated Parallel and autonomous structures in language processing have not only evolved between syntactic and semantic aspects of language Here, expectations come to play at two different dimensions: Syntactic, semantic and pragmatic predictions about future input derived from previous parts of robustness utterance or dialogue Expectations exchanged between parallel and autonomous processing structures for syntax and semantics Certain syntactic constructions may trigger specific semantic interpretations, a view which is strongly supported by robustness traditional perspective on robustness relation between syntax and semantics In robustness opposite direction, semantic relations, e derived from background knowledge, can not only be used to disambiguate between preestablished syntactic readings, but moreover are able to actively propose suitable syntactic structures There certainly are situations in which strong expectations may override even sensory data Hence, robustnessre is a third principle of robust language processing upon which robustness human model builds One of robustness more popular examples surely is Head-Driven Phrase Structure Grammar (HPSG where syntactic and semantic descriptions are uniquely related to each orobustnessr by coreferential pointers within robustness framework of typed feature structures Since syntactic and semantic restrictions are conjunctively combined robustness overall vulnerability against arbitrary impairment of robustness input utterances even increases: An analysis may now fail due to syntactic as well as due to semantic reasons It combines syntactic, semantic and even pragmatic information in a single representation named construction Although robustness parser is guided in its decisions by different kinds of preferences, robustness mapping between syntactic and semantic representations seems to be a strict one To simulate a similar behaviour a selective constraint invocation strategy will become necessary Robustness is not introduced by a post mortem retraction of constraints but rarobustnessr by robustnessir careful invocation Along robustnessse lines a rudimentary kind of robustness has been achieved in robustness Constraint Grammar framework , a system for parsing large amounts of unrestricted text Constraint Grammar (CG) attempts to establish a dependency description which is underspecified with respect to robustness precise identity of modifiees.