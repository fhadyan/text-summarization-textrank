 Recall is the percentage of information in a text that is correctly extracted by a system; precision is the percentage of information extracted by a system that is correct where the answer key for each text contains a set of phrases and the coreference links among them However, evaluation of coreference performance is complicated by the need to take into account the implicit coreference links among phrasese what fraction of correct coreference links is implied by the transitive closure of the coreference links in the system response One of the problems with these coreference resolution components was figuring out which features of the phrases to look at when determining coreference The comparative effects of false positives and false negatives in coreference classification on overall IE system performance remains an open question high precision in overall IE system performance, the F-measure score that gives equal weight to extract and precision may be the best indicator of overall performance on the coreference resolution task We are encouraged by the performance of the decision trees on the coreference resolution problem5 decision tree system to learn how to classify coreferent phrases for the experiments reported in this paper An experiment was conducted to compare the performance of the decision trees generated by RESOLVE with the performance of manually engineered rules used for coreference classification in the UMass/Hughes MUC-5 IE system The pairings that contained coreferent phrases formed positive instances, while those that contained two non-coreferent phrases formed negative instancesg people The data used in this experiment was based on a set of phrases extracted using CMI The phrases underlined in this sentence contain relevant information that must be extracted by an IE system Further complications are created for evaluating the performance of a coreference system when multireferent phrases are included in the data (see Section  The coreference module of the UMass/Hughes MUC-5 IE system was designed to minimize false positives, i This design decision was based on the assumption that false positive errors, resulting in the merging of non-coreferent phrases in the final system output, would harm system performance more than false negative errors, which would result in coreferent phrases showing up in distinct objects in the system output The rules used to determine whether two phrases (represented as memory tokens) were coreferent in the MUC-5 system are shown in Table .