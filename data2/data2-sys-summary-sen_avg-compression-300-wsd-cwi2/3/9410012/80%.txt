 Alternatively, a procedure called Baum-Welch (BW) re-estimation may be used, in which an untagged corpus is passed through the FB algorithm with some initial model, and the resulting probabilities used to determine new values for the lexical and transition probabilities Initial maximum Highest accuracy on the first iteration, and falling thereafter Early maximum Rising accuracy for a small number of iterations (2-4 and then falling as in initial maximum Secondly, we selected test corpora with varying degrees of similarity to the training corpus: the same text, text from a similar domain, and text which is significantly different The results appear in table , showing the best accuracy achieved (on ambiguous words  With a good lexicon but either degraded transitions or a test corpus differing from the training corpus, the pattern tends to be early maximum When the test corpus is very similar to the model, then the pattern is initial maximum If the test and training corpora are near-identical, do not use BW re-estimation; otherwise use for a small number of iterations If no such training corpus is available, but a lexicon with at least relative frequency data is available, use BW re-estimation for a small number of iterations If neither training corpus nor lexicon are available, use BW re-estimation with standard convergence tests such as perplexity In addition, although Merialdo does not highlight the point, BW re-estimation starting from less than 5000 words of hand-tagged text shows early maximum behaviour The model is defined by two collections of parameters: the transition probabilities, which express the probability that a tag follows the preceding one (or two for a second order model and the lexical probabilities, giving the probability that a word has a given tag without regard to words on either side of it 96% accuracy correct assignment of tags to word token, compared with a human annotator, is quoted, over a 500000 word corpus The Xerox tagger attempts to avoid the need for a hand-tagged training corpus as far as possible Instead, an approximate model is constructed by hand, which is then improved by BW re-estimation on an untagged training corpus The initial model set up so that some transitions and some tags in the lexicon are favoured, and hence having a higher initial probability To tag a text, the tags with non-zero probability are hypothesised for each word, and the most probable sequence of tags given the sequence of words is determined from the probabilities The results suggest that a completely unconstrained initial model does not produce good quality results, and that one accurately trained from a hand-tagged corpus will generally do better than using an approach based on re-estimation, even when the training comes from a different source For training from a hand-tagged corpus, the model is estimated by counting the number of transitions from each tag i to each tag j, the total occurrence of each tag i, and the total occurrence of word w with tag i Any transitions not seen in the training corpus are given a small, non-zero probability The lexicon lists, for each word, all of tags seen in the training corpus with their probabilities For words not found in the lexicon, all open-class tags are hypothesised, with equal probabilities For a corpus in which a fraction a of the words are ambiguous, and p is the accuracy on ambiguous words, the overall accuracy can be recovered from 1-a+pa The training and test corpora were drawn from the LOB corpus and the Penn treebank The first experiment concerned the effect of the initial conditions on the accuracy using Baum-Welch re-estimation D2 Lexical probabilities are proportional to the overall tag frequencies, and are hence independent of the actual occurrence of the word in the training corpus contains 32 Secondly, training from a hand-tagged corpus (case D0+T0) always does best, even when the test data is from a different source to the training data, as it is for LOB-L.