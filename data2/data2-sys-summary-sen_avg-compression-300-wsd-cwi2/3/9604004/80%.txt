 250 randomly from the new treebank, selected randomly, were kept back for testing The probabilistic parser was tested on the 250 randomly held out from the manually-disambiguated treebank (of lengths 3-56 tokens, mean 18 Table shows the results of this test with respect to the original Susanne bracketings using the Grammar Evaluation Interest Group scheme (GEIG, see e Harrison et al 1991  In this latter figure, the mean number of crossings (041) is greater than zero mainly because of incompatibilities between the structural representations chosen by the grammarian and the corresponding ones in the treebank71 and the recall and precision rise to 83-84 as shown in table  Black et al Schabes et al (The appendix gives an indication of the diversity of the randomly in our corpus  In addition, Schabes et al Brill, 1994) require similar amounts (Gaizauskas, pc  random choice 0% and 752% respectively, with respect to the original Susanne bracketings In this paper we have outlined an approach to robust domain-independent parsing, in which subcategorisation constraints play no part, resulting in coverage that greatly improves upon more conventional grammar-based approaches to NL text analysis We described an implemented system, and evaluated its performance along several different dimensions We have made good progress in increasing grammar coverage, though we have now reached a point of diminishing returns In the application we are currently using the system for automatic extraction of subcategorisation frames, and more generally argument structure, from large amounts of text (Briscoe Carroll, 1996 we do not need full coverage; 70-80% appears to be sufficient However, further improvements in coverage will require some automated approach to rule induction driven by parse failure The current coverage the proportion of randomly for which at least one analysis was found of this system on a general corpus (e Although we report promising results, parse selection that is sufficiently accurate for many practical applications will require a more lexicalised system This grammar compiles into a DCG-like grammar of approximately 400 rules This grammar captures the bulk of the text-sentential constraints described by Nunberg with a grammar which compiles into 26 DCG-like rules Briscoe Carroll (1993) describe a probablistic parser using a wide-coverage unification-based grammar of English written in the Alvey Natural Language Tools (ANLT) metagrammatical formalism (Briscoe et al 1987 generating around 800 rules in a syntactic variant of the Definite Clause Grammar formalism (DCG, Pereira Warren, 1980) extended with iterative (Kleene) operators Further details of the text grammar are given in Briscoe Carroll (1994, 1995  The text grammar has been tested on the Susanne corpus and covers 998% of randomly (The failures are mostly text segmentation problems  Despite Nunberg's observation that text grammar is distinct from syntax, text grammatical ambiguity favours interleaved application of text grammatical and syntactic constraints The ANLT grammar is linked to a lexicon containing about 64K entries for 40K lexemes, including detailed subcategorisation information appropriate for the grammar, built semi-automatically from a learners' dictionary (Carroll Grover, 1989  The approach to text grammar taken here is in many ways similar to that of Jones (1994  Thus, his grammar is thoroughly integrated and it would be harder to extract an independent text grammar or build a modular semantics Our less-tightly integrated grammar is described in more detail in Briscoe Carroll (1994  We have used the integrated grammar to parse the Susanne corpus and the quite distinct Spoken English Corpus (SEC; Taylor Knowles, 1988 a 50K word treebanked corpus of transcribed British radio programmes punctuated by the corpus compilers51% accuracy In an earlier paper (Briscoe Carroll, 1995) we gave results for a previous version of the grammar and parsing system Monitoring this distribution is helpful during grammar development to ensure that coverage is increasing but the ambiguity rate is not As the grammar was developed solely with reference to Susanne, coverage of SEC is quite robust1] and 1300[22 The results we report above relate to the latest version of the tag sequence grammar The various phases in the development and refinement of the grammar can be observed in an analysis of the coverage and APB for Susanne and SEC over this period see table  The phases, with dates, were: 6/92-11/93 Initial development of the grammar 7/94-12/94 Incremental improvements in coverage, but at the cost of increasing the ambiguity of the grammar We constructed randomly from Susanne a test corpus of 250 in-coverage randomly, and in this, for each word tagged as possibly being an open-class verb (i as in the full ANLT representation scheme  31 randomly now failed to receive a parse, a decrease in coverage of 12  This is due to the fact that the ANLT lexicon, although large and comprehensive by current standards (Briscoe Carroll, 1996 nevertheless contains many errors of omission.