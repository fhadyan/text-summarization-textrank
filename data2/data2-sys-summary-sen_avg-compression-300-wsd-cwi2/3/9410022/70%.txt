 Trial 1: Artificial Data In the first sequence, both programs generated random sequences of tones, then computed the corresponding F0 sequence using , then set about transcribing the F0 sequence Since these sequences were ideal, the best possible evaluation for a transcription was zero For each length, each program transcribed 100 randomly-generated sequences Each pair of bars corresponds to a given transcription length The left member of each pair is for the genetic search program, while the right member is for the annealing search program These indicate the number of times out of 100 that the programs found a transcription with an evaluation less than 1 Observe that the annealing search program performs significantly better in all cases Note that the mutation operation in the genetic search program treats each bit in the parameter encodings equally, while the perturbation operation in the annealing search program is sensitive to the distinction between more significant vs less significant bits This may explain the better convergence behaviour of the annealing search This is probably because a randomly generated sequence will contain downsteps on every second tone (on average) causing a general downtrend in the F0 values and severely limiting the combinatorial explosion of possible transcriptions Again the annealing program fares better than the genetic program Trial 3: Actual Data The final sequence involved real data, including data from the utterance given in Figure 1 Performance results are given in Figure 8 This is because evaluations near zero were less likely with real data In fact, the annealing program never found an evaluation less than 3 while the genetic program never found an evaluation less than 4 Since the programs performed about equally on finding transcriptions with an evaluation less than 7, I shall display these transcriptions along with an indication of how many times each program found the transcription (G = genetic, A = annealing  In sequence 1, three transcriptions were found by both programs The third transcription points to another possibility, given in (  Although we have seen more than one transcription for a given F0 sequence, it is inconvenient to be required to run the programs several times in order to see if more than one solution can be found This is done by defining a distance metric on transcriptions which counts the number of tones in one transcription that have to be changed in order to make it identical to the other transcription In the absence of a program which enshrines these heuristics, it was decided to develop a system for producing a tone transcription from a sequence of F0 values Now, consider the following randomly generated sequence of tones: The annealing program was set the task of finding ten transcriptions of this tone sequence Interestingly, the third solution in both of the above executions was not found, though two new solutions were found Apart from the obvious benefits of automating the process, such as speed and accuracy, it could show up cases where there is more than one possible tone transcription, possibly with different parameter settings for the F0 scaling function My sequence-and-error approach will not necessarily have found optimal parameter values, and so it would be premature to conclude from the performance comparison that annealing search is better than genetic search for the problem of tone transcription Since the parameters are continuous variables, and since the evaluation function which we could write as is a smoothly continuous function in h, l, d, it would be worthwhile to try other (deterministic) search methods for optimising h, l and d, once a candidate tone transcription T has been found I showed that it is desirable for phonologists working on tone to use sequences of F0 values as their primary data, rather than impressionistic transcriptions which make (usually implicit) assumptions about F0 scaling I provided an F0 prediction function which estimated the F0 value of a tone, given the F0 value of the previous tone and the identities of the two tones The function was then incorporated into the evaluation functions of two implemented non-deterministic search algorithms The performance results were encouraging and demonstrate the promise of automated tone transcription Similarly, in many tone languages,voice pitch alone signals the tense of a verb These two possibilities exist because of different F0 scaling parameters Immediately below the two rows of tones we see a row of numbers corresponding to the tones a transcription  a tone transcription) given a sequence of n F0 values X The programs make crucial use of the prediction function in evaluating candidate tone transcriptions This is illustrated in Figure 1, where L indicates a low tone and A promising way of generating contours from tone sequences is to specify one or more pitch targets per tone and then to interpolate between the targets; the task then becomes one of providing a suitable sequence of targets  Exhaustive search for the global optimum is not an option when the search space is prohibitively large In the present context, say for a sequence of 20 tones, the search space contains possible tone transcriptions, and for each of these there are thousands of possible parameter settings, too large a search space for exhaustive search in a reasonable amount of computation time The best known such methods are genetic search and annealing search  In the following sections I describe a genetic algorithm and an annealing algorithm for the tone transcription problem It is perhaps less clear how we should go about recognising tone sequences from pitch contours In its early stages when the temperature is high, annealing search resembles random search As the temperature decreases the search begins to resemble hill-climbing Now there is much less free energy and so transitions to higher energy states are less and less likely temperature At the start of the search the temperature, t is set to 1 During the search, the temperature is reduced at a rate set by the `cooling rate' parameter, until it reaches a value less than 10 6  For a tone sequence of length n, we randomly reset the worst nt tones according to  First, set  free energy function This is the amount of available energy for transitions to higher energy states The factor of 1000 is intended to scale the energy distribution to typical values of the evaluation function The first step is to perturb the previous transcription to make a new one If the new transcription has a better evaluation than the old one, then is negative Finally, we check if the new transcription is better than the best transcription found so far (BestTrans) and if so, we set BestTrans to be the new transcription Once equilibrium is reached, the current transcription is set to be the best transcription found so far, and the search continues Both the genetic and annealing search algorithms have been implemented in C .