 the receive of training sentences for which a QLF with a correct skeletal tree receives the highest score The receives of correctly-processed sentences (i Each preference function is defined as a numerical (possibly real-valued) function on representations corresponding to the sentence analyses Data collection for the semantic collocation functions proceeds by deriving a set of triples from each QLF analysis of the sentences in the training set From these five functions on triples we define five semantic collocation preference functions applied to QLFs, in each case by averaging over the result of applying the function to each triple derived from a QLF We refer to these functions by the same names as their underlying functions on triples In contrast, the other collocation functions only make use of the training score to select the best analysis of a sentence, discarding the rest We have presented a relatively simple analytic technique for automatically determining a set of scaling factors for preference functions used in semantic disambiguation There are also some real-valued functions, including the semantic collocation functions discussed in section  Four functions return non-zero scores on these analyses A fourth, SemColl, is a semantic collocation function As mentioned earlier, the preference score is a weighted sum of a set of preference functions: Each preference function fj takes a complete QLF representation qi as input, returning a numerical score sij, the overall preference score being computed by summing over the product of function scores with their associated scaling factors cj: The training process begins by analysing the corpus sentences and computing, for each analysis of each sentence, the training score of the analysis with respect to the manually-approved skeletal tree and the (unscaled) values of the preference functions applied to that analysis.