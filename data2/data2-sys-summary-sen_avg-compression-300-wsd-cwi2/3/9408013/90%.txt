 the skeletal of training sentences for which a QLF with a correct skeletal tree receives the highest score One of the functions we used shows the limitations of least-squares scaling factor optimisation, alluded to above, in quite a dramatic way The function in question returns the skeletal of temporal modifiers in a QLF Each preference function is defined as a numerical (possibly real-valued) function on representations corresponding to the sentence analyses Data collection for the semantic collocation functions proceeds by deriving a set of triples from each QLF analysis of the sentences in the training set We refer to the coefficients, or weights, used in this linear combination as the scaling factors for the functions More specifically we use  Mean distance: the average of the relativised training score for all QLF analyses (not necessarily highest ranked ones) which include the semantic collocation corresponding to the triple From these five functions on triples we define five semantic collocation preference functions applied to QLFs, in each case by averaging over the result of applying the function to each triple derived from a QLF We refer to these functions by the same names as their underlying functions on triples Thus the optimality of a set of scaling factors is relatively insensitive to sentence length In contrast, the other collocation functions only make use of the training score to select the best analysis of a sentence, discarding the rest When one collocation function is selected to act together with the nineteen non-collocation-based functions from the default set (the set defined in section and used in the experiments on scaling factor calculation) the picture changes slightly It may be that other preference functions make up for some shortfall of the function that is, at least in part, taken account of by the mean distance function Large scale rule based analysis systems have therefore tended to employ a collection of functions to produce a score for sorting analyses in a preference order We have presented a relatively simple analytic technique for automatically determining a set of scaling factors for preference functions used in semantic disambiguation There is now more empirical work comparing such functions, particularly in the case of functions based on statistical information about lexical or semantic collocations The results we present show that these functions vary considerably in disambiguation accuracy, but that the best collocation functions are more effective than a function based on simple estimates of syntactic rule probabilities In this paper we address two issues relating to the application of preference functions There are also some real-valued functions, including the semantic collocation functions discussed in section  Four functions return non-zero scores on these analyses A fourth, SemColl, is a semantic collocation function As mentioned earlier, the preference score is a weighted sum of a set of preference functions: Each preference function fj takes a complete QLF representation qi as input, returning a numerical score sij, the overall preference score being computed by summing over the product of function scores with their associated scaling factors cj: The training process begins by analysing the corpus sentences and computing, for each analysis of each sentence, the training score of the analysis with respect to the manually-approved skeletal tree and the (unscaled) values of the preference functions applied to that analysis The relativised training score is the distance function with respect to which the first stage of scaling factor calculation takes place It can be seen that the relativised results of our hypothetical preference function are a perfect predictor of relativised training score.