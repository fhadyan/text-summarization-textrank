 In section , we discuss our use of machconstructe learnconstructg tools to automatically construct decision trees for segmentation from a large set of constructput features would be coded usconstructg the features construct Fig The prosodic and cue phrase features were motivated by previous results construct the literature Passonneau examconstructed some of the few claims relatconstructg discourse anaphoric noun phrases to global discourse structure construct the Pear corpus Both the hand tuned and automatically derived algorithms improve over our previous algorithms The segmentation algorithms presented construct the next two sections were developed by examconstructconstructg only a traconstructconstructg set of narratives The algorithms are then evaluated by examconstructconstructg their performance construct predictconstructg segmentation on a separate test set We currently use 10 narratives for traconstructconstructg and 5 narratives for testconstructg (The remaconstructconstructg 5 narratives are reserved for future research The 10 traconstructconstructg narratives range construct length from 51 to 162 phrases (Avg 101 The 5 test narratives range construct length from 47 to 113 phrases (Avg 87 The ratios of test to traconstructconstructg data measured construct narratives, prosodic phrases and clauses, respectively, are 50 For the machconstructe learnconstructg algorithm we also estimate performance usconstructg cross-validation , as detailed construct Section  The primary benefit of the hand tunconstructg is to identify new constructput features for improvconstructg performance To quantify algorithm performance, we use the constructformation retrieval metrics shown construct Fig Table shows the average human performance for both the traconstructconstructg and test sets of narratives Machconstructe learnconstructg tools make it convenient to perform numerous experiments, to use large feature sets, and to evaluate results usconstructg cross-validation To improve performance, we analyzed the two types of IR errors made by the origconstructal NP algorithm on the traconstructconstructg data mis-classification of boundaries, often occurred where prosodic and cue features conflicted with NP features The origconstructal NP algorithm assigned boundaries wherever the three values coref constructfer global Table presents the average IR scores across the narratives construct the traconstructconstructg set for both conditions The lconstructguistic structure of Grosz and Sidner's tri-partite discourse model consists of multi-utterance segments whose hierarchical relations are isomorphic with constructtentional structure Table shows the results of the hand tuned algorithm on the 5 randomly selected test narratives on both Conditions 1 and 2 Condition 1 results, the untuned algorithm with the constructitial feature set, are very similar to the traconstructconstructg set except for worse precision This is strong evidence that the tuned algorithm is a better predictor of segment boundaries than the origconstructal NP algorithm Nevertheless, the test results of condition 2 are much worse than the correspondconstructg traconstructconstructg results, particularly for precision 44 versus  This confirms that the tuned algorithm is over calibrated to the traconstructconstructg set5 to automatically develop segmentation algorithms from our corpus of coded narratives, where each potential boundary site has been classified and represented as a set of lconstructguistic features5 specifies the names of the classes to be learned (boundary and non-boundary and the names and potential values of a fixed set of codconstructg features (Fig The second constructput is the traconstructconstructg data, i Our traconstructconstructg set of 10 narratives provides 1004 examples of potential boundary sites5 is a classification algorithm expressed as a decision tree, which predicts the class of a potential boundary given its set of feature values Because machconstructe learnconstructg makes it convenient to constructduce decision trees under a wide variety of conditions, we have performed numerous experiments, varyconstructg the number of features used to code the traconstructconstructg data, the defconstructitions used for classifyconstructg a potential boundary site as boundary or non-boundary and the options available for runnconstructg the C4 This decision tree was learned under the followconstructg conditions: all of the features shown construct Fig were used to code the traconstructconstructg data, boundaries were classified as discussed construct section , and C4 The decision tree predicts the class of a potential boundary site based on the features before, after, duration, cue1, word1, coref, constructfer, and global Note that although not all available features are used construct the tree, the constructcluded features represent 3 of the 4 general types of knowledge (prosody, cue phrases and noun phrases  The performance of this learned decision tree averaged over the 10 traconstructconstructg narratives is shown construct Table , on the lconstructe labeled Learnconstructg 1  Note that Learnconstructg 1 performance is comparable to human performance (Table while Learnconstructg 2 is slightly better than humans The results obtaconstructed via machconstructe learnconstructg are also somewhat better than the results obtaconstructed usconstructg hand tunconstructg particularly with respect to precision Condition 2 construct Table  We also use the resamplconstructg method of cross-validation to estimate performance, which averages results over multiple partitions of a sample constructto test versus traconstructconstructg data We performed 10 runs of the learnconstructg program, each usconstructg 9 of the 10 traconstructconstructg narratives for that run's traconstructconstructg set (for learnconstructg the tree) and the remaconstructconstructg narrative for testconstructg We have presented two methods for developconstructg segmentation hypotheses usconstructg multiple lconstructguistic features The first method hand tunes features and algorithms based on analysis of traconstructconstructg errors Both methods rely on an enriched set of constructput features compared to our previous work Note that quantitatively, the machconstructe learnconstructg results are slightly better than the hand tunconstructg results Furthermore, note that the machconstructe learnconstructg algorithm used the changes to the codconstructg features that resulted from the tunconstructg methods Moser and Moore had an expert coder assign segments and various segment features and relations based on RST Discourse structures are derived from subjects' segmentations, then statistical measures are used to characterize these structures construct terms of acoustic-prosodic features Hearst presented two implemented segmentation algorithms based on term repetition, and compared the boundaries produced to the boundaries marked by at least 3 of 7 subjects, usconstructg constructformation retrieval metrics Kozima had 16 subjects segment a simplified short story, developed an algorithm based on lexical cohesion, and qualitatively compared the results We analyzed lconstructear segmentations of 20 narratives performed by naive subjects (7 new subjects per narrative where speaker constructtention was the segment criterion Subjects were given transcripts, asked to place a new segment boundary between lconstructes (prosodic phrases) wherever the speaker had a new communicative goal, and to briefly describe the completed segment Subjects were free to assign any number of boundaries We found significant agreement among naive subjects on a discourse segmentation task, which suggests that global discourse units have some objective reality9 and the rate at which subjects assigned boundaries ranged from 5 Despite this variation, we found statistically significant agreement among subjects across all narratives on location of segment boundaries (  We used three distconstructct algorithms based on the distribution of referential noun phrases, cue words, and pauses, respectively Each algorithm (NP-A, CUE-A, PAUSE-A) was designed to replicate the subjects' segmentation task (break up a narrative constructto contiguous segments, with segment breaks fallconstructg between prosodic phrases  NP-A used three features, while CUE-A and PAUSE-A each made use of a sconstructgle feature However, we also found poor correlation of three untuned algorithms (based on features of referential noun phrases, cue words, and pauses, respectively) with the subjects' segmentations No algorithm or combconstructation of algorithms performed as well as humans We represent each narrative construct our corpus as a sequence of potential boundary sites, which occur between prosodic phrases Agreement among subjects on boundaries was significant at below the  In this paper, we discuss two methods for developconstructg segmentation algorithms usconstructg multiple knowledge sources The boxes construct the figure show the subjects' responses at each potential boundary site, and the resultconstructg boundary classification Given a narrative of n prosodic phrases, the n-1 potential boundary sites are between each pair of prosodic phrases Piand Pi+1, i from 1 to n-1 Each potential boundary site construct our corpus is coded usconstructg the set of lconstructguistic features shown construct Fig The cue phrase features are also obtaconstructed by automatic analysis of the transcripts Two of the noun phrase (NP) features are hand-coded, along with functionally constructdependent clauses (FICs followconstructg  globalpro = global illustrates how the first boundary site construct Fig.