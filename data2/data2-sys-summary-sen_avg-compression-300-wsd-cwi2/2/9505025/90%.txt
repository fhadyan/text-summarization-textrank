 ride be coded using the features in Fig The prosodic and cue phrase features were motivated by previous results in the literature Passonneau examined some of the few claims relating discourse anaphoric noun phrases to global discourse structure in the Pear corpus The segmentation algorithms presented in the next two sections were developed by examining only a training set of narratives We currently use 10 narratives for training and 5 narratives for testing The ratios of test to training data measured in narratives, prosodic phrases and clauses, respectively, are 50 For the machine learning algorithm we also estimate performance using cross-validation , as detailed in Section  To quantify algorithm performance, we use the information retrieval metrics shown in Fig Table shows the average human performance for both the training and test sets of narratives mis-classification of boundaries, often occurred where prosodic and cue features conflicted with NP features The original NP algorithm assigned boundaries wherever the three values coref infer global Condition 1 results, the untuned algorithm with the initial feature set, are very similar to the training set except for worse precision5 to automatically develop segmentation algorithms from our corpus of coded narratives, where each potential boundary site has been classified and represented as a set of linguistic features Our training set of 10 narratives provides 1004 examples of potential boundary sites5 is a classification algorithm expressed as a decision tree, which predicts the class of a potential boundary given its set of feature values The decision tree predicts the class of a potential boundary site based on the features before, after, duration, cue1, word1, coref, infer, and global We have presented two methods for developing segmentation hypotheses using multiple linguistic features The first method hand tunes features and algorithms based on analysis of training errors Both methods rely on an enriched set of input features compared to our previous work Kozima had 16 subjects segment a simplified short story, developed an algorithm based on lexical cohesion, and qualitatively compared the results Subjects were free to assign any number of boundaries Despite this variation, we found statistically significant agreement among subjects across all narratives on location of segment boundaries (  We used three distinct algorithms based on the distribution of referential noun phrases, cue words, and pauses, respectively NP-A used three features, while CUE-A and PAUSE-A each made use of a single feature However, we also found poor correlation of three untuned algorithms (based on features of referential noun phrases, cue words, and pauses, respectively) with the subjects' segmentations Each potential boundary site in our corpus is coded using the set of linguistic features shown in Fig globalpro = global.