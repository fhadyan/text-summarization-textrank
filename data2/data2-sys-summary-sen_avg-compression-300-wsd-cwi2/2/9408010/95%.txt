 The data contains about 19,000different direct object tokens, about 10,000 different verb tokens and about 140,000 different token pairs We use of token data as training and token rest as testing data The automaton tokenn outputs a sequence of verb-object pairs, which constitute our training and testing data Given tokense probability estimates pG(yl|xk token likelihood FMLof token training data, e token probability of token training data being generated by our probability estimates pG(yl|xk measures how well token training data is represented by token estimates and can be used as optimisation criterion (  In token following, we will derive an optimisation function FML in terms of frequency counts observed in token training data It divides token data into N-1 samples as retained part and only one sample as held-out part Let Ti denote token data without token pair (X[i Y[i and pG,Ti(yl|xk) token probability estimates based on a given classification G and training corpus Ti75 during clustering.