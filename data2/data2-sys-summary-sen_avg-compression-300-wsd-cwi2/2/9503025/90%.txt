 Word vectors reflecting vector meanings are expected to enable numerical approaches to semantics For the vector sense disambiguation based on the context similarity, co-occurrence vectors from the 1987 Wall Street Journal (20M total vectors) was advantageous over distance vectors from the Collins English Dictionary ( head vectors + definition vectors  For learning or meanings from example vectors, distance vectors gave remarkably higher precision than co-occurrence vectors ) is used to measure the distance between vectors The vector dictionary is thus linked to the vectors book, vector, language, and alphabetical The vectors in Fig using co-occurrence statistics We used the same set of origin vectors as for the distance vectors Co-occurrence Vector With WSD, the precision by using co-occurrence vectors from a 20M vectors corpus was higher than by using distance vectors from the CED The results using distance vectors are shown by dots ( and using co-occurrence vectors from the 1987 WSJ (20M vectors) by circles (  A context size (x-axis) of, for example, 10 means 10 vectors before the target vector and 10 vectors after the target vector Corpus size (for co-occurrence vectors) Figure shows the change in disambiguation precision as the corpus size for co-occurrence statistics increases from 200 vectors to 20M vectors.