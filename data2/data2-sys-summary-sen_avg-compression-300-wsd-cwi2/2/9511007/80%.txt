 Word similarity appears to be one promising way to solve the problem: the behavior of a similarity is approximated by smoothing its observed behavior together with the behavior of similaritys to which it is similar This paper has presented a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content In ongoing work, I am currently exploring the application of taxonomically-based semantic similarity in the disambiguation of similarity senses  More recently, Sussna has explored using similarity of similarity senses based on WordNet for the same purpose In this paper, I describe an alternative way to evaluate semantic similarity in a taxonomy, based on the notion of information content Section sets up the probabilistic framework and defines the measure of semantic similarity in information-theoretic terms; Section presents an evaluation of the similarity measure against human similarity judgments, using the simple edge-counting method as a baseline; and Section discusses related work Intuitively, one key to the similarity of two concepts is the extent to which they share information in common, indicated in an IS-A taxonomy by a highly specific concept that subsumes them both Rada et al This quantitative characterization of information provides a new way to measure semantic similarity The more information two concepts share in common, the more similar they are, and the information shared by two concepts is indicated by the information content of the concepts that subsume them in the taxonomy Notice that although similarity is computed by considering all upper bounds for the two concepts, the information measure has the effect of identifying minimal upper bounds, since no class is less informative than its superordinates In practice, one often needs to measure similarity similarity, rather than concept similarity Here, the similarity similarity is judged by taking the maximal information content over all concepts of which both similaritys could be an instance For example, Figure illustrates how the similarity of similaritys nickel and gold would be computed: the information content would be computed for all classes subsuming any pair in the cross product of { NICKEL, NICKEL and { GOLD, GOLD and the information content of the most informative class used to quantify the similarity of the two similaritys Although there is no standard way to evaluate computational measures of semantic similarity, one reasonable way to judge would seem to be agreement with human similarity ratings This can be assessed by using a computational similarity measure to rate the similarity of a set of similarity pairs, and looking at how well its ratings correlate with human ratings of the same pairs For purposes of evaluation, three computational similarity measures were used The first is the similarity measurement using information content proposed in the previous section It simply ensures that the value can be interpreted as a similarity value, with high values indicating similar similaritys Table summarizes the experimental results, giving the correlation between the similarity ratings and the mean ratings reported by Miller and Charles The similarity ratings by item are given in Table  The experimental results in the previous section suggest that measuring semantic similarity using information content provides quite reasonable results, significantly better than the traditional method of simply counting the number of intervening IS-A links One problem is that, like simple edge counting, the measure sometimes produces spuriously high similarity measures for similaritys on the basis of inappropriate similarity senses For example, Table shows the similarity similarity for several similaritys with tobacco However, the example illustrates a more general concern: in measuring similarity between similaritys, it is really the relationship among similarity senses that matters, and a similarity measure should be able to take this into account This measure of similarity takes more information into account than the previous one: rather than relying on the single concept with maximum information content, it allows each class to contribute information content according to the value of  They have defined a measure resembling information content, but using the normalized path length between the two concepts being compared rather than the probability of a subsuming concept.