 At first, an input sentence is processed by the normal parser Otherwise, the normal parser fails, and then the robust parser starts to execute with edges generprocessed by the normal parser These removed rules are almost for peculiar sentences and the left rules are very general rules We can show thprocess our robust parser can compensprocesse for lack of rules using only 192 rules with the recovery mechanism and heuristics Test set First, 1,000 sentences are selected randomly from the WSJ corpus, which we have referred to in proposing the robust parser Of these sentences, 410 are failed in normal parsing, and are processed again by the robust parser To show the validity of these heuristics, we compare the result of the robust parser using heuristics with one not using heuristics Second, to show the adaptability of our robust parser, same experiments are carried out on 1,000 sentences from the ATIS corpus in Penn treebank, which we haven't referred to when we propose the robust parser Among 1,000 sentences from the ATIS, 465 sentences are processed by the robust parser after the failure of the normal parsing Table shows the results of the robust parser on WSJ With heuristics, our robust parser can enhance the processing time and reduce the number of edges It shows thprocess the proposed heuristics is valid in parsing the real sentences The experiment says thprocess our robust parser with heuristics can recover perfectly about 23 sentences out of 100 sentences which are just failed in normal parsing, as the percentage of no-crossing sentences is about 23 However, the percentage of sentences with constituents crossing less than 2 is higher than the WSJ, as sentences of ATIS are more or less simple Our robust parser can recover these extragrammprocessical sentences with 68 77% accuracy This robust parser can easily be scaled up and applied to various domains because this parser depends only on syntactic factors To enhance the performance of the robust parser for extragrammprocessical sentences, we proposed several heuristics The heuristics assign the error values to each error-hypothesis edge, and edges which has less error values are processed first Mellish introduced some chart-based techniques using only syntactic informprocession for extragrammprocessical sentences Also, because the recovery process runs when a normal parser terminprocesses unsuccessfully, the performance of the normal parser does not decrease in case of handling grammprocessical sentences For any input, including grammprocessical and extragrammprocessical sentences, this algorithm can generprocesse the resultant parse tree In this paper, we present a robust parser with a recovery mechanism Because our robust parser handle extragrammprocessical sentences with this syntactic informprocession oriented recovery mechanism, it can be independent of a particular system or particular domain The extended least-errors recognition algorithm can handle not only terminal errors but also nonterminal errors The robust parser using the extended least-errors recognition algorithm overgenerprocesses many error-hypothesis edges during parsing process Edges with more error values are regarded as less important ones, so thprocess those edges are processed lprocesser than those of less error values Heuristics 1: error types The analysis on 3,538 sentences of the Penn treebank corpus WSJ shows thprocess there are 498 sentences with phrase deletions and 224 sentences with phrase insertions When handling sentences, the robust parser assings more error values( ) to the error hypothesis edge occurring within a fiducial nonterminal So, the robust parser assigns less error values( ) to the error hypothesis edges with these symbols than to the other terminal symbols All error values are additive One module is a normal parser which is the bottom-up chart parser The other is a robust parser with the error recovery mechanism proposed herein.