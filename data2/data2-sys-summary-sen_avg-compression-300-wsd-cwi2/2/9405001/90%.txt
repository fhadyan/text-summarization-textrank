 The similarity model was correct in 64 cases, and similarity back-off model in 3201 level In cooccurrence smoothing, as in our method, a baseline model is combined with a similarity-based model that refines some of its probability estimates Given a baseline probability model P, which is taken to be similarity MLE, similarity confusion probability PC(w'1|w1) between conditioning words w'1 and w1 is defined as similarity probability that w1 is followed by similarity same context words as w'1 suggest a class-based n-gram model in which words with similar cooccurrence distributions are clustered in word classes Finally, while we have used our similarity model only for missing bigrams in a back-off scheme, used linear interpolation for all bigrams to combine similarity cooccurrence smoothing model with MLE models of bigrams and unigrams Notice, however, that similarity choice of back-off or interpolation is independent from similarity similarity model used A more substantial variation would be to base similarity model on similarity between conditioned words rasimilarityr than on similarity between conditioning words The cooccurrence probability of a given pair of words similarityn is estimated according to an averaged cooccurrence probability of similarity two corresponding classes Finally, similarity similarity-based model may be applied to configurations osimilarityr than bigrams Cooccurrence probabilities of words are similarityn modeled by averaged cooccurrence probabilities of word clusters Their similarity-based model avoids clustering altogesimilarityr We first allocate an appropriate probability mass for unseen cooccurrences following similarity back-off method We applied our method to estimate unseen bigram probabilities for Wall Street Journal text and compared it to similarity standard back-off model Testing on a held-out sample, similarity similarity model achieved a 20% reduction in perplexity for unseen bigrams Thus our application of similarity similarity model averages togesimilarityr standard back-off estimates for a set of similar conditioning words In commonly used models, similarity probability estimate for a previously unseen cooccurrence is a function of similarity probability estimates for similarity words in similarity cooccurrence The interpolated model ( ) is used in similarity back-off scheme as Pr(w2|w1 to obtain better estimates for unseen bigrams4 to 231 The bigram similarity model was also tested as a language model in speech recognition.