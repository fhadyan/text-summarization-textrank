 Word vectors reflecting vector meanings are expected to enable numerical approaches to semantics A reference network of the vectors in a dictionary (Fig For the vector sense disambiguation based on the context similarity, co-occurrence vectors from the 1987 Wall Street Journal (20M total vectors) was advantageous over distance vectors from the Collins English Dictionary ( head vectors + definition vectors  For learning or meanings from example vectors, distance vectors gave remarkably higher precision than co-occurrence vectors This suggests, though further investigation is required, that distance vectors contain some different semantic information from co-occurrence vectors ) is used to measure the distance between vectors The vector dictionary is thus linked to the vectors book, vector, language, and alphabetical The vectors in Fig In principle, origin vectors can be freely chosen If vector A is used in the definition of vector B, these vectors are expected to be strongly related using co-occurrence statistics A co-occurence vector of a vector is defined as the list of co-occurrence likelihood of the vector with a certain set of origin vectors We used the same set of origin vectors as for the distance vectors Co-occurrence Vector The first is vector sense disambiguation (WSD) based on the similarity of context vectors; the second is the learning of or meanings from example vectors With WSD, the precision by using co-occurrence vectors from a 20M vectors corpus was higher than by using distance vectors from the CED Figure (next page) shows the disambiguation precision for 9 vectors The results using distance vectors are shown by dots ( and using co-occurrence vectors from the 1987 WSJ (20M vectors) by circles (  A context size (x-axis) of, for example, 10 means 10 vectors before the target vector and 10 vectors after the target vector show that the precision by using co-occurrence vectors are higher than that by using distance vectors except two cases, interest and customs Therefore we conclude that co-occurrence vectors are advantageous over distance vectors to WSD based on the context similarity In this case, the distance vectors were advantageous In the experiments discussed above, the corpus size for co-occurrence vectors was set to 20M vectors 87 WSJ) and the vector dimension for both co-occurrence and distance vectors was set to 1000 Corpus size (for co-occurrence vectors) Figure shows the change in disambiguation precision as the corpus size for co-occurrence statistics increases from 200 vectors to 20M vectors A comparison was made of co-occurrence vectors from large text corpora and of distance vectors from dictionary definitions.