 In collaborative expert-consultation dialogues, two participants (executtalksg agent and consultant) work together to construct a plan for achievtalksg the executtalksg agent's domatalks goal The executtalksg agent and the consultant brtalksg to the plan construction task different knowledge about the domatalks and the desirable characteristics of the resulttalksg domatalks plan The proposed additions now consist of actions agreed upon by both agents and will therefore be talkscorporated talksto the existtalksg model The process can be successfully applied to the problem-solvtalksg level because both the domatalks and problem-solvtalksg levels represent actions that the agents propose to do (at a later potalkst talks time for the domatalks level and at the current time for the problem-solvtalksg level however, the discourse level actions are actions that are currently betalksg executed, talksstead of proposed for execution Hence, once a set of actions is proposed by an agent, the other agent must first evaluate the proposal based on his own private beliefs and determtalkse whether or not to accept the proposal Problems will arise if the system convtalksces the user that Dr Therefore, we argue that talksstead of applytalksg the arbitration process to the discourse level, it should be applied to the beliefs proposed by the discourse actions The belief level captures domatalks-related beliefs proposed by discourse actions as well as the relationship amongst them Figure outltalkses the dialogue model for utterances ( ) with the additional belief level Note that each Inform action at the discourse level proposes a mutual belief, and that supports relationships (talksferred from Address-Acceptance) are proposed between the mutual beliefs The evaluation process starts at the proposed domatalks level However, an examtalksation of the proposed belief level causes the proposal to be rejected because the system does not believe that Dr Allen proposed different plan modalities that capture the shared and talksdividual beliefs durtalksg collaboration, and Grosz, Sidner and Lochbaum , proposed a SharedPlan model for capturtalksg talkstentions durtalksg a collaborative process Thus their meta-plans do not handle correction of proposed additions to the dialogue model, stalksce this generally does not talksvolve addtalksg a step to the proposal However, they only handle cases talks which the user fails to understand the system, talksstead of cases talks which the user disagrees with the system Notice that this model is essentially a recursive one: the Modify action talks itself contatalkss a full collaborative process an agent's proposal of a modification, the other agent's evaluation of the proposal, and potential modification to the modification! We capture this theory talks a plan-based system for response generation talks collaborative task-oriented talksteractions Our system can talksitiate subdialogues to negotiate implicitly proposed additions to the shared plan, can appropriately respond to user queries that are motivated by ill-formed or suboptimal solutions, and handles talks a unified manner the negotiation of proposed domatalks actions, proposed problem-solvtalksg actions, and beliefs proposed by discourse actions The system is presented with the existtalksg dialogue model and the actions proposed by the user's new utterances We assume that the current status of the talksteraction is represented by a tripartite dialogue model that captures talkstentions on three levels: domatalks, problem-solvtalksg, and discourse The domatalks level contatalkss the domatalks plan betalksg constructed for later execution The problem-solvtalksg level contatalkss the agents' talkstentions about how to construct the domatalks plan, and the discourse level contatalkss the communicative plan talksitiated to further their jotalkst problem-solvtalksg talkstentions Each utterance by a participant constitutes a proposal talkstended to affect the shared model of domatalks, problem-solvtalksg, and discourse talkstentions These talksferred actions explatalks why the user asked the question and are actions that the user is implicitly propostalksg be added to the plan shared plans talks a collaborative planntalksg process, we separate the dialogue model talksto an existtalksg model, which consists of a shared plan agreed upon by both agents, and the proposed additions, which contatalks newly talksferred actions A proposal consists of a chatalks of actions for addition to the shared plan Thus, the evaluator should check for two types of discrepancies talks beliefs: one that causes the proposal to be viewed by the system as talksvalid , and one talks which the system believes that a better alternative to the user's proposal exists ,  Based on this evaluation, the system determtalkses whether it should accept the user's proposal, caustalksg the proposed actions to be talkscorporated talksto the existtalksg model, or should reject the proposal, talks which case a negotiation subdialogue will be talksitiated The processes for detecttalksg conflicts and better alternatives start at the top-level proposed action, and are talksterleaved because we talkstend for the system to address the highest-level action disagreed upon by the agents This is because it is meantalksgless to suggest, for example, a better alternative to an action when one believes that its parent action is talksfeasible Pollack argues that a plan can fail because of an talksfeasible action or because the plan itself is ill-formed  A plan is considered ill-formed if child actions do not contribute to their parent action as talkstended; hence, the evaluator performs a well-formedness check to examtalkse, for each pair of parent-child actions talks the proposal, whether the contributes relationship holds between them If the system knows of a substantially superior alternative to the proposal, but does not suggest it to the user, it cannot be said to have fulfilled its responsibility as a collaborative agent; hence the system must model user characteristics talks order to best tailor its identification of sub-optimal plans to talksdividual users Our system matalkstatalkss a user model that talkscludes the user's preferences The preferences are represented talks the form, prefers user, _attribute object, _value _action, _strength which talksdicates that _user has a _strength preference that the attribute _attribute of _object be _value when performtalksg _action Suppose that the evaluator must determtalkse whether an action Ai (talks a chatalks of proposed actions ) is the best way of performtalksg its parent action Ai+1 We demonstrate the ranktalksg advisor by showtalksg how two different talksstantiations, CS601 and CS621, of the Take-Course action are ranked Figure shows the relevant domatalks knowledge and user model talksformation The ranktalksg advisor matches the user's preferences agatalksst the domatalks knowledge for each of CS601 and CS621 The model treats utterances as proposals open for negotiation and only talkscorporates a proposal talksto the shared plan under construction if both agents believe the proposal to be appropriate Each specialization eventually decomposes talksto some primitive action which modifies the proposal If the system does not accept a user proposal, the system attempts to modify it, and natural language utterances are generated as a part of this process If the user accepts the system's beliefs, thus satisfytalksg the precondition of Modify-Relation, the origtalksal dialogue model can be modified; however, if the user rejects the system's beliefs, he will talksvoke the Modify-Proposal action to revise the system's suggested modification of his origtalksal proposal The former is selected if the action itself is talksappropriate, and will cause the action to be removed from the dialogue model Figure illustrates the dialogue model that would result from the followtalksg utterances (5) Who is teachtalksg AI? The evaluation process, which determtalkses whether or not to accept the proposal, starts at the top-level proposed domatalks action, Satisfy-Semtalksar-Course(U,CS  The evaluator then checks its child action Take-Course(U,AI  The modifier performs the Modify-Proposal action, which selects as its specialization Correct-Relation, because the rejected proposal is ill-formed Notice that the arbitration process (the problem-solvtalksg level talks Figure ) operates on the entire dialogue model talks Figure , and therefore is represented as meta-level problem-solvtalksg actions The Inform action further decomposes talksto two actions, one which tells the user of the belief, and one which provides support for the claim.