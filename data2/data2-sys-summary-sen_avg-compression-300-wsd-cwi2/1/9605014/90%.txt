 We then constructed a number of thesauri based on these data, using our method We also extracted as our test data 172 (verb,noun1,prep,noun2) patterns from the data in the same corpus, which is not used in the training data `Word-Based `MLE-Thesaurus and `MDL-Thesaurus' respectively stand for using word-based estimates, using a thesaurus constructed by employing MLE, and using a thesaurus constructed by our method A method of constructing a thesaurus based on corpus data usually consists of the following three steps: (i) Extract co-occurrence data (e We have proposed a method of clustering words based on large corpus data Using a thesaurus constructed by our method can improve pp-attachment disambiguation results for his comments In this paper, extract assume that the observed data are generated by a model belonging to the class of models just described, and select a model which best explains the data MDL stipulates that the best probability model for given data is that model which requires the least code length for encoding of the model itself, as extractll as the given data relative to it We refer to the code length for the model as the `model description length' and that for the data the `data description length We apply MDL to the problem of estimating a model consisting of a pair of partitions as described above The model description length quantifies the simplicity (complexity) of a model, and the data description length quantifies the fit to the data Given a model M and data S, its total description length L(M) is computed as the sum of the model description length Lmod(M the description length of its parameters Lpar(M and the data description length Ldat(M  We artificially constructed a true model of word co-occurrence, and then generated data according to its distribution We then used the data to estimate a model (clustering words and measured the KL distance betextracten the true model and the estimated model Also, MLE tends to select a model overfitting the data, while MDL tends to select a model which is simple and yet fits the data reasonably extractll.