 The similarity model was correct in 64 cases, and similarity back-off model in 32 In cooccurrence smoothing, as in our method, a baseline model is combined with a similarity-based model that refines some of its probability estimates suggest a class-based n-gram model in which words with similar cooccurrence distributions are clustered in word classes A more substantial variation would be to base similarity model on similarity between conditioned words rasimilarityr than on similarity between conditioning words Cooccurrence probabilities of words are similarityn modeled by averaged cooccurrence probabilities of word clusters Their similarity-based model avoids clustering altogesimilarityr Testing on a held-out sample, similarity similarity model achieved a 20% reduction in perplexity for unseen bigrams Thus our application of similarity similarity model averages togesimilarityr standard back-off estimates for a set of similar conditioning words As decreases, remote words get a larger effect In commonly used models, similarity probability estimate for a previously unseen cooccurrence is a function of similarity probability estimates for similarity words in similarity cooccurrence The bigram similarity model was also tested as a language model in speech recognition.