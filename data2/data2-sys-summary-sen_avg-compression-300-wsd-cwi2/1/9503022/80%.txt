 Recently, there has been a growing interest in research on formalizing feature theory We will prove that these complexity results do not hold if we consider unification grammars that use these feature theories in addition to a constituent structure component First we will show, that the complexity of a unification grammar theory may be higher than the complexity of its feature theory and constituent structure components Second we will explain, that the complexity of a unification grammar may be lower than the complexity of the formalized feature theory In the remainder of this section we will show that the feature theory is simple So we may say that the algorithm solves the unification problem The first proof implies that the complexity of a feature theory does not provide an upper bound for the complexity of grammars using that feature theory Hence the algorithm FEATUREGRAPHSAT takes quadratic time, and thus shows that the feature theory is indeed simple The second proof implies that the complexity of a feature theory might not provide a lower bound for the complexity of grammars using that feature theory \t\t 3 ProofFrom , Proposition 5 ProofBy induction on the length of a cycle An novice in complexity theory might expect that a problem is not harder than the problem's hardest component However, combining problems may yield a problem that is harder than each of the problems when considered separately This restriction is called the `Off-line Parsability Constraint  From Johnson's work, we see that combining problems may change the complexity from decidable to undecidable We claim that combining problems may change also the complexity from tractable to intractable The claim shows that even under the Off-line Parsability Constraint the complexity of the feature theory still does not provide an upper bound on the complexity of the unification grammar In the next section we will present a fixed regular grammar Then we combine this regular grammar with the feature theory from Section into a unification grammar The next section contains the preliminaries on complexity theory and feature theory Many other regular grammars could be given for the same language However, the one presented, as will be seen later, is sufficient for our purposes here: that is, the reduction from SATISFIABILITY There are multiple formalisms for unification grammars Most of these formalisms distinguish two components: a constituent structure and a feature graph Table contains the grammar rules of unification grammar G These formalisms describe the use of feature theory in computational linguistics In Section , we introduce a simple feature theory: a feature theory with only reentrance In Section , we present a unification grammar that uses this simple feature theory Fact 4 We show that the recognition problem of this grammar is harder than the unification problem of the feature theory and the recognition problem of the constituent structure component This T derives in b steps Finally, this A derives in csteps Both the recognition problem of this regular grammar, and the satisfiability problem of this feature theory take polynomial time In Section , we explain why the recognition problem of a unification grammar might be of lower complexity than the unification problem of the feature theory First, we will give the reduction from the NP-complete problem SAT to the recognition problem of G ProofBy induction on the construction of SAT formulas In complexity theory one tries to determine the complexity of problems One substring wm: Let S0 = S derive wm S ( where k depends on the assignment g: The non-terminal S derives the empty string in one step Thus the feature structure associated with S is  The feature structure associated with T is the unification of and the feature structure associated with S: where if , and if  The feature structure associated with S0 is None of the unifications fails, and thus S derives wm suppose that is in the language generated by G By fact , where  Obviously, if, and only if,  Because S derives w, the feature structure associated with S does not contain contradicting information: 3) follows This completes the second subproof Lemma proves that this reduction f is computable in polynomial time An additional NP upper bound is proven for an arbitrary string and grammar, which results in an NP-complete recognition problem Lemma 4 The NP upper bound is proven as follows The second check is performed by the algorithm FEATUREGRAPHSAT from Section  Clearly, both checks only take polynomial time For instance, let problem A be the complement of problem B In some specific situations, however, these reductions do not exist Consider for instance the class of grammars that generate a finite language The combination of a feature theory with a grammar from this class yields a unification grammar that generates a finite language Obviously, the recognition problem of this unification grammar does not depend on the unification problem of the feature theory The feature theory does not provide a lower bound if the unification grammar uses only a fragment of the feature theory This happens when the unification grammar formalism restricts the unification For instance, the unification grammar formalism may demand that feature structures are unified at the outermost attributes This demand implies that the size of the feature structures that appear in the fixed unification grammar is bounded Consequently, there have to be feature structures in the feature theory that cannot be encoded by the unification grammar One may object that the obligatory unification at the outermost attribute should be incorporated in the formalization of the feature theory However, there is no predefined way to construct unification grammars from a feature theory and a grammar component So, there may be many blurred restrictions on the unification These blurred restrictions are the cause that the formalization of the feature theory may be too expressive and that the unification grammar uses only a fragment of the feature theory The two examples show that not in all situations the complexity of the unification problem of the feature theory provides a lower bound for the complexity of the recognition problem of the unification grammar In this paper, we have assessed the complexity results of formalizations that intend to describe feature theories in computational linguistics These formalizations do not take the constituent structure component of unification grammars into account An indirect way to determine the lower bound complexity of a problem is the reduction A reduction from some problem A to some problem B maps instances of problem A onto instances of problem B Suppose problem B is a problem with unknown complexity Hence B is also an NP-hard problem The feature theories that are used in computational linguistics are contained in unification grammars This operation is called unification These unification grammars consist of constituent structure components, and feature theories In this section we will present a simple feature theory The feature theory contains reentrance, but no negation or disjunction Although this feature theory is simple, it contains many aspects from other feature theories In addition, Section shows that combining this simple feature theory with a simple constituent structure component results in a difficult unification grammar This part should convince the reader that the feature theory is indeed simple Although a universal feature theory does not exist, there is a general understanding of its objects We claim that the complexity results from the formalisms do no longer hold when a feature theory and a constituent structure component are combined into a unification grammar The object of feature theories are abstract linguistic objects, e.