 Recently, there has been a growing interest in research on formalizing feature theory We will prove that these complexity results do not hold if we consider unification grammars that use these feature theories in addition to a constituent structure component However for our purposes it suffices to interpret the formulas as feature graphs First we will show, that the complexity of a unification grammar theory may be higher than the complexity of its feature theory and constituent structure components Second we will explain, that the complexity of a unification grammar may be lower than the complexity of the formalized feature theory Hence we can view the algorithm as a unification algorithm The unification of A and B is denoted by  In the remainder of this section we will show that the feature theory is simple The algorithm FEATUREGRAPHSAT can be used to determine whether two abstract objects can be unified: if the formulas and describe abstract objects, then describes their unification if, and only if, the unification exists So we may say that the algorithm solves the unification problem The algorithm FEATUREGRAPHSAT below determines syntactically whether a formula is satisfiable in some feature algebra The first proof implies that the complexity of a feature theory does not provide an upper bound for the complexity of grammars using that feature theory Hence the algorithm FEATUREGRAPHSAT takes quadratic time, and thus shows that the feature theory is indeed simple The second proof implies that the complexity of a feature theory might not provide a lower bound for the complexity of grammars using that feature theory Therefore, we argue that if one is interested in the complexity of unification grammars that are used in grammars, one should look at the complexity of these unification grammars as a whole \t\t 3 ProofFrom , Proposition 5 No insight in the complexity of a unification grammar is gained by looking only at the complexity of its components in isolation2 A simplified set of primitive formulas S is acyclic if, and only if, S does not contain a sequence of formulas and (  ProofBy induction on the length of a cycle An novice in complexity theory might expect that a problem is not harder than the problem's hardest component However, combining problems may yield a problem that is harder than each of the problems when considered separately This restriction is called the `Off-line Parsability Constraint  From Johnson's work, we see that combining problems may change the complexity from decidable to undecidable We claim that combining problems may change also the complexity from tractable to intractable The claim shows that even under the Off-line Parsability Constraint the complexity of the feature theory still does not provide an upper bound on the complexity of the unification grammar In the next section we will present a fixed regular grammar Then we combine this regular grammar with the feature theory from Section into a unification grammar The regular language that we want to recognize is  The next section contains the preliminaries on complexity theory and feature theory Many other regular grammars could be given for the same language However, the one presented, as will be seen later, is sufficient for our purposes here: that is, the reduction from SATISFIABILITY Obviously, the recognition problem of fixed regular grammar takes linear time There are multiple formalisms for unification grammars Most of these formalisms distinguish two components: a constituent structure and a feature graph Table contains the grammar rules of unification grammar G These formalisms describe the use of feature theory in computational linguistics In Section , we introduce a simple feature theory: a feature theory with only reentrance In Section , we present a unification grammar that uses this simple feature theory The following fact results from fact and the previous example, which showed that cannot be generated by G We show that the recognition problem of this grammar is harder than the unification problem of the feature theory and the recognition problem of the constituent structure component This T derives in b steps Finally, this A derives in csteps If , where , and , then there is a such that (d = a + b + c)and the feature structure is associated with T, where if l = p, and if  In the previous section we combined the regular grammar from Section and the feature theory from Section into a unification grammar G Both the recognition problem of this regular grammar, and the satisfiability problem of this feature theory take polynomial time However, we will prove that the recognition problem of the unification grammar G is NP-hard In Section , we explain why the recognition problem of a unification grammar might be of lower complexity than the unification problem of the feature theory First, we will give the reduction from the NP-complete problem SAT to the recognition problem of G Then we will show that this reduction is computable in polynomial time and answer preserving The reduction f is computable in linear time ProofBy induction on the construction of SAT formulas In complexity theory one tries to determine the complexity of problems One substring wm: Let S0 = S derive wm S ( where k depends on the assignment g: The non-terminal S derives the empty string in one step Thus the feature structure associated with S is  The feature structure associated with T is the unification of and the feature structure associated with S: where if , and if  The feature structure associated with S0 is None of the unifications fails, and thus S derives wm The complexity is measured by the amount of time and space needed to solve a problem suppose that is in the language generated by G By fact , where  Obviously, if, and only if,  Because S derives w, the feature structure associated with S does not contain contradicting information: 3) follows This completes the second subproof The previous lemma proves that the reduction f from SAT to the recognition problem of the unification grammar Gis answer preserving Lemma proves that this reduction f is computable in polynomial time Hence these two lemmas together prove that the recognition problem of the unification grammar G is NP-hard An additional NP upper bound is proven for an arbitrary string and grammar, which results in an NP-complete recognition problem Lemma 4 The NP upper bound is proven as follows The second check is performed by the algorithm FEATUREGRAPHSAT from Section  Clearly, both checks only take polynomial time So one would be tempted to answer the question above in the affirmative For instance, let problem A be the complement of problem B In some specific situations, however, these reductions do not exist Example(s) The feature theory does not provide a lower bound if the complexity of the recognition problem of the grammar component provides a lower bound for the complexity of the recognition problem of the unification grammar Consider for instance the class of grammars that generate a finite language The combination of a feature theory with a grammar from this class yields a unification grammar that generates a finite language Obviously, the recognition problem of this unification grammar does not depend on the unification problem of the feature theory Hence the lower bound complexity of this class of unification grammars is not provided by the complexity of the feature theory The feature theory does not provide a lower bound if the unification grammar uses only a fragment of the feature theory This happens when the unification grammar formalism restricts the unification For instance, the unification grammar formalism may demand that feature structures are unified at the outermost attributes This demand implies that the size of the feature structures that appear in the fixed unification grammar is bounded Consequently, there have to be feature structures in the feature theory that cannot be encoded by the unification grammar One may object that the obligatory unification at the outermost attribute should be incorporated in the formalization of the feature theory However, there is no predefined way to construct unification grammars from a feature theory and a grammar component So, there may be many blurred restrictions on the unification These blurred restrictions are the cause that the formalization of the feature theory may be too expressive and that the unification grammar uses only a fragment of the feature theory The two examples show that not in all situations the complexity of the unification problem of the feature theory provides a lower bound for the complexity of the recognition problem of the unification grammar In some special cases the complexity of the unification grammar may be lower than the complexity of the feature theory In this paper, we have assessed the complexity results of formalizations that intend to describe feature theories in computational linguistics These formalizations do not take the constituent structure component of unification grammars into account Thus the complexity results that have been achieved in the formalisms of feature theories are not immediately relevant for unification grammars used in computational linguistics There is a direct manner to determine the upper bound complexity of a problem, if there is an algorithm that solves the problem: determine the complexity of that algorithm An indirect way to determine the lower bound complexity of a problem is the reduction A reduction from some problem A to some problem B maps instances of problem A onto instances of problem B Suppose problem B is a problem with unknown complexity Let there be a reduction f from an NP-hard problem A to problem B The grammatical theories used in computational linguistics do not consist of bare feature theories Hence B is also an NP-hard problem A well-known NP-complete problem is SATISFIABILITY (SAT  The feature theories that are used in computational linguistics are contained in unification grammars Although there is no such thing as a universal feature theory, there is a general understanding of its abstract objects The properties of abstract objects can be combined to form new abstract objects This operation is called unification The unification of abstract objects combines all the properties of these abstract objects, provided that the properties are not contradictory These unification grammars consist of constituent structure components, and feature theories All kinds of additions to these rudiments of feature theory have been presented in the literature In this section we will present a simple feature theory The feature theory contains reentrance, but no negation or disjunction Although this feature theory is simple, it contains many aspects from other feature theories In addition, Section shows that combining this simple feature theory with a simple constituent structure component results in a difficult unification grammar In the first part of this section, we will formalize the notion of a feature theory This part should convince the reader that the feature theory is indeed simple Although a universal feature theory does not exist, there is a general understanding of its objects We claim that the complexity results from the formalisms do no longer hold when a feature theory and a constituent structure component are combined into a unification grammar The object of feature theories are abstract linguistic objects, e In this paper, we will focus on the complexity results that are obtained from formalizing feature theories.