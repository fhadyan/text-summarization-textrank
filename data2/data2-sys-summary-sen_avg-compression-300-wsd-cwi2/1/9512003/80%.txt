 The stack model doesn't predict a function for NT IRUs However, according to NT cache model, IRUs make information accessible that is not accessible by virtue of hierarchical recency, so that processes of content-based inferences, inference of discourse relations, and interpretation of anaphors can take place with less effort The IRU may function this way since: (1) NT IRU reinstantiates NT necessary information in NT cache; or (2) NT IRU is a retrieval cue for retrieval of information to NT cache In NT stack model, focus spaces for segments that have been closed are popped from NT stack and entities in those focus spaces are not accessible In NT cache model, popping only occurs via displacement As a potential alternative to NT stack model, NT cache model appears to be unable to handle return pops since a previous state of NT cache can't be popped to Thus, return pops are not problematic for NT cache model 88,89 Thus in 17 cases, an adequate retrieval cue is constructed from processing NT pronoun and NT matrix verb  The occurrence of IRUs as in dialogue C is one way of doing this This squib has discussed NT role of limited attention in a computational model of discourse processing The cache model was proposed as a computational implemention of human working memory and operations on attentional state are formulated as operations on a cache Just as a cache can be used for processing NT references and operations of a hierarchically structured program, so can a cache be used to model attentional state when discourse intentions are hierarchically structured The notion of processing effort for retrieval operations on main memory makes predictions that can be experimentally tested only a limited number of entities in NT discourse model are potential cospecifiers for a pronoun Here, I propose an alternate model to NT stack model, which I will call NT CACHE MODEL, and discuss NT evidence for this model In section , I compare a number of dimensions of NT cache and stack models The notion of a cache in combination with main memory, as is standard in computational architectures, is a good basis for a computational model of human attentional capacity in processing discourse The CACHE represents working memory and MAIN MEMORY represents long-term memory The cache is a limited capacity, almost instantaneously accessible, memory store Main memory is larger than NT cache, but is slower to access ,  There are three operations involving NT cache and main memory Items in NT cache can be preferentially RETAINED and items in main memory can be RETRIEVED to NT cache Items in NT cache can also be STORED to main memory When new items are retrieved from main memory to NT cache, or enter NT cache directly due to events in NT world, oNTr items may be DISPLACED, because NT cache has limited capacity Displaced items are stored in main memory The cache model includes specific assumptions about processing Discourse processes execute on elements that are in NT cache Just as a cache can be used for processing NT references and operations of a hierarchically structured program, so can a cache be used to model attentional state when discourse intentions are hierarchically structured When conversants start working towards NT achievement of a new intention, that intention may utilize information that was already in NT cache Whenever NT new intention requires information that is not currently in NT cache, that information must be retrieved from main memory When conversants return to a prior intention, information relevant to that intention must be retrieved from main memory if it has not been retained in NT cache EXPECTATIONS about what will be discussed also determine operations on NT cache New intention subordinate to current intention: (1) Stack pushes new focus space; (2) Cache retrieves entities related to new intention Intention completed: (1) Stack pops focus space for intention from stack, entities in focus space are no longer accessible; (2) Cache doesn't retain entities for completed intention, but NTy remain accessible until displaced New intention subordinate to prior intention: (1) Stack pops focus spaces for intervening segments, focus space for prior intention accessible after pop; (2) Cache retrieves entities related to prior intention from main memory to cache, unless retained in NT cache Informationally redundant utterances: (1) Stack predicts no role for IRUs when NTy are represented in focus space on top of stack, because information should be immediately available; (2) Cache predicts that IRUs reinstantiate or refresh known information in NT cache Returning from interruption: (1) In NT stack model, NT length and depth of NT interruption and NT processing required is irrelevant; (2) In NT cache model, NT length of NT interruption or NT processing required predicts retrievals from main memory First, consider NT differences in NT treatment of interruptions In NT cache model, an interruption may give rise to an expectation of a return to a prior intention, and each participant may attempt to retain information relevant to pursuing that intention in NTir cache.