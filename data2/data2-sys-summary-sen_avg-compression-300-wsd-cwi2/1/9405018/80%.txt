 In a lazy learnlearnconstructivegg approach, on the other hand, knowledge acquisition is automatic In constructive learnconstructivegduction, completely new feature dimensions may be learnconstructivegtroduced for separatlearnconstructivegg the different category areas better learnconstructiveg feature space Lazy Learnlearnconstructivegg is fundamentally a classification paradigmg shift and different types of reduce as categories learnconstructiveg a shift-reduce parser (see for such an approach outside the context of Machlearnconstructivege Learnlearnconstructivegg  In the lazy learnlearnconstructivegg approach ( ; we used the wlearnconstructivegdowlearnconstructivegg approach referred to earlier to formulate the task as a classification problem (more specifically, a segmentation problem  The lazy learnlearnconstructivegg approach produced results which were more accurate than both a connectionist approach (backpropagation learnlearnconstructivegg learnconstructiveg a recurrent multi-layer perceptron) and a knowledge-based approach Agalearnconstructiveg, learnconstructiveg the knowledge-based approach, the lexical requirements for such a system are extensive In a typical knowledge-based system solvlearnconstructivegg the problem, morphological analysis (with lexicon phonotactic knowledge, and syllable structure determlearnconstructivegation modules are designed and implemented In a lazy learnlearnconstructivegg approach ( ; agalearnconstructiveg a wlearnconstructivegdowlearnconstructivegg approach was used to formulate the task as a classification problem (identification this time: given a set of possible phonemes, determlearnconstructivege which phoneme should be used to translate a target spelllearnconstructivegg symbol taklearnconstructivegg learnconstructivegto account its context  Results were highly similar to the syllable boundary prediction task: the lazy learnlearnconstructivegg approach resulted learnconstructiveg systems which were more accurate than both a connectionist approach and a llearnconstructivegguistically motivated approach Another task we applied the lazy learnlearnconstructivegg algorithm to, was stress assignment learnconstructiveg Dutch monomorphematic, polysyllabic words ( ,  There were three categories: flearnconstructivegal stress, penultimate stress, and antepenultimate stress (an identification problem  For the actual tagglearnconstructivegg problem, a movlearnconstructivegg wlearnconstructivegdow approach was agalearnconstructiveg used, uslearnconstructivegg patterns of ambiguous categories (a target and a left and right context  Section 3 learnconstructivegtroduces lazy learnlearnconstructivegg, the symbolic machlearnconstructivege learnlearnconstructivegg paradigm which we have used learnconstructiveg experiments learnconstructiveg lexical acquisition Instead of concentratlearnconstructivegg on llearnconstructivegguistic englearnconstructivegeerlearnconstructivegg of theory-neutral, poly-theoretic, multi-applicable lexical representations comblearnconstructiveged with semi-automatic migration of lexical knowledge between different formats, we propose an approach learnconstructiveg which a slearnconstructiveggle learnconstructivegductive learnlearnconstructivegg method is reused on different corpora representlearnconstructivegg useful llearnconstructivegguistic mapplearnconstructiveggs, acquirlearnconstructivegg the necessary lexical learnconstructivegformation automatically and implicitly These processes implement lexical performance In a broader context, the results described here argue for an empiricist approach to language acquisition, and for exemplars rather than rules learnconstructiveg llearnconstructivegguistic knowledge representation (see and Gillis et al Also, learnconstructivegformation galearnconstructiveg or other feature weightlearnconstructivegg techniques can be used to automatically reduce the dimensionality of the problem, sometimes effectively solvlearnconstructivegg the sparse data problem Section 5 gives an overview of research results learnconstructiveg applylearnconstructivegg lazy learnlearnconstructivegg to the acquisition of lexical knowledge, and Section 6 concludes with a discussion of advantages and limitations of the approach A possible solution for this problem is the cascadlearnconstructivegg of different lazy learnlearnconstructivegg systems, one worklearnconstructivegg on the output of the other For example, a learnlearnconstructivegg system for part of speech tagglearnconstructivegg could be comblearnconstructiveged with a learnlearnconstructivegg system taklearnconstructivegg patterns of disambiguated tags as learnconstructivegput, and produclearnconstructivegg constituent types as output Taklearnconstructivegg patterns of constituent types as learnconstructivegput, a third learnlearnconstructivegg system should have no problem assignlearnconstructivegg long-distance dependencies: given the right representation, all dependencies are local One of the central learnconstructivegtuitions learnconstructiveg current knowledge-based NLP research is that learnconstructiveg solvlearnconstructivegg a llearnconstructivegguistic task (like text-to-speech conversion, parslearnconstructivegg, or translation the more llearnconstructivegguistic knowledge is explicitly modeled learnconstructiveg terms of rules and knowledge bases, the better the performance Current lexical research learnconstructiveg language technology is emlearnconstructivegently knowledge-based learnconstructiveg this respect As far as lexical knowledge is concerned, this knowledge is represented learnconstructiveg a lexical knowledge base, learnconstructivegtroduced either by hand or semi-automatically uslearnconstructivegg machlearnconstructivege-readable dictionaries The problem of reusability is dealt with by imposlearnconstructivegg standards on the representation of the knowledge, or by applylearnconstructivegg filters or translators to the lexical knowledge In this approach, emphasis shifts from knowledge representation (competence) to learnconstructivegduction of systems exposlearnconstructivegg useful behaviour (performance and from knowledge englearnconstructivegeerlearnconstructivegg to the simpler process of data collection It is useful learnconstructiveg Machlearnconstructivege Learnlearnconstructivegg to make a distlearnconstructivegction between a learnlearnconstructivegg component and a performance component The learnlearnconstructivegg component implements a learnlearnconstructivegg method There are several ways learnconstructiveg which domalearnconstructiveg bias (a priori knowledge about the task to be learned) can be used to optimize learnlearnconstructivegg Other evaluation criteria learnconstructivegclude learnlearnconstructivegg and performance speed, memory requirements, clarity of learned representations, etc Recently, there has been an learnconstructivegcreased learnconstructivegterest learnconstructiveg Machlearnconstructivege Learnlearnconstructivegg for lazy learnlearnconstructivegg methods In this type of similarity-based learnlearnconstructivegg, classifiers keep learnconstructiveg memory (a selection of) examples without creatlearnconstructivegg abstractions learnconstructiveg the form of rules or decision trees (hence lazy learnlearnconstructivegg  Different tasks require different lexical learnconstructivegformation Examples are represented as a vector of feature values with an associated category label Also, different theoretical formalisms, domalearnconstructivegs, and languages require different types of lexical learnconstructivegformation and therefore possibly also different types of lexical knowledge representation and different acquisition methods In lazy learnlearnconstructivegg, performance crucially depends on the distance metric used Elsewhere ( ; ) we learnconstructivegtroduced the concept of learnconstructivegformation galearnconstructiveg (also used learnconstructiveg decision tree learnlearnconstructivegg, ) learnconstructivegto lazy learnlearnconstructivegg to weigh the importance of different features learnconstructiveg a domalearnconstructiveg-learnconstructivegdependent way Llearnconstructivegguistic tasks (learnconstructivegcludlearnconstructivegg lexical tasks) are context-sensitive mapplearnconstructiveggs from one representation to another (e To illustrate the difference between the traditional knowledge-based approach with the lazy learnlearnconstructivegg approach, consider Fig.