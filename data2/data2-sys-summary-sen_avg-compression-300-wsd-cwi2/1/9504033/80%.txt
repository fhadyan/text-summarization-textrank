 A noun architecture may be applied to noun compounds For three word compounds it suffices to compute the ratio of two probabilities, that of a left-branching analysis and that of a right-branching one For the adjacency model, when the given compound is w1 w2 w3, we can estimate this ratio as: For the dependency model, the ratio is: In both cases, we sum over all possible categories for the words in the compound Because the dependency model equations have two factors, they are affected more severely by data sparseness0) is used to favour a left-branching analysis Comparisons are made across five dimensions: Each of two analysis models are applied: adjacency and dependency Eight different training schemes have been used to estimate the parameters and each set of estimates used to analyse the test set under both the adjacency and the dependency model As can be seen, the dependency model is more accurate than the adjacency model0316 demonstrating the superiority of the dependency model, at least for the compounds within Grolier's encyclopedia Lauer and Dras (1994) suggest two improvements to the method used above Five training schemes have been applied with these extensions A marked improvement is observed for the adjacency model, while the dependency model is only slightly improved To determine the difference made by conceptual association, the pattern training scheme has been retrained using lexical counts for both the dependency and adjacency model, but only for the words in the test set Each of two parameterisations are used: associations between words and associations between concepts One problem with the training methods given in section is the restriction of training data to nouns in  To test whether using tagged data would make a difference, the freely available Brill tagger (Brill, 1993) was applied to the corpus Since no manually tagged training data is available for our corpus, the tagger's default rules were used (these rules were produced by Brill by training on the Brown corpus  Three training schemes have been used and the tuned analysis procedures applied to the test set However, for the pattern training scheme an improvement was made to the dependency model, producing the highest overall accuracy of 81  While Hindle and Rooth (1993) use a partial parser to acquire training data, such machinery appears unnecessary for noun compounds The model also has the further commendation that it predicts correctly the observed proportion of left-branching compounds found in two independently extracted test sets There are at least four existing corpus-based algorithms proposed for syntactically analysing noun compounds Given a three word compound, a search is conducted elsewhere in the corpus for each of the two possible subcomponents Resnik (1993) used unambiguous noun compounds from the parsed Wall Street Journal (WSJ) corpus to estimate the association values and analysed a test set of around 160 compounds It uses what I will call the DEPENDENCY MODEL Figure shows a graphical comparison of the two analysis models The dependency model attempts to choose a parse which makes the resulting relationships as acceptable as possible Consider the compound calcium ion exchange, which is typically left-branching (that is, the first two words are bracketed together  Lauer and Dras (1994) show that under a dependency model, left-branching compounds should occur twice as often as right-branching compounds (that is two-thirds of the time  In the test set used here and in that of Resnik (1993 the proportion of left-branching compounds is 67% and 64% respectively The dependency model has also been proposed by Kobayasi et al (1994) for analysing Japanese noun compounds, apparently independently A test set of syntactically ambiguous noun compounds was extracted from our 8 million word Grolier's encyclopedia corpus in the following way All consecutive sequences of these words were extracted, and the three word sequences used to form the test set The remaining compounds were assigned either a left-branching or right-branching analysis One problem with applying lexical association to noun compounds is the enormous number of parameters required, one for every possible pair of nouns By the assumption that words within a group behave nounly, this is constant given the two categories To ensure that the test set is disjoint from the training data, all occurrences of the test noun compounds have been removed from the training corpus Two types of training scheme are explored in this study, both unsupervised.