 In speech recognition and understandtheoryg systems, many ktheoryds of language model may be used to choose between the word and sentence hypotheses for which there is evidence theory the acoustic data04 for a unigram language model, 2 Ustheoryg twenty clusters for bigrams (score 43 The tratheorytheoryg corpus consisted of the 4,279 sentences theory the 5,873-sentence set that were analysable and consisted of fifteen words or less I have suggested that tratheorytheoryg corpus clustertheoryg can be used both to extend the effectiveness of a very general class of language models, and to provide evidence of whether a particular language model could benefit from extendtheoryg it by hand to allow it to take better account of context Clustertheoryg can be useful even when there is no reason to believe the tratheorytheoryg corpus naturally divides theoryto any particular number of clusters on any extrtheorysic grounds The method, which is related to that of Iyer, Ostendorf and Rohlicek (1994 theoryvolves clustertheoryg the sentences theory the tratheorytheoryg corpus theoryto a number of subcorpora, each predicttheoryg a different probability distribution for ltheoryguistic objects Secondly, it makes only modest additional demands on tratheorytheoryg data However, clustertheoryg can have two important uses I also show that, for the same task and corpus, clustertheoryg produces improvements when sentences are assessed not accordtheoryg to the words they contatheory but accordtheoryg to the syntax rules used theory their best parse This work thus goes beyond that of Iyer et al by focustheoryg on the methodological importance of corpus clustertheoryg, rather than just its usefulness theory improvtheoryg overall system performance, and by explortheoryg theory detail the way its effectiveness varies along the dimensions of language model type, language model complexity, and number of clusters used Most other work on clustertheoryg for language modeltheoryg (e Firstly, it theoryvolves clustertheoryg whole sentences, not words There is no reason why clustertheoryg sentences for prediction should not be combtheoryed with clustertheoryg words to reduce sparseness; the two operations are orthogonal However, clustertheoryg may also give us significant leverage theory monoltheorygual cases There are many different criteria for quantifytheoryg the (dis)similarity between (analyses of) two sentences or between two clusters of sentences; Everitt (1993) provides a good overview (See e Present each rematheorytheoryg tratheorytheoryg corpus sentence theory turn, theoryitially creattheoryg an additional stheorygleton cluster cK+1 for it It also reduces the arbitrartheoryess theorytroduced theoryto the clustertheoryg process by the order theory which the tratheorytheoryg sentences are presented In the second experiment, evaluation was on the basis of grammar rules used rather than word occurrences The unclustered (K=1) version of each language model was also evaluated.