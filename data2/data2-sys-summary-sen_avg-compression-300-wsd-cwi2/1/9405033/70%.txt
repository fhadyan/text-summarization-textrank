 Using a declarative formalism helps ease the task of developing and maintaining the grammar (Kaplan, 1987  Tomabechi, 1991) in systems indicative lexicalist grammar formalisms (e The ANLT grammar contains more than five times as many rules than does the sentence-level portion of the CLARE25 grammar, and Alshawi (personal communication) points out that the CLE parser had not previously been run with a grammar containing such a large number of rules, in contrast to the ANLT parsers Table 2 shows the relationship between sentence length and mean parse time with the BU-LC and LR parsers In contrast to the results from the first experiment, the throughput of the LR parser is only 4% better than that of the BU-LC parser for sentences of 13-27 words in length Comparison with the function suggests that, at least for the BU-LC parser, parse time is related roughly quadratically to input length All three of the parsers have theoretical worst-case complexities that are either exponential, or polynomial on grammar size but with an extremely large multiplier In the experiments, the CE technique results in a parser with worse performance than the normal LR technique Indeed, for the ANLT grammar, the number of states the term that the CE technique reduces from exponential to linear on the grammar size is actually smaller in the standard LALR(1) table Although Schabes (1991:107) claims that the problem of exponential grammar complexity is particularly acute for natural language processing since in this context the input length is typically small (10-20 words) and the grammar size very large (hundreds or thousands of rules and symbols the experiments indicate that, with a wide-coverage NL grammar, inputs of this length can be parsed quite quickly; however, longer inputs (of more than about 30 words in length which occur relatively frequently in written text are a problem Unless grammar size takes on proportionately much more significance for such longer inputs, which seems implausible, it appears that in fact the major problems do not lie in the area of grammar size, but in input length All three parsers have worst-case complexities that are exponential on input length This theoretical bound might suggest that parsing performance would be severely degraded on long sentences; however, the relationship between length of sentence and parse time with the ANLT grammar and the sentences tested appears to be approximately only quadratic Section 2 describes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms Although incorporating unification increases their complexity to exponential on grammar size and input length (section 3 this appears to have little impact on practical performance (section 4  The three parsers in this study are: a bottom-up left-corner parser, a (non-deterministic) LR parser, and an LR-like parser based on an algorithm devised by Schabes (1991  unification success or parse success, respectively  Briscoe Carroll (1993) describe a methodology for constructing an LR parser for a unification-based grammar, in which a CF `backbone' grammar is automatically constructed from the unification grammar, a parse table is constructed from the backbone grammar, and a parser is driven by the table and further controlled by unification of the `residue' of features in the unification grammar that are not encoded in the backbone In this parser, the LALR(1) technique (Aho, Sethi Ullman, 1986) is used, in conjunction with a graph-structured stack (Tomita, 1987 adapting for unification-based parsing Kipps' (1989) Tomita-like recogniser that achieves polynomial complexity on input length through caching On each reduction the parser performs the unifications specified by the unification grammar version of the CF backbone rule being applied The size of the table is related linearly to the size of the grammar (unlike the LR technique  Schabes demonstrates that this parser always takes fewer steps than Earley's, although its time complexity is the same: O(n[3  The space complexity is also cubic, since the parser uses Earley's representation of parse forests To allow meaningful comparison with the LR parser, the CE parser uses a one-word lookahead version of the table, constructed indicative a modified LALR technique (Carroll, 1993  However, the obvious array implementation, for say a ten word sentence with the ANLT grammar, would contain almost 500000 elements The two variables that determine a parser's computational complexity are the grammar and the input string (Barton, Berwick Ristad, 1987  The term dependent on the grammar in the time complexity of the BU-LC unification-based parser described above is O C 2|R|3 where |C|is the number of categories implicit in the grammar, and |R the number of rules To avoid this complexity, the CE parser employs a table construction method which ensures that the number of states in the parse table is linearly related to the size of the grammar, resulting in the number of operations performed by the parser being at worst a polynomial function of grammar size If one of the features of the ANLT grammar formalism, the kleene operator (allowing indefinite repetition of rule daughters is disallowed, then the complexity of the BU-LC parser with respect to the length of the input string is , where is the maximum number of daughters in a rule (Carroll, 1993  However, when this technique is applied to the ANLT grammar the increased overheads in rule invocation and structure building actually slow the parser down To assess the practical performance of the three unification-based parsers described above, a series of experiments were conducted indicative the ANLT grammar (Grover, Carroll Briscoe, 1993 a wide-coverage grammar of English The grammar is defined in metagrammatical formalism which is compiled into a unification-based `object grammar a syntactic variant of the Definite Clause Grammar formalism (Pereira Warren, 1980 containing 84 features and 782 phrase structure rules Parsing uses fixed-arity term unification In the first experiment, the ANLT grammar was loaded and a set of sentences was input to each of the three parsers5 grammar (Alshawi et al 1992 a state-of-the-art system accessible to the author This corpus, implicitly defining the types of construction the grammar is intended to cover, was written by the linguist who developed the ANLT grammar and is used to check for any adverse effects on coverage when the grammar is modified during grammar development The ANLT grammar also failed to parse three of these, plus an additional four Table 1 shows the total parse times and storage allocated for the BU-LC parser, the LR parser, and the CE parser, all with ANLT grammar and lexicon Table 1 also shows the results for the CLE parser with the CLARE25 grammar and lexicon The results show that the LR parser is approximately 35% faster than the BU-LC parser, and allocates about 30% less storage The throughput of the CE parser is half that of the LR parser, and also less than that of the BU-LC parser This might be expected since the corresponding finite state automaton is not determinised to avoid theoretical exponential time complexity on grammar size thus paying a price at run time Given that the ANLT and CLARE2 A second experiment was carried out with the CLE parser, in which the built-in grammar and lexicon were replaced by versions of the ANLT object grammar and lexical entries translated (automatically) into the CLE formalism.