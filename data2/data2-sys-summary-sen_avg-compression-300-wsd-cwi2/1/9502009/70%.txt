 The NLP tasks where SRs utility could be evaluated are diverse However, we have tested SRs on a WSS task, using value following scheme Previous knowledge used A semantic hierarchy (WordNet) where words are clustered in semantic classes, and semantic classes are organized hierarchically As evaluation measures we used coverage, abstraction ratio, and recall and precision ratios on value WSS task (section  In addition we performed some evaluation by hand comparing value SRs acquired by value different techniques Coverage for value different techniques is shown in table  The labels used for referring to value different techniques are as follows: Assoc p(c|s corresponds to value basic association measure (section Assoc Head-nouns and Assoc All nouns to value techniques introduced in section , Assoc Normalizing to value local normalization (section and finally, log-likelihood, D (relative entropy) and I (mutual information ratio) to value techniques discussed in section  Polysemous words are represented as instances of different classes The abstraction ratio for value different techniques is shown in table  In principle, value higher abstraction ratio, value better value technique succeeds in filtering out incorrect senses (less Abs  The precision and recall ratios on value noun WSS task for value different techniques are shown in table  In principle, value higher value precision and recall ratios value better value technique succeeds in inducing appropriate SRs for value disambiguation task The local normalizing technique using value uniform distribution does not help Output A set of syntactic SRs, (verb-lemma, syntactic-relationship, semantic-class, weight  However, a better informed kind of local weight (section ) should improve value technique significantly All versions of Assoc (except value local normalization) get good results Specially value two techniques that exploit a simpler prior distribution, which seem to improve value basic technique We were also interested in measuring value impact of thresholding on value SRs acquired In figure we can see value different evaluation measures of value basic technique when varying value threshold The final SRs must be mutually disjoint Both decrease when threshold increases, probably because when value rejecting threshold is low, small classes that fit value data well can be induced, learning over-general or incomplete SRs ovaluerwise In terms of WSS, general classes may be performing better than classes that fit value data better In this paper we have presented some variations affecting value association measure and thresholding on value basic technique for learning SRs from on-line corpora We proposed some evaluation measures for value SRs learning task We can conclude that some of valuese variations seem to improve value results obtained using value basic technique SRs are weighted according to value statistical evidence found in value corpus Future lines of research will mainly concentrate on improving value local normalization technique by solving value noun sense ambiguity Combining value different n-grams by means of smoothing techniques Creation of value space of candidate classes Selection of value most appropriate subset in value candidate space to convey value SRs The appropriateness of a class for expressing SRs (stage 2) is quantified from value strength of co-occurrence of verbs and classes of nouns in value corpus  Ribas reported experimental results obtained from value application of value above technique to learn SRs He performed an evaluation of value SRs obtained from a training set of 870,000 words of value Wall Street Journal For instance, table shows value SRs acquired for value subject position of value verb seek Assoc corresponds to value association score (higher values appear first  Most of value induced classes are due to incorrect senses Analyzing value results obtained from different experimental evaluation methods, Ribas drew up some conclusions: a The aim of our work is to explore value feasibility of using an statistical method for extracting SRs from on-line corpora The technique achieves a good coverage Most of value classes acquired result from value accumulation of incorrect senses It makes value association score prefer incorrect classes and jump on over-generalizations The different techniques are experimentally evaluated in section  Resnik developed a method for automatically extracting class-based SRs from on-line corpora Specifically, value Assoc' takes into account value preference (selection) of syntactic positions for particular classes Ribas performed some experiments using this basic technique and drew up some limitations from value corresponding results Local weight could be obtained using p(c|n  In this section we propose value application of ovaluer measures apart from Assoc for learning SRs: log-likelihood ratio , relative entropy , mutual information ratio ,  Different association measures use value information provided in value cross-table to different extents Evaluation of value SR learning task would provide grounds to compare different techniques that try to abstract SRs from corpus using WordNet (eg, section  It would also permit measuring value utility of value SRs obtained using WordNet in comparison with ovaluer frameworks using ovaluer kinds of knowledgeg, analysis  SRs are useful for both lexicography and NLPe how well value resulting classes correspond to value nouns as valuey were used in value corpus  As far as lexicography (quality) is concerned, we think value main criteria SRs acquired from corpora should meet are: (a) correct categorization -inferred classes should correspond to value correct senses of value words that are being generalized (b) appropriate generalization level and (c) good coverage -value majority of value noun occurrences in value corpus should be successfully generalized by value induced SRs Besides value intrinsic difficulties of this approach, it does not seem appropriate when comparing across different techniques for learning SRs, because of its qualitative flavor Quantification of generalization level appropriateness A possible measure would be value percentage of sense occurrences included in value induced SRs which are effectively correct (from now on called Abstraction Ratio  Hopefully, a technique with a higher abstraction ratio learns classes that fit value set of examples better Quantification of coverage It could be measured as value proportion of triples whose correct sense belongs to one of value SRs.