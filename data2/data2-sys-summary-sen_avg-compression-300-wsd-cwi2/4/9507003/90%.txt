 The notion of robustness in natural language processing is a rarobustnessr broad one and lacks a precise definition information decrease Whereas Constraint Grammar restricts itself to purely syntactic means, an integration of simple semantic criteria into Constraint Dependency Grammar has been proposed recently  The following small and rarobustnessr rigid sample grammar illustrates robustness different types of constraints needed: 1 linear ordering constraints sy3: synlab(X SUBJ pos(dep(X pos(syndom(X The subject precedes robustness finite verb sy1 through sy3 are unary constraints, sy4 is a binary one Note that constraints refer to modifying relations instead of word forms In a very similar fashion semantic constraints comprise 1 Semantic constraints need not be restricted to linguistically motivated (i compatibility matrices within robustness constraint satisfaction problem no longer contain binary categories but confidence scores also ranging from zero (for impossible combinations) up to one (for combinations not even violating a single constraint  On robustness semantic layer only robustness licensing constraint se1 is declared as a strict one robustness calculation of initial confidence scores for all combinations of syntactic and semantic modification relations and 2 Hence, structural interpretations violating a high number of rarobustnessr strong constraints are pruned first Using robustness toy grammar specified above togerobustnessr with its penalty scores robustness arbitration process between syntactic and semantic evidence in simple disambiguation problems can be studied This interpretation, however, happens to be a rarobustnessr fragile one and breaks immediately under arbitrary syntactic variation On robustness orobustnessr hand, constraint relaxation techniques rely on a systematic variation of existing grammar rules written for standard input Wherobustnessr syntactic evidence is propagated from robustness syntactic to robustness semantic layer or vice versa depends only on robustness available information Constraints of this type can be used to model e agreement conditions in syntactic rules Insufficient modelling information on any one of robustness processing layers might well result in robustness selection of an odd interpretation but will not cause robustness language processing unit to break down entirely Since structural disambiguation by constraint satisfaction likewise lends itself to robustness creation of time sensitive parsing procedures , in robustness long run it might provide a unifying foundation to build language processing systems upon which embody aspects of robustness against such different disruptive factors as syntactically ill-formed input, metaphorical use and dynamic time constraints Psycholinguistic evidence provides a contradictory picture of human language processing It allows to yield an at least vague interpretation even in cases of extremely distorted input: 1 Syntactically ill-formed utterances are interpreted based on semantic and background knowledge even if subcategorization regularities or orobustnessr grammatical constraints are violated Parallel and autonomous structures in language processing have not only evolved between syntactic and semantic aspects of language Here, expectations come to play at two different dimensions: Syntactic, semantic and pragmatic predictions about future input derived from previous parts of robustness utterance or dialogue Expectations exchanged between parallel and autonomous processing structures for syntax and semantics In robustness opposite direction, semantic relations, e Since syntactic and semantic restrictions are conjunctively combined robustness overall vulnerability against arbitrary impairment of robustness input utterances even increases: An analysis may now fail due to syntactic as well as due to semantic reasons It combines syntactic, semantic and even pragmatic information in a single representation named construction.