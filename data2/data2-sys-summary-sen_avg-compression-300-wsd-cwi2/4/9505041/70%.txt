 Because traditional notions of language complexity are generally defined in terms of rewriting mechanisms, complexity of the languages licensed by these formalisms can be difficult to determine A node is in the set assigned to Xi in iff it is labeled with Xi Rabin showed that, for any in the language of SnS, the set of trees encoding the satisfying assignments for in is accepted by a particular type of finite-state automaton on infinite trees We say that the set is Rabin recognizable 100] But formal language theory still has much to offer to generative linguistics It follows that a set of trees is definable in iff they are Rabin recognizable If we restrict our attention to sets of finite trees, we can take Rabin's automata to be ordinary finite-state automata over finite trees , that is, the sets of finite trees that are definable in are simply recognizable A tree is accepted if it can be labeled by the automaton in such a way that the root is labeled with a start state and the set of states labeling the leaves is one of a set of accepting sets of states Every set of trees that is accepted in this way is the projection of a local set It is easy to show that, given a recognizable set of trees, one can construct a CFG to generate the corresponding set of trees labeled with pairs as in  Language complexity provides one of the most useful measures with which to compare languages and language formalisms In the example, for instance, this would include, among others, the productions The original set of trees is then the first projection of the set generated by the CFG This characterization provides a powerful tool for establishing strong context-freeness of classes of languages that are defined by constraints on the structure of the trees analyzing the strings in the language If one can show that the constraints defining such a set, or perhaps that any constraints in the class employed by a given formalism, can be defined within then the corresponding language or class of languages is strongly context-free Much of the value of standard language complexity classes, on the other hand, comes from results that allow one to show that a given language or class of languages is not included in a particular complexity class One relatively easy way of establishing such results is by employing the contrapositive of Theorem  If one can show that a given predicate, when added to allows definition of known non-CF languages, then clearly that predicate properly extends the power of the language and cannot be definable In this way, one can show that the predicate which holds between two nodes iff the yields of the subtrees rooted at those nodes are labeled identically wrt P is not definable in , for if it were one could define the copy language  Let be the monadic second-order theory of G Lewis showed that this theory is undecidable by showing how one could define the set of terminating computations of an arbitrary Turing machine within it Now, the monadic second-order theory of any of our intended structures is decidable (by reduction to SnS as is the monadic second-order theory of any of our intended structures augmented with any predicate that is definable in (since we can reduce this to the theory of the original structure via that definition  Our approach to showing that a predicate is not definable in is to show that the theory of one of our structures augmented with that predicate is not decidable In particular, we will show that the theory of such a structure includes an undecidable fragment of the monadic second-order theory of the grid More importantly, characterization results for language complexity classes tend to be in terms of the structure of languages, and the structure of natural language, while hazy, is something that can be studied more or less directly In essence, the indexation is an equivalence relation, one that distinguishes unboundedly many equivalence classes among the nodes of the tree Let S2S+CI be the monadic second-order theory of this class of structures Let ALIGN= right where This requires that every node is co-indexed with itself, that the left children of co-indexed nodes are co-indexed as are the right children of co-indexed nodes, and that the left child of the right child and right child of the left child of co-indexed nodes are co-indexed (Although such evidence may well be difficult to find, as witnessed by the history of less successful attempts to establish results such as Shieber's , Further, language complexity classes characterize, along one dimension, the types of resources necessary to parse or recognize a language The non-definability of free-indexation is a significant obstacle to capturing GB accounts of language in  Results of this type for the class of human languages, then, make specific predictions about the nature of the human language faculty, predictions that, at least in principle, can both inform and be informed by progress in uncovering the physical nature of that faculty We thus establish that this account licenses a strongly context-free language In this paper we discuss a flexible and quite powerful approach to establishing language complexity results for formalisms based on systems of constraints on trees This is our definition of chains the core notion in contemporary GB accounts of movement The principles embodying a GB theory of language are collected into modules which apply at various levels of this analysis The principles we capture include basic X-bar Theory, Theta Theory, the Case Filter, Binding Theory, Control Theory and various constraints on movement, in particular the Empty Category Principle In Section we introduce a logical language, , capable of encoding such constraints lucidly In this section we focus on the Empty Category Principle and the definition of chains One argument against such a view is that in some cases (such as head-raising) chains formed by one movement can be disrupted by subsequent movement In fact, at least if one can employ indices to identify the elements of chains, there is no need for such a retreat Even limiting oneself to the language of L[2]K,P, if one restricts attention to languages, like English, in which head-movement is strictly limited, it is possible to get a purely declarative (and reasonably clear) account of the issues usually treated by reconstruction A particular example, one that will be a focus of this paper, is Government and Binding Theory The fundamental issue we must address in defining chains within is how to identify the antecedent of a trace without reference to indices Thus definability in characterizes the strongly context-free languages This puts specific constraints on the structural relationship between a trace and its antecedent In Rizzi's theory, this is a conjunctive principle with two components, a Formal Licensing requirement and an Identification requirement: ECP (Rizzi A non-pronominal empty category must be properly head-governed This can be done in one of two ways, either by a particular class of index, the referential indices, or by a sequence of antecedent-government links In this way, minimality suffices to pick out the unique antecedent of traces in chains that are identified by antecedent-government But under Rizzi's criteria chains can also be identified by referential indices Manzini , in fact, argues for an account of A-movement (movements, like these we have been considering, to non-argument positions) which implies that no more than two such chains one referential and one non-referential may ever overlap Relativized Minimality theory distinguishes a number of distinct varieties of antecedent-government, one for each class of movement We look at one representative case -antecedent-government The idea, now, is to define chains as any set of nodes that are linearly ordered by  As we admit the notion of trivial chains chains with a single element, formed by zero movements we can generalize this to a global requirement that every element of the tree is a member of a (possibly trivial) well-formed chain Thus we are able to show that the language licensed by this particular GB theory is strongly context-free The fact that we can exhibit a definition in of the class of trees licensed by a specific GB account of English provides a strong complexity result for that class of trees it is strongly context-free The account works for English notion we can classify chains in English into a bounded set of types in such a way that no two chains of the same type ever cross Our approach to chains will work for any account of language that satisfies this principle While this is often modeled as a specific range of Transformational Grammars, the connection between the underlying grammar mechanism and the language a given GB theory licenses is quite weak Thus, in the final structure all chains of head-movement overlap In this paper we have introduced a kind of descriptive complexity result for the strongly Context-Free Languages a language is strongly context-free iff the set of trees analyzing the syntax of its strings is definable in (modulo a projection  Using this result we have sketched a couple of language complexity results relevant to GB, namely, that free-indexation cannot, in general, be enforced by CFGs, and that a specific GB account of English licenses a strongly context-free language The fact that the definition works for English is a consequence of the fact that, in the account of English we capture, it is possible to classify chains into finitely many categories in such a way that no two chains from a given category ever overlap Our definition is unable to identify any well-formed chains including these positions; indeed, there is unlikely to be any way to distinguish these chains without the equivalent of unbounded indices The fact that this is context-free says nothing about the nature of human language faculty, since the principle it depends upon is unlikely to be a principle of Universal Grammar Extensions of our descriptive complexity result to larger language complexity classes could provide formal restrictions on the principles employed by GB theories that would be sufficient to provide non-trivial generative capacity results for those theories without losing the ability to capture the full range of human language With such extended characterizations one might establish upper bounds on the complexity of human language in general This suggests that the regularities of human languages that are the focus of the linguistic studies are perhaps reflections of properties of the human language faculty that can be characterized, at least to some extent, by language complexity classes What distinguishes the formalization we discuss is the fact that it is carried out in a language which can only define strongly context-free sets The fact that the formalization is possible, then, establishes a relatively strong language complexity result for the theory we capture We have, then, two conflicting criteria for our language In addition, it includes an arbitrary array of monadic predicate constants constants naming specific subsets of the nodes in the tree In an extreme view, one can take the underlying mechanism simply to generate the set of all finite trees (labeled with some alphabet of symbols) while the grammatical theory is actually embodied in a set of principles that filter out the ill-formed analyses The formula , for instance, is true at every node labeled N There are two sorts of variables as well those that range over nodes in the tree and those that range over arbitrary subsets of those nodes (thus this is is monadic second-order language  Crucially, though, this is all the language includes To be precise, the actual language we use in a given situation depends on the sets of constants in use in that context We are concerned then with a family of languages, parameterized by the sets of individual and set constants they employ We use lower-case for individual variables and constants, and upper-case for set variables and predicate constants As a result, it has been difficult to establish language complexity results for GB theories, even at the level of the recursive , or context-sensitive languages So, for instance, asserts that the set assigned to X includes every node dominated by the node assigned to x Truth, for these languages, is defined relative to a specific class of modelse the model is for a language ) we will generally omit it The intended class of these models are, in essence, labeled tree domains Tree domains, then, are particular subsets of  That language complexity results for GB should be difficult to come by is hardly surprising ( is the set of natural numbers &gt; Every tree domain has a natural interpretation as a model for (which interprets only the fixed predicate symbols &gt; The structures of interest to us are just those models that are the natural interpretation of a tree domain, augmented with interpretations of additional individual and predicate constants If is a set of sentences in a language , we will use the notation to denote the set of trees, i The development of GB coincided with the abandonment, by GB theorists, of the presumption that the traditional language complexity classes would provide any useful characterization of the human languages is just a monadic predicate; it is within the language of (for suitable P) and its definition is simply a biconditional formula This followed, at least in part, from the recognition of the fact that the structural properties that characterize natural languages as a class may well not be those that can be distinguished by existing language complexity classes Definitions can also use predicates expressing properties of sets and relations between sets, as long as those properties can be explicitly defined A set of nodes, then, is finite iff each of its non-empty subsets has an upper-bound with respect to lexicographic order as well We can now give an example of a class of sets of trees that is definable in the local sets (ie the sets of derivation trees generated by Context-Free Grammars  Given an arbitrary Context-Free Grammar, we can treat its terminal and non-terminal symbols as monadic predicate constants If the set of productions for a non-terminal A, for instance, is we can translate this as where We can collect such translations of all the productions of the grammar together with sentences requiring nodes labeled with terminal symbols to have no children, requiring the root to be labeled with the start symbol, requiring the sets of nodes labeled with the terminal and non-terminal symbols to partition the set of all nodes in the tree, and requiring that set of nodes to be finite The proof hinges on the fact that one can translate formulae in into the language of SnS the monadic second-order theory of multiple successor functions This is the monadic second-order theory of the structure a generalization of the natural numbers with successor and less-than.