 ride be coded using the features in Fig The prosodic and cue phrase features were motivated by previous results in the literature We currently use 10 narratives for training and 5 narratives for testing The ratios of test to training data measured in narratives, prosodic phrases and clauses, respectively, are 50 mis-classification of boundaries, often occurred where prosodic and cue features conflicted with NP features The original NP algorithm assigned boundaries wherever the three values coref infer global Condition 1 results, the untuned algorithm with the initial feature set, are very similar to the training set except for worse precision5 to automatically develop segmentation algorithms from our corpus of coded narratives, where each potential boundary site has been classified and represented as a set of linguistic features Our training set of 10 narratives provides 1004 examples of potential boundary sites We have presented two methods for developing segmentation hypotheses using multiple linguistic features The first method hand tunes features and algorithms based on analysis of training errors Subjects were free to assign any number of boundaries However, we also found poor correlation of three untuned algorithms (based on features of referential noun phrases, cue words, and pauses, respectively) with the subjects' segmentations Each potential boundary site in our corpus is coded using the set of linguistic features shown in Fig global.