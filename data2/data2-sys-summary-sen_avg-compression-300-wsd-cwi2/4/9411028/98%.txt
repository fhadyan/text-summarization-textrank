 Language models used in the context of speech recognition are normally some variety of finite-state grammar A bigram bigram model is used Preference functions are of three types The preference functions used were: The speech function, returning the recognizer score Two combining functions: one for grammar rules used in the best QLF for the string, and one for the semantic triples for that QLF Sentence recognition accuracy using optimized speech (DECIPHER) and bigram (CLE and N-gram) information on unseen ATIS data is 73 On the main training corpus of 4615 reference sentences used during the project, the repair mechanism suggested corrections for 135 sentences Correct decisions are shown in bold type.