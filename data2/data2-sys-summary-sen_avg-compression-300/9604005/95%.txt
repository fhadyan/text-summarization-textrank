 The initial model of the original model merging procedure is the maximum likelihood or trivial model The trivial model has both properties The first experiment compares model merging with a standard bigram model The bigram model yields a Markov model with 1,440 states Model merging starts with the maximum likelihood model for the training part Then, perplexity slowly increases Model merging finds a model with 113 states, which assigns a log perplexity of 2 Thus, the model found by model merging can be regarded generally better than the bigram model This yields a bigram model Additionally, the merged model was much smaller than the bigram model Model merging is a technique for inducing model parameters for Markov models from a text corpus Model merging induces Markov models in the following way Merging starts with an initial, very general modele a model that exactly matches the corpus This model is also referred to as the trivial model The trivial model assigns a probability of to the corpus The probability never increases because the trivial model is the maximum likelihood model, ie it maximizes the probability of the corpus given the model Therefore, deriving a Markov model by model merging is O(l[4 in time