 We arrive at a surprising conclusion that a set of idiomatic expressions with complicated meanings and a trivial construction about time can have the same semantic complexity (From the perspective of answering yes/no questions  Let U be a finite set of tokens Then, the size of MU is the measure of what is -complexity of U for Dialog 1 The system is able to handle a whole range of grammatical constructions, including complex prepositional phrases Thus, the semantic what is -complexity of S is greater than the what is -complexity of T The set Q consists of questions about parameters of calendar events: event_time event_name alarm_on event_topic event_participants  Similarly, we can compute the semantic complexity of ELIZA as Q-complexity What would happen if one would like to play the game of asking what is questions with a machine How complex such a machine would have to be? Again, using the results of and about the roughly 10:1 ratio of the number of words to the number of facts necessary to understand sentences with them, we get that for the set T we need about 20 facts for two rounds of questions However for S we would need about 250 for two rounds of questions And these numbers are closer to our intuitive understanding of the semantic complexity of the two sets We have shown how these two kinds of complexity measures distinguish between the two sets of sentences with at  In other words, the real complexity of discussing a narrative is at least the complexity of iterated-what-is combined with iterated-why (and might as well include alternative questions  yes/no and what-is complexities  What is -complexity: A natural language understanding system has to deal with a set of basic objects It can be argued that what is -complexity is a reasonable measure of how complex is the set of those basic objects Namely, what is -complexity and twice-iterated-what-is -complexity measures the size of the database of background knowledge facts Intuitively, this is a reasonable measure of their semantic complexity Complexity of grammatical constructions: In many cases the complexity of a new construction is not much greater than the complexity of the subconstructions they are built from allowing schedule a cafeteria , and increasing the complexity of the grammar, e by increasing the number of noun categories np(event np(place) etc Similarly, as new constructions introduce more complexities, for example, S(imp) VP NP PP, we can increase the number of constructions Thus, roughly, the complexity of the grammar can be estimated by the number of grammatical constructions, defaults and filters The number of semantic/ontological categories is small The second advantage of a limited domain lies in the relatively small number of semantic categories Notice that the meanings of A and B is ignored here; hence from the point of view of semantic complexity, the semantics of most A are B would be very simple (5 states is enough  The complexity of discourse: Despite the simplicity of ELIZA, people were willing to attribute to it a much more complex behavior One can of course argue about the adequacy of either model, but the fact remains that for simple tasks dialog complexity is limited by a small number of basic states We have defined semantic complexity by connecting the concept of Kolmogorov complexity with the types of questions that can apply to a sentence (a string  an abstract machine for answering questions of interest We have analyzed semantic complexities of simple examples involving prepositional phrases and of larger NLU programs We have introduced a new concept of meaning of a string, identifying it with the set of values for a fixed set of questions For instance: (1) How useful is the new concept of meaning? What about compositional semantics? Notice that the appeal of compositionality at least partly lies in reducing the complexity of the meaning automaton at a price of high what-is -complexity (i the complex semantic descriptions of words) we get a very simple automaton whose only move is functional application (2) Can we estimate semantic complexities by statistical means? This is possible for some cases of what-is -complexity, e (3) Can we express semantic complexity of a NLU task as a function of the complexity of an automaton partially solving the task and the description (or a corpus) of the whole task It would mean that given e For instance, for what is -complexity such a result is trivially holds: the size of the corpus determines the size of the explanation table But when? (5) If we measure the semantic complexity by the number of pairs in the functions, the yes-no complexities of the two sets T and S were the same and equal to 24[2 similarly if we use Turing machines with the complexity of 25, not 30) it behaves almost like the yes-no machine of Section 3 Acknowledgments Kanevsky for our discussions of semantic complexity, and W Background knowledge is bounded One should ask how many such facts we need? There is evidence ( , , ) that the ratio of the number of words to the number of facts necessary to understand sentences with them is about 10:1 Secondly, they have a similar number of background knowledge facts So the question remains: why is the domain of scheduling meetings easier than the domain of discussing divorce experiences? How could we measure the open-ended character of the latter? We are now ready to introduce the concept of semantic complexity for sets of sentences and natural language understanding tasks, i Then, for example, if we examine the semantic complexity of two sets of 24 sentences, one consisting of very simple time expressions, and the other of a set of idioms, it turns out - surprisingly - that from a certain perspective they have identical complexities, but from another perspective they do not For simplicity, we will consider the two constructions simply as sets of sentences One of the tools for measuring complexity widely used in theoretical computer science is Kolmogorov complexity Kolmogorov complexity of a string x is defined as as the size of the shortest string y from which a certain universal Turing machine produces x for details and a very good survey of Kolmogorov complexity and related concepts  We could define semantic complexity of a set of sentences S as its Kolmogorov complexity, i as the size (measured by the number of states) of the simplest machine M, such that for any sentence s in S its semantics is given by M(s  It is also problematic because the function K assigning its Kolmogorov complexity to a string is not computable Thus, instead, we will define Q-complexity of a set of sentences S as the size of the simplest model scheme M=MS, such that any sentence s in S its semantics is given by M(s and M(s) correctly answers all questions about s contained in Q In this paper we think of M as a Turing machine that computes the semantics of the sentences in S, and measure its size by the number of states Let Q be a set of questions a formal string) is not given by its truth conditions or denotation but by a set of answers: Now, given a set of sentences S and a set of questions Q, their meaning automaton is a function which satisfies the constraint M (s,q) = q(s) i Note that the idea of a meaning automaton as a question answer map allows us to bypass all subtle semantics questions without doing violence to them We can measure the semantic complexity of a set of sentences by the size of the smallest model that answers all relevant questions about those sentences (in practice, the simplest we are able to construct  A simple classification of questions given by (pp We now want to examine a few measures of semantic complexity: yes/no-complexity, and what is -complexity We also analyze the complexity of ELIZA as Q-complexity, and argue that defining semantic complexity of NL interfaces as Q-complexity makes sense If we measure the semantic complexity by the number of pairs in the functions, the yes-no complexities of both sets are the same and equal 24[2  If we measure it by the number of states of their respective Turing machines, because the two problems are isomorphic, their yes-no complexity will again be identical For example, we can build a two state, 4-tape Turing machine This machine can be described as a table, hence we can assign the complexity of 30 to it