 We address the problem of automatically acquiring case frame patterns (selectional patterns) from large corpus data The acquisition of case frame patterns normally involves the following three subproblems: 1) Extracting case frames from corpus data, 2) Generalizing case frame slots within these case frames, 3) Learning dependencies that exist between these generalized case frame slots (The bracketed corpus does overlap with part of the tagged corpus We acquired case frame patterns using the training data Table shows 37 of the verbs whose dependencies between arg2 and other case slots are positive and exceed a certain threshold, i In this paper, we view the problem of learning case frame patterns as that of learning a multi-dimensional discrete joint distribution, where random variables represent case slots Table shows 22out of these 140 verbs such that their case slots have positive dependency that exceeds a certain threshold, i We then formalize the dependencies between case slots as the probabilistic dependencies between these random variables We also used the 357 verbs and their case frames used in Experiment 1 to acquire class-based case frame patterns using the proposed method We randomly selected 100 verbs among these 357 verbs and attempted to acquire their case frame patterns We generalized the case slots within each of these case frames using the method proposed by to obtain class-based case slots, and then replaced the word-based case slots in the data with the obtained class-based case slots What resulted are class-based case frame examples like those shown in Figure  We used these data as input to the learning algorithm and acquired case frame patterns for each of the 100 verbs We found that no two case slots are determined as dependent in any of the case frame patterns Our experimental result verifies the validity in practice of the assumption widely made in statistical natural language processing that class-based case slots (and also word-based case slots) are mutually independent, at least when the data size available is that provided by the current version of the Penn Tree Bank We defined an artificial class-based model and generated some data according to its distribution We then used the data to estimate a class-based model (dendroid distribution and evaluated the estimated model by measuring the number of dependencies (dependency arcs) it has and the KL distance between the estimated model and the true model We repeatedly generated data and observed the `learning curve namely the relationship between the number of dependencies in the estimated model and the data size used in estimation, and the relationship between the KL distance between the estimated and true model and the data size The primary contribution of research reported in this paper is that we have proposed a method of learning dependencies between case frame slots, which is theoretically sound and efficient, thus providing an effective tool for acquiring case dependency information For the slot-based model, sometimes case slots are found to be dependent For the word-based or class-based models, case slots are judged independent, with the data size currently available in the Penn Tree Bank We proposed to use dependency forests to represent case frame patterns It is possible that more complicated probabilistic dependency graphs like Bayesian networks would be more appropriate for representing case frame patterns This would require even more data and thus the problem of how to collect sufficient data would be a crucial issue, in addition to the methodology of learning case frame patterns as probabilistic dependency graphs for his comments We employ Suzuki's algorithm to learn case frame patterns as dendroid distributions In this paper, we propose a method of learning dependencies between case frame slots We conducted some experiments to automatically acquire case frame patterns from the Penn Tree Bank bracketed corpus As explained in Introduction, the problem of learning case frame patterns can be viewed as that of estimating the underlying multi-dimensional joint distribution which gives rise to such data In this paper, we use `case slots' to mean surface case slots, and we uniformly treat obligatory cases and optional cases By `dependency' is meant the relation that exists between case slots which constrains the possible values assumed by each of those case slots For example, the data in Figure can be generated by a word-based model, and the data in Figure by a class-based model We then formulate the dependencies between case slots as the probabilistic dependencies between the random variables in each of these three models A simplifying assumption that is often made to deal with this difficulty is that random variables (case slots) are mutually independent ) and The independence assumption can also be made in the case of a class-based model or a slot-based model Assuming that random variables (case slots) are mutually independent would drastically reduce the number of parameters These examples indicate that the possible values of case slots depend in general on those of the other case slots: that is, there exist `dependencies' between different case slots Since many of the random variables (case slots) in case frame patterns are essentially independent, this feature is crucial in our context, and we thus employ Suzuki's algorithm for learning our case frame patterns It tends to be the case usually that a simpler model has a poorer fit to the data, and a more complex model has a better fit to the data There has been no method proposed to date, however, that learns dependencies between case slots in the natural language processing literature This is reasonable since with a small data size most case slots cannot be determined to be dependent with any significance We conducted some experiments to test the performance of the proposed method as a method of acquiring case frame patterns In our first experiment, we tried to acquire slot-based case frame patterns First, we extracted 181,250 case frames from the Wall Street Journal (WSJ) bracketed corpus of the Penn Tree Bank as training data There were 357 verbs for which more than 50 case frame examples appeared in the training data In the past research, the distributional pattern of each case slot is learned independently, and methods of resolving ambiguity are also based on the assumption that case slots are independent , , , , , , , or dependencies between at most two case slots are considered , ,  First we acquired the slot-based case frame patterns for all of the 357 verbs We then conducted a ten-fold cross validation to evaluate the `test data perplexity' of the acquired case frame patterns, that is, we used nine tenth of the case frames for each verb as training data (saving what remains as test data to acquire case frame patterns, and then calculated perplexity using the test data We also calculated the average perplexity of the `independent slot models' acquired based on the assumption that each case slot is independent It seems safe to say therefore that the dendroid model is more suitable for representing the true model of case frames than the independent slot model We used the case frames of all 357 verbs as our training data