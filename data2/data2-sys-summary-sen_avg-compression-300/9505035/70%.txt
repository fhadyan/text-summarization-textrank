 The Xerox Tagger HREF= 9505035 Thus, the Lancaster-Oslo/Bergen (LOB) Corpus distinguishes about 135 tags, and the Lancaster UCREL group uses a set of 166 tags (for CLAWS2 HREF= 9505035 Other tagsets are even larger, as the one used in the London-Lund Corpus of Spoken English, which contains 197 tags As a consequence of this combination of techniques, present excelent results tagging an English corpus with the Xerox Tagger and the constraint-based system ENGCG HREF= 9505035 It contains 479 POS tags (there are also special tags for punctuation signs  Given the rich verbal morphology of Spanish, verbal tags account for 59% of the total number of tags HREF= 9505035html#Cutting92 &gt;Cutting et al 1992 for instance, report on tagging results on even numbered sentences of the Brown corpus using a 50,000 forms lexicon With this lexicon and the suffix file, no unknown forms were encountered in the training process, thus providing no training data for forms assigned the open class However, a greater lexicon does not necessarily guarantee a better tagging accuracy Some authors use an optimal dictionary that indicates, for each word, all the tags assigned to it somewhere in the corpus being used, but not other, possible tags  Since our starting point is not a tagged corpus in which to perform the testing of a given stochastic model, our lexicon is not specially biased towards the corpus we aim at tagging Hence, the whole set of tags for each word has been taken into account during lexicon building The lexicon used by the system has been produced by compiling different sources of information, although some coding work has also been performed This lexicon is being used in the actual tagging of the ITU corpus, since it provides a more accurate model to lexical ambiguity than that provided by suffix information alone Training on hidden Markov models of language is performed without a tagged corpus Two such ways implemented in the Xerox Tagger, concerning ambiguity classes and state transitions, are described below: The biasing facts on ambiguity classes are called symbol biases This way, ambiguity classes are annotated with favoured tags The Xerox Tagger uses a statistical method for text tagging Using different values for the number of iterations (the number of times the same block is used in training) and the size of the block of text used for training The choice of the training corpus affects the result Finally, the choice of the training corpus has consequences on the accuracy of the system As demonstrated by , when using an HMM, a greater training corpus does not necessarily guarantee a better accuracy On the contrary, an initial model estimated by performing Relative Frequency (RF) training on a tagged text may degrade if a relatively great untagged corpus is used next Although the decision of tagging the ITU corpus using the full version of the tagset was already adopted and postediting on the corpus so tagged has begun, a parallel development of the tagger with the reduced tagset has been performed The full 1M word subset of the corpus being postedited has been used as the training corpus, leaving file SP_itu_corpus_000 as the test corpus This corpus contains 9,366 tagged tokens The corpus has been used in an incremental way, testing results with each partial model obtained Two types of training have been used with this model1% better accuracy than the full tagset Table 1 shows the behaviour of the system when tagging the test corpus with the full tagset The first one makes use of a tagged training corpus Results, however, are better with a previously trained model A small amount of text is manually tagged and used to train a partially accurate model This model is then used to tag more text; the tags are manually corrected and subsequently used to retrain the model This paper presents results obtained with the port to Spanish of a public domain tagger the Xerox Tagger The second method does not require a tagged training corpus present, using a corpus different to that used for training, results sensibly better for French (96 While use a tagset consisting of 88 tags and a tagset with 42 tags, our tagset has 466 different tags These tagset size may be excesive, specially for a probabilistic tagger, but results obtained with our corpus show similar accuracy, with the value-added benefit for the tagged corpus of having the whole variety of morphosyntactic categories and subcategories reflected in it uses this method for training a text tagger uses word equivalence classes based on parts of speech, to pool data from individual words The number of equivalence classes (referred to as ambiguity classes in HREF= 9505035 The Xerox Tagger is based on an HMM It uses ambiguity classes and a first-order model to reduce the number of parameters to be estimated without significant reduction in accuracy Besides, relatively few ambiguity classes are sufficient for wide coverage, so it is unlikely that adding new words to the lexicon requires retraining, as their ambiguity classes are accomodated Words not found in the lexicon are assigned an ambiguity class according to both context and suffix information The set of tags identifies an ambiguity class, which is also delivered by the lexicon The training module takes long sequences of ambiguity classes as input The tagging module buffers sequences of ambiguity classes between sentence boundaries Words not found in the manually-constructed lexicon are generally both open class and regularly inflected according to HREF= 9505035 A language-specific method can be employed to guess ambiguity classes for these unknown words This function also operates on an untagged training corpus As a final stage, words not found in the lexicon and ending in a suffix not recognized are assigned a default ambiguity class (open class  As already mentioned in the previous section, in case a word is unknown to the system, `suffix' information can be used in order to approximate its possible ambiguity class The above-mentioned function operates on a training text and calculates two parameters: the suffixes themselves the ambiguity class assigned to each suffix In the suffix calculation, the unique parameter that can be controlled is their maximum lenght The ambiguity class to be assigned to each suffix is selected from the set of classes computed during normal training, which is written to a classes file This file contains (i) every tag observed in the lexicon (which is, obviously, unambiguous (ii) every set of ambiguously assigned tags for every form in the lexicon, and (iii) the ambiguity class for the open class (a default class  The above-mentioned function, after computing a suffix, observes words in the lexicon ending in the proposed suffix and the set of tags assigned to them It then eliminates those tags not included in the ambiguity class for the open class and, afterwards, tries to match the remaining tags with one of the existing ambiguity classes If it succeeds, this ambiguity class is assigned to the suffix Conversely, if it fails, the suffix will receive the default ambiguity class If we establish an open class including all nominal, adjectival, and verbal tags, the classes file will contain, along with this open class, the list of individual tags of the tagset, the default ambiguity class, several ambiguity classes formed by 2-tuples, 3-tuples, 4-tuples and a few 5-tuples and 6-tuples This means that computed suffixes must be accomodated into these latter ambiguity classes in order to maximize accuracy in the assignment of tags (the use of the default ambiguity class in these cases will produce incorrect results in most cases  Assuming that a is one of the suffixes computed by the above-mentioned function, the problem then is trying to match the set of tags observed in the lexicon for words ending in a included in the intersection with the default ambiguity class with one of the previously computed classes The former ambiguity class does simply not exist there must exist at least one ambiguous form (ending in a or in another suffix) validating an ambiguity class in order for it to be selected when observed in words ending in a Moreover, in inflectional languages, the selection of the training corpus is also crucial to the issue of suffix calculation However, this prerequisite alone does not guarantee a proper computation of suffixes, since the function operates not only on word tokens from the training corpus but also on the system's lexicon The parameter to be considered in this respect is not the actual size of this lexicon (which, nevertheless, is important in order to accurately assign ambiguity classes to word tokens from a corpus but the set of ambiguity classes represented in that lexicon and this set would not increase with the addition of new words Some systems, like the Xerox Tagger, compute probabilistically both the suffixes and the ambiguity classes associated to them; but others, like the one described in HREF= 9505035html#Weischedel93 &gt;Weischedel et al 1993 include a hybrid approach where suffixes are manually added and ambiguity classes are approximated directly from training data Hence, a new approach could include both manually-computed suffix tables and ambiguity classes, specially for inflectional languages where this information can be straightforwardly obtained, thus improving system accuracy The selection of the training corpus and the results obtained are also discussed