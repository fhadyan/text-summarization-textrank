 All results are for the IBM data The data consisted of training and test files of 20801 and 3097 quintuples respectively An iterative, unsupervised method was then used to decide between noun and verb attachment for each triple The decision was made as follows: If then choose noun attachment, else choose verb attachment The test used in can then be stated as follows in our notation: If then choose noun attachment, else choose verb attachment The backed-off method based on just the f(v,p) and f(n1,p) counts would be: If then choose noun attachment, else choose verb attachment, where An experiment was implemented to investigate the difference in performance between these two methods This gave 1924 test cases In particular, quadruples and triples seen in test data will frequently be seen only once or twice in training data This set was used during development of the attachment algorithm, ensuring that there was no implicit training of the method on the test set itself The training and test data were both the unprocessed, original data sets A particularly surprising result is the significance of low count events in training data Finally, more training data is almost certain to improve results All results in this section are on the IBM training and test data, with the exception of the two `average human' results `Always noun attachment' means attach to the noun regardless of (v,n1,p,n2  `Most likely for each preposition' means use the attachment seen most often in training data for the preposition seen in the test quadruple Counts of lower order tuples can also be made - for example f(1,P=from)is the number of times (P=from) is seen with noun attachment in training data, f(V=is,N2=research) is the number of times (V=is,N2=research) is seen with either attachment and any value of N1 and P A maximum likelihood method would use the training data to give the following estimation for the conditional probability: Unfortunately sparse data problems make this estimate useless A quadruple may appear in test data which has never been seen in training data (In this experiment about 95% of those quadruples appearing in test data had not been seen in training data  The attachment decisions for these triples were unknown, so an unsupervised training method was used (section 5 Two human judges annotated the attachment decision for 880 test examples, and the method performed at 80% accuracy on these cases use 12,000 training and 500 test examples (Typical examples would be `If P=of then choose noun attachment' or `If V=buy and P=for choose verb attachment  Transformations (using words only) score 819% on the IBM data used in this paper use the data described in section 2 The training and test data were supplied by IBM, being identical to that used in  Each sub-tuple predicts noun or verb attachment with a weight indicating its strength of prediction - the weights are trained to maximise the likelihood of training data For example (P=of) might have a strong weight for noun attachment, while (V=buy,P=for) would have a strong weight for verb attachment Results of 77 The backed-off estimate is a method of combating the sparse data problem For each such VP the head verb, first head noun, preposition and second head noun were extracted, along with the attachment decision (1 for noun attachment, 0 for verb  Else (default is noun attachment  The decision is then: If choose noun attachment