 The importance of good preference functions for ranking competing analyses produced by language processing systems grows as the coverage of these systems improves Suppose that a function M has a tendency to give high scores to correct QLFs when the contributions of other functions do not clearly favour any QLF, but that M tends to perform much less well when other functions come up with a clear choice The least-squares scaling factors are therefore adjusted iteratively by a hill-climbing procedure that directly examines the QLF choices they give rise to on the training corpus Scaling factors are altered one at a time in an attempt to locally optimise the number of correct disambiguation decisions, i the number of training sentences for which a QLF with a correct skeletal tree receives the highest score By collecting these intervals for all the functions and for all the sentences in the training corpus, one can determine the effect on the number of correct disambiguation decisions of any alteration to any single scaling factor One of the functions we used shows the limitations of least-squares scaling factor optimisation, alluded to above, in quite a dramatic way The function in question returns the number of temporal modifiers in a QLF The performance of each set of factors was evaluated as follows Each preference function is defined as a numerical (possibly real-valued) function on representations corresponding to the sentence analyses A weighted sum of these functions is then used as the overall measure to rank the possible analyses of a particular sentence Data collection for the semantic collocation functions proceeds by deriving a set of triples from each QLF analysis of the sentences in the training set This is followed by statistical analysis to produce the following functions of each triple in the observed triple population The first two functions have been used in other work on collocation; some authors use simple pairs rather than triples (i We refer to the coefficients, or weights, used in this linear combination as the scaling factors for the functions This variant of , in which the numerator is signed, is used so that the function is monotonic, making it more suitable in preference functions Mean distance: the average of the relativised training score for all QLF analyses (not necessarily highest ranked ones) which include the semantic collocation corresponding to the triple From these five functions on triples we define five semantic collocation preference functions applied to QLFs, in each case by averaging over the result of applying the function to each triple derived from a QLF We refer to these functions by the same names as their underlying functions on triples The collocation functions are normalized by multiplying up by the number of words in the sentence to which the function is being applied This normalization keeps scores for QLFs in the same sentence comparable, while at the same time ensuring the triple function scores tend to grow with sentence length in the same way that the non-collocation functions tend to do Thus the optimality of a set of scaling factors is relatively insensitive to sentence length Our use of the mean distance function was motivated by the desire to take into account additional information from the training material which is not exploited by the other collocation functions In contrast, the other collocation functions only make use of the training score to select the best analysis of a sentence, discarding the rest The syntactic rule cost function is significantly worse than all the collocational functions except the mutual information one, for which the difference is not significant either way (There may, of course, exist better syntactic functions than the one we have tried The mean distance function is much superior to all the others when acting alone However, this similarity in the results should be taken with some caution, because our syntactic preference function is rather crude, and because our best semantic function (mean distance) uses the additional information mentioned above When one collocation function is selected to act together with the nineteen non-collocation-based functions from the default set (the set defined in section and used in the experiments on scaling factor calculation) the picture changes slightly However, the difference between the and functions is no longer quite so clear cut, and the relative advantage of the mean distance function compared with the function is less It may be that other preference functions make up for some shortfall of the function that is, at least in part, taken account of by the mean distance function Large scale rule based analysis systems have therefore tended to employ a collection of functions to produce a score for sorting analyses in a preference order Until recently, the choice of the various functions used in rule based systems was made mainly according to anecdotal information about the effectiveness of, for example, various attachment preference strategies We have presented a relatively simple analytic technique for automatically determining a set of scaling factors for preference functions used in semantic disambiguation We have also confirmed empirically that considerable differences exist between the effectiveness of differently formulated collocation functions for disambiguation The experiments provide a basis for selecting among different collocational functions, and suggest that a collocation function must be evaluated in the context of other functions, rather than on its own, if the correct selection is to be made There is now more empirical work comparing such functions, particularly in the case of functions based on statistical information about lexical or semantic collocations The results we present show that these functions vary considerably in disambiguation accuracy, but that the best collocation functions are more effective than a function based on simple estimates of syntactic rule probabilities In this paper we address two issues relating to the application of preference functions Finally we take a close look at a set of semantic collocation functions, defining them in in section and comparing their effectiveness at disambiguation in section  Another reason for choosing ATIS was that it consists of several thousand sentences in a constrained discourse domain, which helped avoid sparseness problems in training collocation functions QLFs express semantic content, but are derived compositionally from complete syntactic analyses of a sentence and therefore mirror much syntactic structure as well However, the use of QLF analyses is not central to our method: the important thing is that the representation used is rich enough to support a variety of preference functions It consists of one collocation-based function and nineteen non-collocation-based ones The work described in section involved substituting single alternative collocation-based functions for the single one in the set of twenty There are also some real-valued functions, including the semantic collocation functions discussed in section  Four functions return non-zero scores on these analyses A fourth, SemColl, is a semantic collocation function McCord ( ) gives very specific information about the weights he uses to combine preference functions, though these weights are chosen by hand We do not directly address here the problems of applying preference functions to select the best analysis when none is completely correct; we assume, based on our experience with the spoken language translator, that functions and scaling factors trained on cases where a completely correct analysis exists will also perform fairly well on cases where one does not Employing treebank analyses in the training process required defining a measure of the degree of correctness of a QLF analysis under the assumption that the phrase-structure analysis in the treebank is correct When we first implemented a disambiguation mechanism of the kind described above, an initial set of scaling factors was chosen by hand according to knowledge of how the particular raw preference functions were computed and introspection about the `strength' of the functions as indicators of preference Another problem was that it became difficult to detect preference functions that were ineffective, or simply wrong, if they were given sufficiently low scaling factors Probably a more serious problem is that the contributions of different preference functions to selecting the most plausible analyses seem to vary from one sublanguage to another These disadvantages point to the need for automatic procedures to determine scaling factors that optimise preference function rankings for a particular sublanguage In our framework, a numerical `preference score' is computed for each of the alternative analyses, and the analyses are ranked according to this score As mentioned earlier, the preference score is a weighted sum of a set of preference functions: Each preference function fj takes a complete QLF representation qi as input, returning a numerical score sij, the overall preference score being computed by summing over the product of function scores with their associated scaling factors cj: The training process begins by analysing the corpus sentences and computing, for each analysis of each sentence, the training score of the analysis with respect to the manually-approved skeletal tree and the (unscaled) values of the preference functions applied to that analysis One source of variation in the data that we want to ignore in order to derive scaling factors appropriate for selecting QLFs is the fact that preference function values for an analysis often reflect characteristics shared by all analyses of a sentence, as much as the differences between alternative analyses For example, a function that counts the occurrences of certain constructs in a QLF will tend to give higher values for QLFs for longer sentences In the limit, one can imagine a function that, for an N-word sentence, returned a value of N+G for a QLF with training score G with respect to the skeletal tree Such a function, if it existed, would be extremely useful, but (if sentence length were not also considered) would not be a particularly accurate predictor of QLF training score In order to discount irrelevant intersentence variability, both the training score with respect to the skeletal tree and all the preference function scores are therefore relativised by subtracting from them the corresponding values for the analysis of that sentence which best matches the skeletal tree The relativised training score is the distance function with respect to which the first stage of scaling factor calculation takes place It can be seen that the relativised results of our hypothetical preference function are a perfect predictor of relativised training score Suppose also that the training scores and the scores assigned by preference functions, , f1 and f2 are as follows: An initial set of scaling factors is calculated in a straightforward analytic way by approximating gi, the relativised training score of qi, by , where cj is the scaling factor for preference function fj and zij is the relativised score assigned to qi by fj