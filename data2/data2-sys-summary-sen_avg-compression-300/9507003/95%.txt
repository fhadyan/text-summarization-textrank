 The notion of robustness in natural language processing is a rather broad one and lacks a precise definition information decrease Whereas Constraint Grammar restricts itself to purely syntactic means, an integration of simple semantic criteria into Constraint Dependency Grammar has been proposed recently  The following small and rather rigid sample grammar illustrates the different types of constraints needed: 1 sy1 through sy3 are unary constraints, sy4 is a binary one In a very similar fashion semantic constraints comprise 1 Semantic constraints need not be restricted to linguistically motivated (i On the semantic layer only the licensing constraint se1 is declared as a strict one Hence, structural interpretations violating a high number of rather strong constraints are pruned first Using the toy grammar specified above together with its penalty scores the arbitration process between syntactic and semantic evidence in simple disambiguation problems can be studied This interpretation, however, happens to be a rather fragile one and breaks immediately under arbitrary syntactic variation On the other hand, constraint relaxation techniques rely on a systematic variation of existing grammar rules written for standard input agreement conditions in syntactic rules Psycholinguistic evidence provides a contradictory picture of human language processing Parallel and autonomous structures in language processing have not only evolved between syntactic and semantic aspects of language Expectations exchanged between parallel and autonomous processing structures for syntax and semantics Since syntactic and semantic restrictions are conjunctively combined the overall vulnerability against arbitrary impairment of the input utterances even increases: An analysis may now fail due to syntactic as well as due to semantic reasons It combines syntactic, semantic and even pragmatic information in a single representation named construction