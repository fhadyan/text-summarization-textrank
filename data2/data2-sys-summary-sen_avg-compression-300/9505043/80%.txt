 The goal of an Information Extraction (IE) system is to identify information of interest from a collection of texts Recall is the percentage of information in a text that is correctly extracted by a system; precision is the percentage of information extracted by a system that is correct where the answer key for each text contains a set of phrases and the coreference links among them However, evaluation of coreference performance is complicated by the need to take into account the implicit coreference links among phrasese what fraction of correct coreference links is implied by the transitive closure of the coreference links in the system responsee what fraction of coreference links in the response is implied by the transitive closure of the coreference links in the key One of the problems with these coreference resolution components was figuring out which features of the phrases to look at when determining coreference As was noted earlier, the MUC-5 coreference rules were designed to minimize false positives The comparative effects of false positives and false negatives in coreference classification on overall IE system performance remains an open question high precision in overall IE system performance, the F-measure score that gives equal weight to recall and precision may be the best indicator of overall performance on the coreference resolution task One of the original goals of this new approach was to develop a system that achieved good performance in resolving references - performance that was at least as good as the performance achieved using manually engineered rules in our MUC-5 system We are encouraged by the performance of the decision trees on the coreference resolution problem In an effort to address these problems, a new approach to coreference resolution was begun after the MUC-5 evaluation: a system named RESOLVE was created to build decision trees that can be used to classify pairs of phrases as coreferent or not coreferent The errors generated by the sentence analyzer were eliminated by using a special tool - the Coreference Marking Interface, or CMI - to extract a set of phrases from the MUC-5 English Joint Venture (EJV) corpus RESOLVE used the C45 decision tree system to learn how to classify coreferent phrases for the experiments reported in this paper An experiment was conducted to compare the performance of the decision trees generated by RESOLVE with the performance of manually engineered rules used for coreference classification in the UMass/Hughes MUC-5 IE system A set of references, along with the coreference links among these, were extracted from a group of texts via CMI The pairings that contained coreferent phrases formed positive instances, while those that contained two non-coreferent phrases formed negative instances The references marked via CMI were converted into a memory token representation in order to test the performance of the MUC-5 system's coreference module The data used in this experiment was based on a set of phrases extracted using CMI The phrases underlined in this sentence contain relevant information that must be extracted by an IE system Some phrases are multireferent, i Thus for a set of phrase pairs which share a given phrase, more than one pair would be classified as a positive instance of coreference Further complications are created for evaluating the performance of a coreference system when multireferent phrases are included in the data (see Section  The coreference module of the UMass/Hughes MUC-5 IE system was designed to minimize false positives, ie minimize the likelihood that two phrases that were not coreferent would be labeled coreferent This design decision was based on the assumption that false positive errors, resulting in the merging of non-coreferent phrases in the final system output, would harm system performance more than false negative errors, which would result in coreferent phrases showing up in distinct objects in the system output Another factor influencing the coreference module was the short time allotted to developing and testing this system component The rules used to determine whether two phrases (represented as memory tokens) were coreferent in the MUC-5 system are shown in Table  One of the many difficulties in developing the rule set for coreference classification was in ordering the rules Since this experiment involved a comparison between RESOLVE and a manually engineered rule set, the features used in this experiment were based on the antecedents of the coreference rules used in the UMass/ Hughes MUC-5 IE system Since the two phrases are not coreferent, this represents a negative instance COMMON-NP: Do the references share a common noun phrase? Some references contain non-simple noun phrases, e Coreference is a symmetrical and transitive relation that holds among a set of two or more references, e