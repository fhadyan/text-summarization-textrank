 The NLP tasks where SRs utility could be evaluated are diverse However, we have tested SRs on a WSS task, using the following scheme Previous knowledge used A semantic hierarchy (WordNet) where words are clustered in semantic classes, and semantic classes are organized hierarchically As evaluation measures we used coverage, abstraction ratio, and recall and precision ratios on the WSS task (section  In addition we performed some evaluation by hand comparing the SRs acquired by the different techniques Coverage for the different techniques is shown in table  The labels used for referring to the different techniques are as follows: Assoc p(c|s corresponds to the basic association measure (section Assoc Head-nouns and Assoc All nouns to the techniques introduced in section , Assoc Normalizing to the local normalization (section and finally, log-likelihood, D (relative entropy) and I (mutual information ratio) to the techniques discussed in section  Polysemous words are represented as instances of different classes The abstraction ratio for the different techniques is shown in table  In principle, the higher abstraction ratio, the better the technique succeeds in filtering out incorrect senses (less Abs  The precision and recall ratios on the noun WSS task for the different techniques are shown in table  In principle, the higher the precision and recall ratios the better the technique succeeds in inducing appropriate SRs for the disambiguation task The local normalizing technique using the uniform distribution does not help Output A set of syntactic SRs, (verb-lemma, syntactic-relationship, semantic-class, weight  However, a better informed kind of local weight (section ) should improve the technique significantly All versions of Assoc (except the local normalization) get good results Specially the two techniques that exploit a simpler prior distribution, which seem to improve the basic technique We were also interested in measuring the impact of thresholding on the SRs acquired In figure we can see the different evaluation measures of the basic technique when varying the threshold The final SRs must be mutually disjoint Both decrease when threshold increases, probably because when the rejecting threshold is low, small classes that fit the data well can be induced, learning over-general or incomplete SRs otherwise In terms of WSS, general classes may be performing better than classes that fit the data better In this paper we have presented some variations affecting the association measure and thresholding on the basic technique for learning SRs from on-line corpora We proposed some evaluation measures for the SRs learning task We can conclude that some of these variations seem to improve the results obtained using the basic technique SRs are weighted according to the statistical evidence found in the corpus Future lines of research will mainly concentrate on improving the local normalization technique by solving the noun sense ambiguity Combining the different n-grams by means of smoothing techniques Creation of the space of candidate classes Selection of the most appropriate subset in the candidate space to convey the SRs The appropriateness of a class for expressing SRs (stage 2) is quantified from the strength of co-occurrence of verbs and classes of nouns in the corpus  Ribas reported experimental results obtained from the application of the above technique to learn SRs He performed an evaluation of the SRs obtained from a training set of 870,000 words of the Wall Street Journal For instance, table shows the SRs acquired for the subject position of the verb seek Assoc corresponds to the association score (higher values appear first  Most of the induced classes are due to incorrect senses Analyzing the results obtained from different experimental evaluation methods, Ribas drew up some conclusions: a The aim of our work is to explore the feasibility of using an statistical method for extracting SRs from on-line corpora The technique achieves a good coverage Most of the classes acquired result from the accumulation of incorrect senses It makes the association score prefer incorrect classes and jump on over-generalizations The different techniques are experimentally evaluated in section  Resnik developed a method for automatically extracting class-based SRs from on-line corpora Specifically, the Assoc' takes into account the preference (selection) of syntactic positions for particular classes Ribas performed some experiments using this basic technique and drew up some limitations from the corresponding results Local weight could be obtained using p(c|n  In this section we propose the application of other measures apart from Assoc for learning SRs: log-likelihood ratio , relative entropy , mutual information ratio ,  Different association measures use the information provided in the cross-table to different extents Evaluation of the SR learning task would provide grounds to compare different techniques that try to abstract SRs from corpus using WordNet (eg, section  It would also permit measuring the utility of the SRs obtained using WordNet in comparison with other frameworks using other kinds of knowledgeg, analysis  SRs are useful for both lexicography and NLPe how well the resulting classes correspond to the nouns as they were used in the corpus  As far as lexicography (quality) is concerned, we think the main criteria SRs acquired from corpora should meet are: (a) correct categorization -inferred classes should correspond to the correct senses of the words that are being generalized (b) appropriate generalization level and (c) good coverage -the majority of the noun occurrences in the corpus should be successfully generalized by the induced SRs Besides the intrinsic difficulties of this approach, it does not seem appropriate when comparing across different techniques for learning SRs, because of its qualitative flavor Quantification of generalization level appropriateness A possible measure would be the percentage of sense occurrences included in the induced SRs which are effectively correct (from now on called Abstraction Ratio  Hopefully, a technique with a higher abstraction ratio learns classes that fit the set of examples better Quantification of coverage It could be measured as the proportion of triples whose correct sense belongs to one of the SRs