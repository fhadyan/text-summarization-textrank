g , ,  The TRAINS System is a large integrated natural language conversation and plan reasoning system The dialogue manager is responsible for maintaining the flow of conversation and making sure that the conversational goals are met Each utterance will generally contain acts (or partial acts) at each of these levels The over-riding goal for the TRAINS domain is to construct and execute a plan that is shared between the two participants As shown above, though, new obligations will need to be addressed before performing intended actions Obligations might also lead directly to immediate action For the discourse actor, special consideration must be given to the extra constraints that participation in a conversation imposes Discourse Obligations from Table 2 Several approaches have been suggested to account for this behavior Weak Obl: Grounding (coordinate mutual beliefs) 5 Discourse Goals: Domain Plan Negotiation 6g the observance of a new utterance from the userg the acceptance, rejection, or clarification  This might, of course, end up in releasing the turn If all accessible utterances are grounded, the actor then considers the negotiation of domain beliefs and intentions (lines 9-10  Utterance 1 is interpreted as performing two Core Speech Acts Figure shows the relevant parts of the discourse state after interpretation of this utterance The resulting discourse context (after the system decides to acknowledge) is shown in Figure  Yet, typically agents will still respond in such situations The reasoning leading up to utterance 14 is similar to that leading to utterance 2 When the system decided to acknowledge, this creates a discourse obligation to address the request The discourse state after the decision to acknowledge is shown in Figure  The default behavior is to allow the user to maintain the initiative through the plan construction phase of the dialogue We can illustrate the system behaving more on the basis of goals than obligations with a modification of the previous exampleg a choice of the particular engine or boxcar to use  Assuming that the user still has not taken the turn back, the system can now propose these new items to the user If a proposal is rejected, the system can negotiate and offer a counterproposal or accept a counter proposal from the user Obligations do not replace the plan-based model, but augment it Some researchers, e Representing both obligations and goals explicitly allows the system to naturally shift from one mode to the other It is left unexplained what goals motivate conversational co-operation When planning, an agent considers both its goals and obligations in order to determine an action that addresses both to the extent possibleg consider most politicians at press conferences  The intentional story account of this goes as follows Obligations also cannot be reduced to simple expectations, although obligations may act as a source of expectations We use a set of rules that encode discourse conventions Some obligation rules based on the performance of conversation acts are summarized in Table g the architecture proposed by  There are a large number of strategies which may be used to incorporate obligations into the deliberative process, based on how much weight they are given compared to the agents goals For instance, consider an agent with an intention to do something as soon as possible We have built a system that explicitly uses discourse obligations and communicative intentions to partake in natural dialogue