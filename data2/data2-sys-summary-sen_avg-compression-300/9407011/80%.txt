g , ,  This provides an elegant account in the simple case, but requires a strong assumption of co-operativeness The TRAINS System is a large integrated natural language conversation and plan reasoning system Figure illustrates the system from the viewpoint of the dialogue manager The dialogue manager is responsible for maintaining the flow of conversation and making sure that the conversational goals are met For this system, the main goals are that an executable plan which meets the user's goals is constructed and agreed upon by both the system and the user and then that the plan is executed Agent A must adopt agent B's goals as her own Each utterance will generally contain acts (or partial acts) at each of these levels When the intentions are formed, the obligations are removed from the stack, although they have not yet actually been met The over-riding goal for the TRAINS domain is to construct and execute a plan that is shared between the two participants As shown above, though, new obligations will need to be addressed before performing intended actions Obligations might also lead directly to immediate action If there are no obligations, then the agent will consider its intentions and perform any actions which it can to satisfy these intentions For the discourse actor, special consideration must be given to the extra constraints that participation in a conversation imposes Discourse Obligations from Table 2 Several approaches have been suggested to account for this behavior Weak Obl: Grounding (coordinate mutual beliefs) 5 Discourse Goals: Domain Plan Negotiation 6 High-level Discourse Goals The implemented actor serializes consideration of these sources into the algorithm in Figure g the observance of a new utterance from the userg the acceptance, rejection, or clarification  In certain cases, though, such as a repair, the system will actually try to take control of the turn and produce an utterance immediately Others have tried to account for this kind of behavior using social intentional constructs such as Joint intentions or Shared Plans  This might, of course, end up in releasing the turn If all accessible utterances are grounded, the actor then considers the negotiation of domain beliefs and intentions (lines 9-10  The actor will try to work towards a shared domain plan, adding intentions to perform the appropriate speech acts to work towards this goal If none of the more local conversational structure constraints described above require attention, then the actor will concern itself with its actual high-level goals It is also at this point that the actor will take control of the conversation, pursuing its own objectives rather than responding to those of the user Utterance 1 is interpreted as performing two Core Speech Acts It is interpreted (literally) as the initiation of an inform about an obligation to perform a domain action (shipping the oranges  Figure shows the relevant parts of the discourse state after interpretation of this utterance Finally, the system acts on the intentions produced by these deliberations (lines 5-6) and produces the combined acknowledgement/acceptance of utterance 2 The resulting discourse context (after the system decides to acknowledge) is shown in Figure  Yet, typically agents will still respond in such situations The reasoning leading up to utterance 14 is similar to that leading to utterance 2 Utterances 15-2=4, 15-5=7, and 15-8=10 are interpreted as requests because of the imperative surface structure The discourse obligation to address the request is incurred only when the system decides to acknowledge the utterances and ground them Utterance 17 is interpreted as a request for evaluation of the plan When the system decided to acknowledge, this creates a discourse obligation to address the request An agent has certain goals, and communication results from a planning process to achieve these goals This is then generated as 18-3 The discourse state after the decision to acknowledge is shown in Figure  However this architecture can handle varying degrees of initiative, while remaining responsive The default behavior is to allow the user to maintain the initiative through the plan construction phase of the dialogue We can illustrate the system behaving more on the basis of goals than obligations with a modification of the previous exampleg a choice of the particular engine or boxcar to use  Assuming that the user still has not taken the turn back, the system can now propose these new items to the user If a proposal is rejected, the system can negotiate and offer a counterproposal or accept a counter proposal from the user Obligations do not replace the plan-based model, but augment it Some researchers, e In particular, much of local discourse behavior can arise in a reactive manner without the need for complex planning Representing both obligations and goals explicitly allows the system to naturally shift from one mode to the other It is left unexplained what goals motivate conversational co-operation We are developing an alternate approach that takes a step back from the strong plan-based approach We believe that people have a much more complex set of motivations for action One responds to a question because this is a social behavior that is strongly encouraged as one grows up, and becomes instilled in the agent When planning, an agent considers both its goals and obligations in order to determine an action that addresses both to the extent possible Returning to the example about questions, when an agent is asked a question, this creates an obligation to respond Rather it is a constraint on the actions that the agent may plan to dog consider most politicians at press conferences  An action that might occur or not-occur according to R is neither obligatory nor forbidden Obligations are quite different from and can not be reduced to intentions and goals The intentional story account of this goes as follows Obligations also cannot be reduced to simple expectations, although obligations may act as a source of expectations Our model of obligation is very simple We use a set of rules that encode discourse conventions We use a simple forward chaining technique to introduce obligations Some obligation rules based on the performance of conversation acts are summarized in Table  A question establishes an obligation to answer the question If an utterance has not been understood, or is believed to be deficient in some way, this brings about an obligation to repair the utteranceg the architecture proposed by  There are a large number of strategies which may be used to incorporate obligations into the deliberative process, based on how much weight they are given compared to the agents goals For instance, consider an agent with an intention to do something as soon as possible We have built a system that explicitly uses discourse obligations and communicative intentions to partake in natural dialogue