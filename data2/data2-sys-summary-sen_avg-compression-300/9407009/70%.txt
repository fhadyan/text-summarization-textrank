 Most spoken language translation systems rely on a pipelined architecture, including speech recognition, linguistic analysis, transfer, generation and speech synthesis218 = 0 In actual fact, however, the error rate is (1 - 539/1001) = 0462 = 1 It is not immediately clear why these strong correlations exist If this were so, one would expect the effect to be less pronounced if the long utterances were removed All of them were significant at the P=00005 level Speech recognition 577 utterances (839 were acceptably recognized6 received a QLF The ratio of error rates is 46 passed grammar specialization; 54 of the 75 relevant incorrectly recognized utterances did so (72 The ratio of error rates is 4 The ratio of error rates is 2 The naive model predicts a combined error rate of 45 Thus the naive model overestimates the error rate by a factor of 119, an even larger difference than for the entire set This made it possible to perform statistical analysis contrasting the results of inputs corresponding to correct and incorrect upstream processing There are several interesting conclusions to be drawn from the results presented above Most obviously, pipelined systems are clearly doing rather better than the naive model predicts For example, the error rates for the linguistic analysis phase, applied to correctly and incorrectly recognized utterances respectively, differed by a factor of about 30005 level Predicting the system error rate on the independence assumption by simple multiplication resulted in a 16% proportional overestimate for all utterances, and a 19% overestimate for the 1-10 word utterances The system is constructed from a set of general-purpose speech and language processing components The main components are the SRI DECIPHER(TM) system (speech recognition two copies of the SRI Core Language Engine (CLE) (source and target language processing and the Telia Research Prophon system (speech synthesis  It outputs to the source language processor an N-best list of sentence hypotheses generated using acoustic and bigram language model scores The CLE is a sophisticated unification-based language processing system which incorporates a broad-coverage domain-independent grammar for English  In the SLT system, the general CLE grammar is specialized to the domain using the Explanation-Based Learning (EBL) algorithm  We focussed our investigations on four conceptual functionalities in the system: speech recognition, source language analysis, grammar specialization, and transfer-and-generation The error rate for each functionality was defined as follows: Speech recognition Proportion of utterances for which the preferred N-best hypothesis is not an acceptable variant of the transcribed utterance Source language analysis Proportion of input utterance hypotheses that do not receive a semantic analysis Grammar specialization Proportion of input utterance hypotheses receiving an analysis with the normal grammar that receive no analysis with the specialized grammar Transfer-and-generation Proportion of input utterance hypotheses receiving an analysis with the normal grammar that do not produce an acceptable translation The basic method for establishing correlations among processing functionalities was to contrast results between two sets of inputs, corresponding to i) correct upstream processing and ii) incorrect but correctable upstream processing respectively The simplest example is provided by the linguistic processing phase Of the 1001 utterances, 789 were recognized acceptably, and 212 unacceptably Thus one can conclude that utterances failing recognition would anyway be 35 times as likely to fail linguistic processing as well Moving on to the grammar specialization phase, there are two possible types of upstream error for a given utterance: recognition can fail, or the utterance can be out of coverage for the general (unspecialized) grammar Only the first type of error is correctable So the meaningful population of examples is the set of 706 + 135 = 841 utterances for which a QLF is produced assuming correct recognition8 passed grammar specialization The ratio of error rates, 3 For the transfer-and-generation phase, the population of meaningful examples is again 841, but this time there are two types of correctable upstream error: either recognition or grammar specialization can fail Of the 653 examples with no upstream error, 539 (825 produced a good translation; of the 841 - 653 = 188 examples with a correctable upstream error, 119 (63 The ratio of error rates, 2 If we calculate error rates for each phase over the whole population of meaningful examples (correct upstream processing + correctable upstream errors we get the following figures Recognition 1001 examples; 789 successes; error rate = 21 Linguistic analysis 1001 examples; 706 + 135 = 841 successes; error rate = 15 Grammar specialization 841 examples; 653 + 101 = 754 successes; error rate = 10 Transfer and generation 841 examples; 539 + 119 successes; error rate = 21 On the naive model, the error rate for the whole system should be (1 - (1 - 0