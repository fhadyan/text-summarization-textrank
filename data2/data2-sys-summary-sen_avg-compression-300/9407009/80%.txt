 Most spoken language translation systems rely on a pipelined architecture, including speech recognition, linguistic analysis, transfer, generation and speech synthesis218 = 0462 = 1 It is not immediately clear why these strong correlations exist If this were so, one would expect the effect to be less pronounced if the long utterances were removed All of them were significant at the P=00005 level Speech recognition 577 utterances (839 were acceptably recognized6 received a QLF The ratio of error rates is 46 passed grammar specialization; 54 of the 75 relevant incorrectly recognized utterances did so (72 The ratio of error rates is 4 The ratio of error rates is 2 The naive model predicts a combined error rate of 45 Thus the naive model overestimates the error rate by a factor of 119, an even larger difference than for the entire set There are several interesting conclusions to be drawn from the results presented above Most obviously, pipelined systems are clearly doing rather better than the naive model predicts For example, the error rates for the linguistic analysis phase, applied to correctly and incorrectly recognized utterances respectively, differed by a factor of about 3 Predicting the system error rate on the independence assumption by simple multiplication resulted in a 16% proportional overestimate for all utterances, and a 19% overestimate for the 1-10 word utterances The system is constructed from a set of general-purpose speech and language processing components The main components are the SRI DECIPHER(TM) system (speech recognition two copies of the SRI Core Language Engine (CLE) (source and target language processing and the Telia Research Prophon system (speech synthesis  The CLE is a sophisticated unification-based language processing system which incorporates a broad-coverage domain-independent grammar for English  We focussed our investigations on four conceptual functionalities in the system: speech recognition, source language analysis, grammar specialization, and transfer-and-generation Source language analysis Proportion of input utterance hypotheses that do not receive a semantic analysis Grammar specialization Proportion of input utterance hypotheses receiving an analysis with the normal grammar that receive no analysis with the specialized grammar The basic method for establishing correlations among processing functionalities was to contrast results between two sets of inputs, corresponding to i) correct upstream processing and ii) incorrect but correctable upstream processing respectively Thus one can conclude that utterances failing recognition would anyway be 3 Only the first type of error is correctable8 passed grammar specialization The ratio of error rates, 3 Of the 653 examples with no upstream error, 539 (825 produced a good translation; of the 841 - 653 = 188 examples with a correctable upstream error, 119 (63 The ratio of error rates, 2 If we calculate error rates for each phase over the whole population of meaningful examples (correct upstream processing + correctable upstream errors we get the following figures Recognition 1001 examples; 789 successes; error rate = 21 Linguistic analysis 1001 examples; 706 + 135 = 841 successes; error rate = 15 Grammar specialization 841 examples; 653 + 101 = 754 successes; error rate = 10 Transfer and generation 841 examples; 539 + 119 successes; error rate = 21