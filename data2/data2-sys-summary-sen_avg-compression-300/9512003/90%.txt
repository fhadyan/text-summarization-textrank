 In the cache model, popping only occurs via displacement As a potential alternative to the stack model, the cache model appears to be unable to handle return pops since a previous state of the cache can't be popped to Thus, return pops are not problematic for the cache model 88,89 The occurrence of IRUs as in dialogue C is one way of doing this This squib has discussed the role of limited attention in a computational model of discourse processing The cache model was proposed as a computational implemention of human working memory and operations on attentional state are formulated as operations on a cache The notion of processing effort for retrieval operations on main memory makes predictions that can be experimentally tested Here, I propose an alternate model to the stack model, which I will call the CACHE MODEL, and discuss the evidence for this model The CACHE represents working memory and MAIN MEMORY represents long-term memory The cache is a limited capacity, almost instantaneously accessible, memory store There are three operations involving the cache and main memory Items in the cache can be preferentially RETAINED and items in main memory can be RETRIEVED to the cache Items in the cache can also be STORED to main memory Displaced items are stored in main memory The cache model includes specific assumptions about processing New intention subordinate to current intention: (1) Stack pushes new focus space; (2) Cache retrieves entities related to new intention Intention completed: (1) Stack pops focus space for intention from stack, entities in focus space are no longer accessible; (2) Cache doesn't retain entities for completed intention, but they remain accessible until displaced New intention subordinate to prior intention: (1) Stack pops focus spaces for intervening segments, focus space for prior intention accessible after pop; (2) Cache retrieves entities related to prior intention from main memory to cache, unless retained in the cache Informationally redundant utterances: (1) Stack predicts no role for IRUs when they are represented in focus space on top of stack, because information should be immediately available; (2) Cache predicts that IRUs reinstantiate or refresh known information in the cache Returning from interruption: (1) In the stack model, the length and depth of the interruption and the processing required is irrelevant; (2) In the cache model, the length of the interruption or the processing required predicts retrievals from main memory First, consider the differences in the treatment of interruptions