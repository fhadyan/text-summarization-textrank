 An LR parser (Briscoe Carroll, 1993) was applied to unlabelled bracketed sentences from the Susanne treebank, and a new treebank of 1758 correct and complete analyses with respect to the integrated grammar was constructed semi-automatically by manually resolving the remaining ambiguities 250 sentences from the new treebank, selected randomly, were kept back for testing The probabilistic parser was tested on the 250 sentences held out from the manually-disambiguated treebank (of lengths 3-56 tokens, mean 18 Table shows the results of this test with respect to the original Susanne bracketings using the Grammar Evaluation Interest Group scheme (GEIG, see e Harrison et al 1991  In this latter figure, the mean number of crossings (041) is greater than zero mainly because of incompatibilities between the structural representations chosen by the grammarian and the corresponding ones in the treebank71 and the recall and precision rise to 83-84 as shown in table  Black et al (The appendix gives an indication of the diversity of the sentences in our corpus  In addition, Schabes et al To date, no robust parser has been shown to be practical and useful for some NLP task Brill, 1994) require similar amounts (Gaizauskas, pc  Nevertheless, the number of parameters in the probabilistic model is large: it is the total number of possible transitions in an LALR(1) table containing over 150000 actions We started at the full amount (3793 trees and then successively halved it by selecting the appropriate number of trees at random Secondly, removal of punctuation from the input (after segmentation into text sentences) worsens performance as punctuation both reduces syntactic ambiguity (Jones, 1994) and signals non-syntactic (discourse) relations between text units (Nunberg, 1990  random choice 0% and 752% respectively, with respect to the original Susanne bracketings Although this is a different set of sentences, it is likely that the upper asymptote for accuracy for the test corpus lies in this region In this paper we have outlined an approach to robust domain-independent parsing, in which subcategorisation constraints play no part, resulting in coverage that greatly improves upon more conventional grammar-based approaches to NL text analysis We described an implemented system, and evaluated its performance along several different dimensions We have made good progress in increasing grammar coverage, though we have now reached a point of diminishing returns In the application we are currently using the system for automatic extraction of subcategorisation frames, and more generally argument structure, from large amounts of text (Briscoe Carroll, 1996 we do not need full coverage; 70-80% appears to be sufficient However, further improvements in coverage will require some automated approach to rule induction driven by parse failure The current coverage the proportion of sentences for which at least one analysis was found of this system on a general corpus (e Although we report promising results, parse selection that is sufficiently accurate for many practical applications will require a more lexicalised system This grammar compiles into a DCG-like grammar of approximately 400 rules Jackendoff, 1977 by Chomsky-adjunction of adjuncts to maximal projections (XP XP Adjunct Nunberg (1990) develops a partial `text' grammar for English which incorporates many constraints that (ultimately) restrict syntactic and semantic interpretation We have developed a declarative grammar in the ANLT metagrammatical formalism, based on Nunberg's procedural description This grammar captures the bulk of the text-sentential constraints described by Nunberg with a grammar which compiles into 26 DCG-like rules Briscoe Carroll (1993) describe a probablistic parser using a wide-coverage unification-based grammar of English written in the Alvey Natural Language Tools (ANLT) metagrammatical formalism (Briscoe et al 1987 generating around 800 rules in a syntactic variant of the Definite Clause Grammar formalism (DCG, Pereira Warren, 1980) extended with iterative (Kleene) operators Further details of the text grammar are given in Briscoe Carroll (1994, 1995  The text grammar has been tested on the Susanne corpus and covers 998% of sentences (The failures are mostly text segmentation problems  Therefore, a text sentence containing eight commas (and no other punctuation) will have 3170 analyses Despite Nunberg's observation that text grammar is distinct from syntax, text grammatical ambiguity favours interleaved application of text grammatical and syntactic constraints The ANLT grammar is linked to a lexicon containing about 64K entries for 40K lexemes, including detailed subcategorisation information appropriate for the grammar, built semi-automatically from a learners' dictionary (Carroll Grover, 1989  Integrating the text and the PoS sequence grammars is straightforward and the result remains modular, in that the text grammar is `folded into' the PoS sequence grammar, by treating text and syntactic categories as overlapping and dealing with the properties of each using disjoint sets of features, principles of feature propagation, and so forth In addition to the core text-grammatical rules which carry over unchanged from the stand-alone text grammar, 44 syntactic rules (of pre- and post- posing, and coordination) now include (often optional) comma markers corresponding to the purely `syntactic' uses of punctuation The approach to text grammar taken here is in many ways similar to that of Jones (1994  Thus, his grammar is thoroughly integrated and it would be harder to extract an independent text grammar or build a modular semantics Our less-tightly integrated grammar is described in more detail in Briscoe Carroll (1994  We have used the integrated grammar to parse the Susanne corpus and the quite distinct Spoken English Corpus (SEC; Taylor Knowles, 1988 a 50K word treebanked corpus of transcribed British radio programmes punctuated by the corpus compilers51% accuracy In an earlier paper (Briscoe Carroll, 1995) we gave results for a previous version of the grammar and parsing system To examine the efficiency and coverage of the grammar we applied it to our retagged versions of Susanne and SEC Monitoring this distribution is helpful during grammar development to ensure that coverage is increasing but the ambiguity rate is not As the grammar was developed solely with reference to Susanne, coverage of SEC is quite robust (1993) report a coverage of around 95% on computer manuals, as opposed to our coverage rate of 70-80% on much more heterogeneous data and longer sentences1] and 1300[22 The results we report above relate to the latest version of the tag sequence grammar The various phases in the development and refinement of the grammar can be observed in an analysis of the coverage and APB for Susanne and SEC over this period see table  The phases, with dates, were: 6/92-11/93 Initial development of the grammar 7/94-12/94 Incremental improvements in coverage, but at the cost of increasing the ambiguity of the grammar 12/94-10/95 Improving the accuracy of the system by trying to ensure that the correct analysis was in the set returned We constructed randomly from Susanne a test corpus of 250 in-coverage sentences, and in this, for each word tagged as possibly being an open-class verb (i as in the full ANLT representation scheme  31 sentences now failed to receive a parse, a decrease in coverage of 12  This is due to the fact that the ANLT lexicon, although large and comprehensive by current standards (Briscoe Carroll, 1996 nevertheless contains many errors of omission