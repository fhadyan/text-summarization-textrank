 Here we will work upto the rules gradually, by considering which kinds of rules we might need in particular instances from X/s to X Now consider individual transitions The simplest of these is where the type of argument expected by the state is matched by the next word i Thus after likes is absorbed the state category will need to expect an np The rule required is similar to Function Composition in CG i This is relatively trivial using a non-curried notation similar to that used for AACG Now consider the first transition Here a sentence was expected, but what was encountered was a noun phrase, John State-Application and State-Prediction together provide the basis of a sound and complete parser As an example, reconsider the string John likes Sue Neither approach is without problems an np s State-Application can apply, as in Figure 2 as np or np  One possibility corresponds to the prediction of an s s modifier, a second to the prediction of an (np s) (np s) modifier (i The second of these is perhaps the most interesting, and is given in Figure 3 Finally, it is worth noting why it is necessary to use h-lists Consider the following trees, where the np s node is empty The headed list distinguishes between the two cases, with only the first having an np on its headed list, allowing prediction of an s modifier Thus increases in the size of a grammar don't necessarily effect efficiency of processing, provided the increase in size is due to the addition of new words, rather than increased lexical ambiguity However, if we are to base a parser on the rules given above, it would seem that we gain further However there is a major problem This could be in the nature of fixed restrictions to the rules e A more appealing alternative is to base the tuning on statistical methods This could be achieved by running the parser over corpora to provide probabilities of particular transitions given particular words It is therefore necessary to make various generalisations over the states, for example by ignoring the R2 lists The paper has presented a method for providing interpretations word by word for basic Categorial Grammar 1990  (R( x The third allows there to be a verb phrase modifier Mary thinks John coming here was a mistake 1983  Partial syntax trees can be regarded as performing two main roles The second is to provide a basis for a semantic representation The second role can be captured by the parser constructing semantic representations directly 1994  Applicative Categorial Grammars allow categories to have arguments which are themselves functions (e very can be treated as a function of a function, and given the type (n/n n/n) when used as an adjectival modifier  This will be discussed in the final section of the paper Although it is still used for linguistic description (e The first directed Applicative CG was proposed by Bar-Hillel (1953  Functional types included a list of arguments to the left, and a list of arguments to the right The only real difference is that Bar-Hillel allowed arguments to themselves be functions Hence, arguments with functional types had to correspond to single lexical items: there was no way to form the type np s for a non-lexical verb phrase such as likes Mary Rather than adapting the Application Rule to allow functions to be applied to one argument at a time, Bar-Hillel's second system (often called AB Categorial Grammar, or Adjukiewicz/Bar-Hillel CG, Bar-Hillel 1964) adopted a `Curried' notation, and this has been adopted by most CGs since Ades and Steedman noted that the use of function composition allows CGs to deal with unbounded dependency constructions a relative clause 1990  However, there are problems with having just composition, the most basic of the non-applicative operations Thus, the noun very old dilapidated car can get the unacceptable bracketing, very [old dilapidated car  Using the non-Curried notation of Bar-Hillel, it is more natural to use a separate wh-list than to mark wh-arguments individually This is very similar to the way in which wh-movement is dealt with in GPSG (Gazdar et al 1985) and HPSG, where wh-arguments are treated using slash mechanisms or feature inheritance principles which correspond closely to function composition However, unlike Bar-Hillel, we allow one argument to be absorbed at a time Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence s, np then is a category If X is a syntactic type, and L and R are lists of categories, then is a category by rules which say how the current parsing state (e a stack of categories, or a chart) can be transformed by the next word into a new state There are two unusual features