 We then constructed a number of thesauri based on these data, using our method We have proposed a method of clustering words based on large corpus dataYamanishi of CC Res MDL stipulates that the best probability model for given data is that model which requires the least code length for encoding of the model itself, as well as the given data relative to it The model description length quantifies the simplicity (complexity) of a model, and the data description length quantifies the fit to the data Given a model M and data S, its total description length L(M) is computed as the sum of the model description length Lmod(M the description length of its parameters Lpar(M and the data description length Ldat(M  We then used the data to estimate a model (clustering words and measured the KL distance between the true model and the estimated model Also, MLE tends to select a model overfitting the data, while MDL tends to select a model which is simple and yet fits the data reasonably well