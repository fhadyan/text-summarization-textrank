 Leacock and Chodorow have experimented with this measure and the information content measure described here in the context of word sense disambiguation, and found that they yield roughly similar results Word similarity appears to be one promising way to solve the problem: the behavior of a word is approximated by smoothing its observed behavior together with the behavior of words to which it is similar Using this assumption, it is common to treat the words that co-occur near a word as constituting features, and to compute word similarity in terms of how similar their feature sets are As in information retrieval, the feature representation of a word often takes the form of a vector, with the similarity computation amounting to a computation of distance in a highly multidimensional space Given a distance measure, it is not uncommon to derive word classes by hierarchical clustering A difficulty with most distributional methods, however, is how the measure of similarity (or distance) is to be interpreted This paper has presented a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content79 with a benchmark set of human similarity judgments, against an upper bound of r = 0 In ongoing work, I am currently exploring the application of taxonomically-based semantic similarity in the disambiguation of word senses  More recently, Sussna has explored using similarity of word senses based on WordNet for the same purpose The work I am pursuing is similar in spirit to Sussna's approach, although the disambiguation algorithm and the similarity measure differ substantially In this paper, I describe an alternative way to evaluate semantic similarity in a taxonomy, based on the notion of information content Section sets up the probabilistic framework and defines the measure of semantic similarity in information-theoretic terms; Section presents an evaluation of the similarity measure against human similarity judgments, using the simple edge-counting method as a baseline; and Section discusses related work Let be the set of concepts in an IS-A taxonomy, permitting multiple inheritance Intuitively, one key to the similarity of two concepts is the extent to which they share information in common, indicated in an IS-A taxonomy by a highly specific concept that subsumes them both Moreover, if there is a unique top concept, its information content is 0 This quantitative characterization of information provides a new way to measure semantic similarity The more information two concepts share in common, the more similar they are, and the information shared by two concepts is indicated by the information content of the concepts that subsume them in the taxonomy Notice that although similarity is computed by considering all upper bounds for the two concepts, the information measure has the effect of identifying minimal upper bounds, since no class is less informative than its superordinates In practice, one often needs to measure word similarity, rather than concept similarity Here, the word similarity is judged by taking the maximal information content over all concepts of which both words could be an instance For example, Figure illustrates how the similarity of words nickel and gold would be computed: the information content would be computed for all classes subsuming any pair in the cross product of { NICKEL, NICKEL and { GOLD, GOLD and the information content of the most informative class used to quantify the similarity of the two words Formally, where is the set of words subsumed by concept c Although there is no standard way to evaluate computational measures of semantic similarity, one reasonable way to judge would seem to be agreement with human similarity ratings This can be assessed by using a computational similarity measure to rate the similarity of a set of word pairs, and looking at how well its ratings correlate with human ratings of the same pairs For purposes of evaluation, three computational similarity measures were used The first is the similarity measurement using information content proposed in the previous section It simply ensures that the value can be interpreted as a similarity value, with high values indicating similar words Table summarizes the experimental results, giving the correlation between the similarity ratings and the mean ratings reported by Miller and Charles The similarity ratings by item are given in Table  The experimental results in the previous section suggest that measuring semantic similarity using information content provides quite reasonable results, significantly better than the traditional method of simply counting the number of intervening IS-A links One problem is that, like simple edge counting, the measure sometimes produces spuriously high similarity measures for words on the basis of inappropriate word senses For example, Table shows the word similarity for several words with tobacco The problem arises, however, in the similarity rating for tobacco with horse: the word horse can be used as a slang term for heroin, and as a result information-based similarity is maximized, and path length minimized, when the two words are both categorized as narcotics However, the example illustrates a more general concern: in measuring similarity between words, it is really the relationship among word senses that matters, and a similarity measure should be able to take this into account This measure of similarity takes more information into account than the previous one: rather than relying on the single concept with maximum information content, it allows each class to contribute information content according to the value of  In work on resolving syntactic ambiguity using semantic information , I have found that local syntactic information can be used successfully to set values for the  For example, Rada et al report experiments using conceptual distance, implemented using the edge counting metric, as the basis for ranking documents by their similarity to a query Sussna uses semantic relatedness measured with WordNet in word sense disambiguation, defining a measure of distance that weights different types of links and also explicitly takes depth in the taxonomy into account They have defined a measure resembling information content, but using the normalized path length between the two concepts being compared rather than the probability of a subsuming concept