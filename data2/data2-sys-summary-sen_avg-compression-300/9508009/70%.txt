 Some properties of : y ensuremath circ (x ensuremath swarrow} y) ensuremath sqsubseteq x end{eqnarray} gt; textnormal texttt{1 ensuremath sqsubseteq x ensuremath swarrow} x end{eqnarray} gt; (x ensuremath swarrow} y) ensuremath circ z ensuremath sqsubseteq (x ensuremath circ z) ensuremath swarrow} y end{eqnarray} gt; (x ensuremath swarrow} y) ensuremath swarrow} z ensuremath sqsubseteq x ensuremath swarrow} (y ensuremath circ z) end{eqnarray} gt; Having set the basic elements of our proof-theoretic apparatus, we are now able to define the components of a derivation as follows: A derivation, or proof will be a tree structure built according to certain syntactic rules These rules will be called expansion rules, since their application will invariably expand the tree structure There are three sorts of expansion rules: those which expand the tree by generating two formulae from a single one occurring previously in the derivation, those which expand the tree by combining two formulae into a third one which is then added to the tree, and the branching rule The first kind of rule corresponds to what is called -rule in Smullyan tableaux; these rules will be called -rules here as well We shall refer to the second kind as -rules, and to the branching rule as -rule - after Smullyan's, even though his branching rules are different Figure summarises the expansion rules to be employed by the system A deduction bar says that if the formula(e) appearing above it occurs in the tree, then the formula(e) below it should be added to the tableau The rules are easily interpreted according to the intuitions assigned above to signs, formulae and information tokens In section , we introduce the family of categorial calculi, and discuss some of the linguistic arguments which have been put forward in the literature with regard to these calculi Given the expansion rules, the definition of the main data structure to be manipulated by the theorem proving (parsing) algorithm is straightforward: a derivation tree, , is simply a binary tree built from a set of given formulae by applying the rules Unbounded application of , however, might expand the tree indefinitely For efficiency reasons non-branching rules will be exhaustively applied before we move on to employing -rules Definition presents the basic procedure for generating linear expansion for a branch The complete LKE algorithm, Definition , which uses the procedure below, will be presented after we have discussed tableau closure from the information frame perspective We have seen above that the labels are means to propagate information about the formulae through the derivation tree From a semantic viewpoint, the calculi addressed in this paper are obtained by varying the structure assigned to the set of formulae in the derivation Therefore, in order to verify whether a branch is closed for a calculus one has to verify whether the information frame satisfies the constraints which characterise the calculus For instance, the standard Lambek calculus L does not allow any sort of structural manipulation of formulae apart from associativity; LP allows formulae to be permuted; LPE allows permutations and expansion (i Likewise, a tree is closed if it contains only closed branches Checking for label closure will depend on the calculus being used, and consists basically of reducing information token expressions to a normal form, via properties ( and then matching tokens and/or variables that might have been introduced by applications of the -rule according to the properties or combination of properties (Definition ) that characterise the calculus considered Definition gives the general procedure for tableau expansion, abstracted from the heuristics mentioned above The labels introduced via -rules are in fact universally quantified variables which must be instantiated during the label unification step In order to overcome this problem and bind the unification procedure we restrict label (variable) substitutions to the set of tokens occurring in the derivation similarly to the way parameter instantiation is dealt with by liberalized quantification rules for first-order logic tableaux Stronger calculi such as LP, LPE, LPC and LPCE can be obtained for the same general framework by assigning further properties to in the labelling algebra Frames exhibiting combinations of monotonicity, expansivity, commutativity and contraction allow us to characterise these substructural calculi Apart from the fact that it lacks generality, since implementing more powerful calculi would involve modifying the code in order to accommodate new structural rules, this approach presents several sources of inefficiency The main ones are: the generate-and-test strategy employed to cope with associativity, the non-determinism in the branching rules and in rule application itself However, non-determinism due to splitting in the proof structure still remains In that paper, the theorem prover employed is based on proof nets, and the characterisation of different calculi is taken care of by labelling the formulae For substructural calculi stronger than L, much of the complexity (perhaps too much) is shifted to the label unification procedures We believe that this result shows that, even though LKE label unification might be computationally expensive for substructural logics in general, the system seems to be well suited for categorial logics The categorial grammar research programme requires the use of a range of logical calculi for linguistic description The architecture proposed seems promising Among them: implementing a semantic module based on Curry-Howard correspondence between type deduction and -terms, adding local control of structural transformations (structural modalities) to the language, increasing expressivity in the information frames for covering calculi weaker than L (e Dependency Categorial Grammar exploiting the derivational structure encoded in the labels to define heuristics for models of human attachment preferences etc Problems for further investigation might include: the treatment of polymorphic types (by incorporating rules for dealing with quantification analogous to Smullyan's and rules and complexity issues regarding how the general architecture proposed here would behave under more standard theorem proving methods Dependency Categorial Grammar as well as stronger calculi which extend the power of L through the addition of structural rules We can increase the power of L by adding the structural transformations Permutation, Contraction and Expansion, to derive the calculi LP, LPC, LPE and LPCE However it is universally recognized that a system employing the unrestricted use of structural transformations would be far too powerful for any useful linguistic application, since it would allow arbitrary word order variation, copying and deletion In this section we describe the theorem proving framework for categorial deduction Then we move on to the theorem proving strategy, introducing the LKE approach and the algebraic apparatus used to characterise different calculi Many proof procedures for classical logic have been proposed: natural deduction, Gentzen's sequents, analytic (Smullyan style) tableaux, etc Most of these methods, along with proof methods developed for resource logics, such as Girard's proof nets (a variant of Bibel's connection method can be used for categorial logic Leslie presents and compares some categorial versions of these procedures for the standard Lambek calculus L, taking into account complexity and proof presentation issues The main reason for this is the fact that many of the Smullyan tableau expansion rules cause the proof tree to branch, thus increasing the complexity of the search In order to cope with efficiency and generality, we have chosen the LKE system as the proof theoretic basis of our approach LKE is an analytic (its derivations exhibit the sub-formula property) method of proof by refutation which has only one branching rule In addition, its formulae are labelled according to a labelling algebra which will determine the closure conditions for the proof trees In what follows, we shall concentrate on explaining our version of the system, the heuristics that we have found useful for dealing with particularities of the calculi covered, and the relevant results for these calculi The calculus defined above presents no negation, though LKE is similar to a Smullyan-style tableau system, in which the derivations obey the sub-formula principle, but it improves on efficiency by restricting the number of branching rules to just one In our approach, since negation is not defined in the language, we shall make use of signed formulae as proof theoretic devices If we had restricted the system to dealing with signed formulae, we would have a proof procedure for an implicational fragment of standard propositional logic enriched with backwards implication and conjunction However, we have seen that the Lambek calculus does not exhibit any of the structural properties of standard logic, and that different calculi may be obtained by varying structural transformations This mechanism is provided by labelling each formula in the derivation with information tokens A label can be seen as an information token supporting the information conveyed by the signalled formula it labels Different categorial logics are handled by assigning different properties to the labelling algebra, while the basic syntactic apparatus remains the same So, a minimal information token verifying S would be x y Let's formalise these notions by defining an algebraic structure, called Information frame