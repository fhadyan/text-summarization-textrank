 independent evaluations for spoken and written language engineering But evaluation requires modularity to be enforced everywhere, and that will just block innovation 2: We need to bear in mind that finer granularity may differ substantially between systems, so that in may cases comparative evaluation may not be possible generation ? I don't know what 'willing' is supposed to mean here - this is a very resource-dependent thing prosodic marking ? many spoken language systems wont produce any of these native-non-native speakers ? 26 Implementation of Comparative TA SE Two possible scenarios for developing an evaluation programme are the following In this scenario the type of evaluation evolves out of actual funded pilot applications This would be done in the 2nd and final calls the bottom-up scenario ? 2 bottom up  homogeneous 2: I don't think either of theses is an effective way to achieve this goal, but 2 comes closest general business letter dictation Clearly some mix is required5 Content of Comparative TA SE Assessment issues can be divided into those concerning user-centered assessment, and those concerning technology assessment So again, the technological data may not be directly amenable for use as comparative evaluation data Evaluation data comes in three forms 1 Test, or input data 2 `Pure' technology evaluation metrics require user-centered validation User-centered validation of technology evaluation metrics has received scant attention The evaluation structure should allow both technological and user-centered evaluation A braided evaluation structure allows for comparative and individual evaluation of different systems at different levels (user-centered, task-specific, general technology  One could envisage user, task and general technology measures being applied to Task 3 Own-language retrieval would be done only to provide evaluation data Human performance also offers a bench mark for system evaluation Internal technology assessment may or may not form part of progress evaluation, which would in any case require a large element of user-centered assessment Namely, (a) that the form of project internal technology evaluation can vary from project to project, and (b) that technology evaluation provides the core of comparative assessment But what one would like is for comparative technology assessment to build on the back of project internal assessment Wherever possible, projects should be encouraged to make their internal evaluation strategies, test data, user profiles etc QUESTIONNAIRE ON ASSESSMENT AND EVALUATION IN LANGUAGE ENGINEERING 1uni-sb user validation; and 21 Introduction and Terminology Terms later used in the specific sense introduced here are capitalised spontaneous speech channel conditions (telephone vs Would be willing to conduct it 4 Maybe you should have an option 5 Would be willing to participate 4 comparative assessment is not going to divert substantial resources from internal assessment and development; 2 that comparative assessment is likely to bring about project internal improvements, in the same way that internal evaluation should; 3 whatever validation the users deem sufficient) ? 2 2: qualitative assessment is not enough 2: User validation alone won't promote generality and reusability of components Therefore technological assessment levels are undetournable 2: This answer needs to be qualified This reflects a system's maintainability, portability and flexibility3 above