 Bag generation is a form of natural language generation in which the input is a bag (also known as a multiset: a set in which repeated elements are significant) of lexical elements and the output is a grammatical sentence or a statistically most probable permutation with respect to some language model Assumption 1 All lexical signs must be indexed, including functional and nonpredicative elements  Assumption 2 All lexical signs must be connected to each other In order to apply the algorithm, outer domains needed to be compiled from the grammar; these are used to discard wfss by ensuring lexical signs outside a wfss can indeed appear outside that string Two lexical signs are connected if they are directly connected; furthermore, the connectivity relation is transitive To ensure that only connected lexical signs are generated and analysed, the following assumption must also be made: Assumption 3 A grammar will only generate or analyse connected lexical signs Two main types of rule-based bag generators have been proposed To show this, consider the test-rewrite sequence for Example : Test: dog barked the brown big Rewrite: barked the dog brown big Test: barked (the dog) brown big Rewrite: (the dog) barked brown big Test: the dog) barked) brown big Rewrite: the brown dog barked big Test: the (brown dog barked) big Rewrite: the big (brown dog) barked Test: the (big (brown dog barked) (terminate) In this sequence double underscore indicates the starting position of a moved constituent; the moved constituent itself is given in bold face; the bracketing indicates analysed constituents (for expository purposes the algorithm has been oversimplified, but the general idea remains the same  Bag generation has received particular attention in lexicalist approaches to MT, as exemplified by Shake-and-Bake generation ,  This action causes the complete structure for `the dog barked' to be discarded and replaced with that for `the brown dog barked which in turn is discarded and replaced by `the big brown dog barked  These relationships form a graph indicating the necessary conditions for a lexical item to form part of a complete sentence One can also envisage applications of bag generation to generation from minimally recursive semantic representations and other semantic frameworks which separate scoping from content information  Take the following bag: Ex 2 {dog1,the1,brown1,big1} (corresponding to `the big brown dog  In such cases `brown' would modify a different noun with a different index: Ex Since this would not be possible, the NP `the dog' would be discarded What is required is a more tractable algorithm which, given a wfss and its associated sign, will be able to determine whether all remaining lexical elements can ever form part of a complete sentence which includes that wfss Note that deciding whether a lexical sign can appear outside a phrase is determined purely by the grammar, and not by whether the lexical elements share the same index or not Thus, a more complex grammar would allow `the man' from the bag Ex The compilation process results in a set of (Sign,Lex,Bindings) triples called outer domains Outer domains are defined as follow: Definition 3 { (Sign,Lex,Binds) Sign , Lex and there exists a derivation Sign' Lex' or Lex' Sign' , and Sign' a unifier for Sign, Lex' a unifier for Lex, and Binds the set of all path pairs [SignPath,LexPath] such that Sign SignPath is token identical with Lex LexPath} Intuitively, the outer domains indicate that preterminal category Lex can appear in a complete sentence with subconstituent Sign, such that Lex is not a leaf of Sign Outer domains thus represent elements which may lie outside a subtree of category Sign in a complete sentential derivation The following definition specifies how outer domains are used: Definition 4 A lexical sign Lex' is in the outer domain of Sign' iff there is a triple (Sign,Lex,Binds) in outer domains such that Sign and Lex unify with Sign' and Lex' respectively, and there is at least one pair [PathS,PathL] Binds such that Sign PathS unifies with Lex PathL In compiling outer domains, inner domains are used to facilitate computation Inner domains are defined as follows: Definition 5 { (Sign,Lex,Binds) Sign , Lex and there exists a derivation Lex' , with Sign' a unifier for Sign, Lex' a unifier for Lex, and Binds the set of all path pairs [SignPath,LexPath]such that Sign SignPath is token identical with Lex LexPath} The inner domains thus express all the possible terminal categories which may be derived from each nonterminal in the grammar Such a wfss will have been constructed during the bag generation process Then G is connected By Assumption , the lexical elements in the bag, and therefore in any grammatical ordering of it, are connected Instead of simply comparing the value of index paths, it is more restrictive to use outer domains since they give us precisely those elements which are directly connected to a sign and are in its outer domain Consider Example  To eliminate the wfss `the dog' from further consideration, a connected graph of lexical signs is constructed before generation is started (Figure  This graph is built by using the outer domain of each lexical element to decide which of the remaining elements could possibly share an index with it in a complete sentence If the updated graph is not connected then the proposed wfss cannot form part of a complete sentence