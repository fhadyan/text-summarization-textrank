 Words unknown to the lexicon present a substantial problem to part-of-speech ( POS) tagging of real-world texts The major topic in the development of word- POS guessers is the strategy which is to be used for the acquisition of the guessing rules The longer the length the smaller the sample which will be considered representative enough for a confident rule estimation The method for setting up this threshold is based on empirical evaluations of the rule-sets and is described in Section  We can merge two rules which have scored below the threshold and have the same affix (or ending) and the initial class (I  After a successful application of the merging, the resulting rule substitutes the two merged ones The task of assigning a set of POS-tags to a word is actually quite similar to the task of document categorisation where a document should be assigned with a set of descriptors which represent its contents There were two types of data in use at this stage For every word we computed its metrics exactly as in the previous experiment In Table 1 some results of that experiment are shown One can notice a slight difference in the results obtained over the lexicon and the corpus In average ending-guessing rules were detected to cover over 96% of the unknown words In a system for the automated learning of morphological word-formation rules is described It can also handle 6% less unknown words which, in fact, might decrease its performance even lower In comparison with the ending-guessing rules, the morphological rules have much better precision and hence better accuracy of guessing Virtually almost every word which can be guessed by the morphological rules is guessed exactly correct (97% recall and 97% precision  After obtaining the optimal rule-sets we performed the same experiment on a word-sample which was not included into the training lexicon and corpus5% for Ending 75 and Xerox rule-sets and 7% for the Suffix 60 rule-set This, actually, did not come as a surprise, since many main forms required by the suffix rules were missing in the lexicon We also evaluated in detail whether a conjunctive application with the Xerox guesser would boost the performance Table 2 demonstrates some results of this experiment This actually proves that the E75 rule-set fully supercedes the Xerox rule-set Brill outlines a transformation-based learner which learns guessing rules from a pre-tagged training corpus In this evaluation we tried two different taggers The other tagger was the rule-based tagger of Brill  Both of the taggers come with data and word-guessing components pre-trained on the Brown Corpus In the evaluation of tagging accuracy on unknown words we pay attention to two metrics In this case, however, we do not account for the known words which were mis-tagged because of the guessers We tagged several texts of different origins, except from the Brown Corpus For each text we performed two tagging experiments In the second experiment we tagged the same text with the lexicon which contained only closed-class and short words We obtained quite stable results in these experiments This text was detected to have 347 unknown words The results of this tagging are summarised in Table 3 The same situation was detected with Brill's tagger which in general was slightly more accurate than the Xerox one Although the learning process in these and some other systems is fully unsupervised and the accuracy of obtained rules reaches current state-of-the-art, they require specially prepared training data a pre-tagged training corpus, training examples, etc5% to 925% for both taggers In the second experiment we tagged the same text in the same way but with the small lexicon The results of this tagging are summarised in Table 43% for the Xerox tagger and 915% for Brill's tagger In this paper we describe a new fully automatic technique for learning part-of-speech guessing rules The accuracy of the tagging on unknown words dropped by about 5% in general Two types of mis-taggings caused by the guessers occured Usually this is the case with irregular words like, for example, cattle which was wrongly guessed as a singular noun (NN) but in fact is a plural noun (NNS  We presented a technique for fully unsupervised statistical acquisition of rules which guess possible parts-of-speech for words unknown to the lexicon So, first words are looked up in the lexicon This technique does not require specially prepared training data and uses for training the lexicon and word frequencies collected from a raw corpus To select best performing guessing rule-sets we suggested an evaluation methodology, which is solely dedicated to the performance of part-of-speech guessers The cascading guesser outperformed the guesser supplied with the Xerox tagger by about 8-9% and the guesser supplied with Brill's tagger by about 6-7  This makes the accuracy drop caused by the cascading guesser to be less than 6% in general Another important conclusion from the evaluation experiments is that the morphological guessing rules do improve the guessing performance This, actually, results in about 2% higher accuracy of tagging on unknown words The acquired guessing rules employed in our cascading guesser are, in fact, of a standard nature and in that form or another are used in other POS-guessers One of the most important issues in the induction of guessing rule-sets is the choice right data for training Thus the major factor in the learning process is the lexicon The corresponding corpus should include most of the words from the lexicon and be large enough to obtain reliable estimates of word-frequency distribution This would account for cases like try - tries reduce - reducing advise - advisable  We expect it to increase the coverage of thesuffix morphological rules and hence contribute to the overall guessing accuracy This information can be compiled automatically and also might improve the accuracy of tagging unknown words As was pointed out above, one of the requirements in many techniques for automatic learning of part-of-speech guessing rules is specially prepared training data a pre-tagged training corpus, training examples, etc the lexicon In our experiments we used the lexicon and word-frequencies derived from the Brown Corpus  However, 3 to 5% of word tokens are usually missing in the lexicon when tagging real-world texts Moreover, despite the fact that the training is performed on a particular lexicon and a particular corpus, the obtained guessing rules suppose to be domain and corpus independent and the only training-dependent feature is the tag-set in use The acquisition of word- POS guessing rules is a three-step procedure which includes the rule extraction, rule scoring and rule merging phases At the rule extraction phase, three sets of word-guessing rules (morphological prefix guessing rules, morphological suffix guessing rules and ending-guessing rules) are extracted from the lexicon and cleaned from coincidental cases At the scoring phase, each rule is scored in accordance with its accuracy of guessing and the best scored rules are included into the final rule-sets At the merging phase, rules which have not scored high enough to be included into the final rule-sets are merged into more general rules, then re-scored and depending on their score added to the final rule-sets Morphological word-guessing rules describe how one word can be guessed given that another word is known This is where word- POS guessers take their place they employ the analysis of word features, e There are two kinds of morphological rules to be learned: suffix rules (A[s rules which are applied to the tail of a word, and prefix rules (A[p rules which are applied to the beginning of a word To extract such rules a special operator is applied to every pair of words from the lexicon Thus two different sets of guessing rules prefix and suffix morphological rules together with their frequencies are produced Next, from these sets of guessing rules we need to cut out infrequent rules which might bias the further learning process Unlike morphological guessing rules, ending-guessing rules do not require the main form of an unknown word to be listed in the lexicon These rules guess a POS-class for a word just on the basis of its ending characters and without looking up its stem in the lexicon Such rules are able to cover more unknown words than morphological guessing rules but their accuracy will not be as high A set of rules which on the basis of ending characters of unknown words, assign them with sets of possible POS-tags is supplied with the Xerox tagger  Unlike a morphological rule, this rule does not ask to check whether the substring preceeding the ing ending is a word with a particular POS-tag Thus an ending-guessing rule looks exactly like a morphological rule apart from the I-class which is always void The operator is applied to each entry in the lexicon in the way described for the operator of the morphological rules and then infrequent rules with are filtered out Of course, not all acquired rules are equally good as plausible guesses about word-classes: some rules are more accurate in their guessings and some rules are more frequent in their application To perform this experiment we take one-by-one each rule from the rule-sets produced at the rule extraction phase, take each word token from the corpus and guess its POS-set using the rule if the rule is applicable to the word For example, if a guessing rule strips a particular suffix and a current word from the corpus does not have this suffix, we classify these word and rule as incompatible and the rule as not applicable to that word If the rule is applicable to the word we perform look-up in the lexicon for this word and then compare the result of the guess with the information listed in the lexicon In a system of rules which uses both ending-guessing and more morphologically motivated rules is described This estimation of the rule value in fact resembles that used by for scoring POS-disambiguation rules for the French tagger05 = 1