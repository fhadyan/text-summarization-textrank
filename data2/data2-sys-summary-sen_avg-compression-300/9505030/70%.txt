 As explained above, each lexical rule is defined to operate on its own notion of an input and produce its own output For example, to `apply' the dative rule to our Give definition, we could construct a definition such as this: Give-dat: Give [input dative] [surface] [output dative  Word2: Give [alt whq] true [alt dative] true [alt passive] true Thus Word3 improperly attempts topicalisation in addition to wh-question formation, and, as a result, will fail to define a surface tree structure at all: Word3: Give [alt whq] true [alt topic] true [alt dative] true [alt passive] true [parent left form] null This approach to lexical rules allows them to be specified at the appropriate point in the lexical hierarchy, but overridden or modified in subclasses or lexemes as appropriate It also allows default generalisation over the lexical rules themselves, and control over their application Second, we describe trees using only local tree relations (between adjacent nodes in the tree while Vijay-Shanker Schabes also use a nonlocal dominance relation Both these properties are crucial to our embedding of the tree structure in the feature structure So the feature structures that we associate with lexical entries must be viewed as partial So the tree structures we define must be total descriptions Our approach keeps all elementary trees, whether or not they have been partly defined by a lexical rule, entirely within the lexical hierarchy The principal unit of (syntactic) information associated with an LTAG entry is a tree structure in which the tree nodes are labeled with syntactic categories and feature information and there is at least one leaf node labeled with a lexical category (such lexical leaf nodes are known as anchors  In representing such a tree in DATR, we do two things First, in keeping with the radically lexicalist character of LTAG, we describe the tree structure from its (lexical) anchor upwards, using a variant of Kilbury's bottom-up encoding of trees In this encoding, a tree is described relative to a particular distinguished leaf node (here the anchor node using binary relations parent, left and right, relating the node to the subtrees associated with its parent, and immediate-left and -right sisters, encoded in the same way Second, we embed the resulting tree structure (ie the node relations and type information) in the feature structure, so that the tree relations (left, right and parent) become features A simple bottom-up DATR representation for the whole tree (apart from the node type information) follows: Give: [cat] = v [parent cat] = vp [parent left cat] = np [parent parent cat] = s [right cat] = np [right right cat] = p [right right parent cat] = pp [right right right cat] = np ; Daelemans  The implied bottom-up tree structure is shown graphically in figure  Nevertheless, the full tree structure is completely and accurately represented by this encoding But, in both cases, the problem is one of concisely describing feature structures associated with lexical entries and relationships between lexical entries This basic organisational structure can be expressed as the following DATR fragment: VERB: TREENODE [cat] v [type] anchor [parent] VPTREE  VERB+NP: VERB [right] NPCOMP  VERB+NP+PP: VERB+NP [right right] PTREE [right right root] to VERB+NP+NP: VERB+NP [right right] NPCOMP  Die: VERB [root] die Give: VERB+NP+PP [root] give This DATR fragment is incomplete, because it neglects to define the internal structure of the TREENODE and the various subtree nodes in the lexical hierarchy Each such node is a description of an LTAG tree at some degree of abstraction STREE: TREENODE [cat] s VPTREE: TREENODE [cat] vp [parent] STREE [left] NPCOMP  NPCOMP: TREENODE [cat] np [type] substitution PPTREE: TREENODE [cat] pp PTREE: TREENODE [cat] p [type] anchor [parent] PPTREE Here, TREENODE represents an abstract node in an LTAG tree and provides a (default) type of internal A simple example is provided by the following definition for auxiliary verbs: AUXVERB: TREENODE [cat] v [type] anchor [parent cat] vp [right cat] vp [right type] foot We noted above that lexical entries are actually associated with tree families, and that these group together trees that are related to each other However, LTAG's large domain of locality means that all such relationships can be viewed as directly lexical, and thus expressible by lexical rules In fact we can go further than this: because we have embedded the domain of these lexical rules, namely the LTAG tree structures, within the feature structures, we can view such lexical rules as covariation constraints within feature structures, in much the same way that the covariation of, say, syntactic and morphological form is treated Lexical rules are specified by defining a derived output tree structure in terms of an input tree structure, where each of these structures is a set of feature specifications of the sort defined above Each lexical rule has a name, and the input and output tree structures for rule foo are referenced by prefixing feature paths of the sort given above with [input foo or [output foo  So for example, the category of the parent tree node of the output of the passive rule might be referenced as [output passive parent cat  VERB+NP+PP: [output dative right right] NPCOMP  Subject-auxiliary inversion can be achieved similarly by just specifying the output tree structure without reference to the input structure (note the addition here of a form feature specifying verb form AUXVERB: [output auxinv form] finite-inv [output auxinv parent cat] s [output auxinv right cat] s Passive is slightly more complex, in that it has to modify the given input tree structure rather than simply overwriting part of it Individual transitive verbs, or whole subclasses, can override this default, leaving their passive tree structure undefined if required For agentless passives, the necessary additions to the VERB+NP node are as follows: VERB+NP: [output passive form] passive [output passive right] [input passive right right]  Vijay-Shanker Schabes address this problem by introducing a hierarchical lexicon structure with monotonic inheritance and lexical rules, using an approach loosely based on that of Flickinger but tailored for LTAG trees rather than HPSG subcategorization lists Here, the first line stipulates the form of the verb in the output tree to be passive, while the second line redefines the complement structure: the output of passive has as its first complement the second complement of its input, thereby discarding the first complement of its input Wh-questions, relative clauses and topicalisation are slightly different, in that the application of the lexical rule causes structure to be added to the top of the tree (above the S node  Since the relevant lexical rules can apply to sentences that contain any kind of verb, they need to be stated at the VERB node Thus, for example, topicalisation and wh-questions can be defined as follows: VERB: [output topic parent parent parent cat] s [output topic parent parent left cat] np [output topic parent parent left form] normal [output whq] [output topic] [output whq parent parent left form] wh