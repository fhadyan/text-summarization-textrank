 When analyzing the coverage of WordNet taxonomy we considered two different ratios In our case, we define precision as the proportion of triples appearing in syntactic positions with acquired SRs, which effectively fulfill one of those SRs8% triples didn't belong to any of the classes induced for their syntactic positions On the other hand, we define recall as the proportion of triples which fulfill one of the SRs acquired for their corresponding syntactic positions Table shows the SRs corresponding to the subject position of the verb seek n the number of nouns appearing in the corpus that are contained in the class Finally, s indicates the number of actual noun senses used in the corpus which are contained in the class It happens because erroneous senses, metonymies, accumulate evidence for the higher class Abs Some of the SRs could be best gathered in a unique class Senses The class has cropped up because it accumulates enough evidence, provided by erroneous senses Noise The class accumulates enough evidence provided by erroneously extracted triples Almost one correct semantic class for each syntactic position in the sample is acquired The technique achieves a good coverage, even with few co-occurrence triples Although many of the classes acquired result from the accumulation of incorrect senses (73 Specifically, the classes considered to be correct sometimes aren't ranked in the higher positions of the Assoc (e The impact of noise provided by erroneous extraction of co-occurrence triples, in the acquisition of wrong semantic classes, seems to be very moderate Since different verb senses occur in the corpus, the SRs acquired appear mixed In this way, the syntactic position also would provide information (statistical evidence) for measuring the most appropriate classes One possible way would be to disambiguate the senses of the verbs appearing in the corpus, using the SRs already acquired and gathering evidence of the patterns corresponding to each sense by means of a technique similar to that used by  Therefore, once disambiguated the verb senses it would be possible to split the set of SRs acquired An illustration of such a learning is shown in Figure , where the system, departing from the three examples of use, and knowing that prosecutor, buyer and lawmaker are nouns belonging to the semantic class SRs have been used to express semantic constraints holding in different syntactic and functional configurations We won't distinguish the SRs imposed by verbs on arguments and adjuncts We believe that few adjuncts are going to provide enough evidence in the corpus for creating SRs Training set The input to the learning process is a list of co-occurrence triples codifying the co-occurrence of verbs and complement heads in the corpus: (verb, syntactic relationship, noun  A method to draw the co-occurrence triples from corpus is proposed in subsection  Output The result of the learning process is a set of syntactic SRs, (verb, syntactic relationship, semantic class  Semantic classes are represented extensionally as sets of nouns SRs are only acquired if there are enough cases in the corpus as to gather statistical evidence As long as distinct uses of the same verb can have different SRs, we permit to extract more than one class for the same syntactic position SRs must include information on the syntactic position of the words that are being restricted semantically Previous knowledge used In the process of learning SRs, the system needs to know how words are clustered in semantic classes, and how semantic classes are hierarchically organized Ambiguous words must be represented as having different hyperonym classes Learning process The computational process is divided in three stages: (1) Guessing the possible semantic classes, i In our case, where the semantic classes are hypothesized not univoquely from the examples, accuracy becomes fundamental On the one hand, our system intends to learn SRs on any kind of verb's complements However, if the co-occurrences were extracted from a corpus annotated with structural syntactic information (i On the one hand, in approach, semantic classes relevant to the domain are chosen, and consequently, the adjustment of the classes to the corpus is quite nice On the other hand, while implies hand-coding all the relevant words with semantic tags, needs a broad semantic taxonomy Furthermore, SRs may help the parser when deciding the semantic role played by a syntactic complement We adopt 's approach, which quantifies the statistical association between verbs and classes of nouns from their co-occurrence Let be the sets of all verbs, nouns, syntactic positions, and possible noun classes, respectively Mutual information, I(v;c|s measures the strength of the statistical association between the given verb v and the candidate class c in the given syntactic position s Lexicography is also interested in the acquisition of SRs The existence of noise in the training set introduces classes in the candidate space that can't be considered as expressing SRs However, some erroneous classes may persist because they exceed the threshold However, if candidate classes were ordered by the significance of their Assoc with the verb, it is likely that less appropriate classes (introduced by noise) would be ranked in the last positions of the candidate list In different iterations over these candidate classes, two operations are performed: first, the class, c, having the best Assoc (best class is extracted for the final result; and second, the remaining candidate classes are filtered from classes being hyper/hyponyms to the best class performed a similar learning process, but while he was only looking for the preferred class of object nouns, we are interested in all the possible classes (SRs  We used Wordnet as the verb and noun lexicons for the lemmatizer, and also as the semantic taxonomy for clustering nouns in semantic classes The total number of co-occurrence triples extracted amounts to 190,766