 In our case, we define precision as the proportion of triples appearing in syntactic positions with acquired SRs, which effectively fulfill one of those SRs8% triples didn't belong to any of the classes induced for their syntactic positions On the other hand, we define recall as the proportion of triples which fulfill one of the SRs acquired for their corresponding syntactic positions Table shows the SRs corresponding to the subject position of the verb seek n the number of nouns appearing in the corpus that are contained in the class It happens because erroneous senses, metonymies, accumulate evidence for the higher class Abs Some of the SRs could be best gathered in a unique class Senses The class has cropped up because it accumulates enough evidence, provided by erroneous senses Noise The class accumulates enough evidence provided by erroneously extracted triples Almost one correct semantic class for each syntactic position in the sample is acquired Although many of the classes acquired result from the accumulation of incorrect senses (734% of the senses g Table  The impact of noise provided by erroneous extraction of co-occurrence triples, in the acquisition of wrong semantic classes, seems to be very moderate Since different verb senses occur in the corpus, the SRs acquired appear mixed In this way, the syntactic position also would provide information (statistical evidence) for measuring the most appropriate classes Therefore, once disambiguated the verb senses it would be possible to split the set of SRs acquired We believe that few adjuncts are going to provide enough evidence in the corpus for creating SRs Training set The input to the learning process is a list of co-occurrence triples codifying the co-occurrence of verbs and complement heads in the corpus: (verb, syntactic relationship, noun  Output The result of the learning process is a set of syntactic SRs, (verb, syntactic relationship, semantic class  Semantic classes are represented extensionally as sets of nouns SRs are only acquired if there are enough cases in the corpus as to gather statistical evidence SRs must include information on the syntactic position of the words that are being restricted semantically Previous knowledge used In the process of learning SRs, the system needs to know how words are clustered in semantic classes, and how semantic classes are hierarchically organized Ambiguous words must be represented as having different hyperonym classes Learning process The computational process is divided in three stages: (1) Guessing the possible semantic classes, i In our case, where the semantic classes are hypothesized not univoquely from the examples, accuracy becomes fundamental On the one hand, in approach, semantic classes relevant to the domain are chosen, and consequently, the adjustment of the classes to the corpus is quite nice Furthermore, SRs may help the parser when deciding the semantic role played by a syntactic complement We adopt 's approach, which quantifies the statistical association between verbs and classes of nouns from their co-occurrence Let be the sets of all verbs, nouns, syntactic positions, and possible noun classes, respectively Lexicography is also interested in the acquisition of SRs The existence of noise in the training set introduces classes in the candidate space that can't be considered as expressing SRs In different iterations over these candidate classes, two operations are performed: first, the class, c, having the best Assoc (best class is extracted for the final result; and second, the remaining candidate classes are filtered from classes being hyper/hyponyms to the best class performed a similar learning process, but while he was only looking for the preferred class of object nouns, we are interested in all the possible classes (SRs  We used Wordnet as the verb and noun lexicons for the lemmatizer, and also as the semantic taxonomy for clustering nouns in semantic classes The total number of co-occurrence triples extracted amounts to 190,766