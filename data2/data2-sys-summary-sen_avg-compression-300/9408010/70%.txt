 The data contains about 19,000different direct object tokens, about 10,000 different verb tokens and about 140,000 different token pairs We use of the data as training and the rest as testing data The perplexity on the testing text using the clustering algorithm on the verb-object pairs is shown in Table  For comparison, the table also contains the perplexity of a normal uni-gram model (e no predictor variable X) and the performance of the clustering algorithm on the usual bi-gram data (e the word immediately preceding the direct object as predictor variable X  The resulting data is certainly very noisy, but, as opposed to more accurate data obtained from a sophisticated parser, it would be feasible to use this method in a speech recogniser In other words, the data contains pairs like (is, chairman which would usually not be considered as a verb-direct object pair It is possible, that more accurate data (e fewer, but only correct pairs) would lead to a different result But the problem with fewer pairs would of course be that the model can be used in fewer cases, thus reducing the usefulness to a language model that would predict the entire text (rather than just the direct objects  Nevertheless, the interpolation results also show that this linguistically derived predictor is useful as a complement to a standard class based bigram model In the future, we hope to consolidate these early findings by more experiments involving a higher number of clusters and a larger data set The automaton then outputs a sequence of verb-object pairs, which constitute our training and testing data Entries that would not normally be considered verb-object pairs are marked with  Given this data, the goal of our language model is to predict the direct objects and we will measure the influence the knowledge of the preceding verb has on this prediction in terms of perplexity However, because of sparse training data, it is often difficult to estimate this distribution directly The conditional probability distribution is then calculated as which generally requires less training data  In the following, let denote the values of Xand Y at the i[th] data point and let (G1[i G2[i denote the corresponding classes The only difference is that in , the elements of variables X and Y are identical (the data consists of bigrams thus requiring only one clustering function G What is a suitable function F, also called optimisation criterion? Given a classification function G, we can estimate the probabilities pG(yl|xk) of equation using the maximum likelihood estimator, e relative frequencies: where gx=G1(xk gy=G2(yl) and N(x) denotes the number of times x occurs in the data Given these probability estimates pG(yl|xk the likelihood FMLof the training data, e the probability of the training data being generated by our probability estimates pG(yl|xk measures how well the training data is represented by the estimates and can be used as optimisation criterion (  In the following, we will derive an optimisation function FML in terms of frequency counts observed in the training data The likelihood of the training data FML is simply Assuming that the classification is unique, e However, the problem with this maximum likelihood criterion is that we first estimate the probabilities pG(yl|xk) on the training data T and then, given pG(yl|xk we evaluate the classification G on T We begin by presenting in section the process we use to obtain training and testing data from unrestricted English text In other words, both the classification G and the estimator pG(yl|xk) are trained on the same data The basic principle of cross-validation is to split the training data T into a retained part TR and a held-out part TH We can then use TR to estimate the probabilities pG(yl|xk) for a given classification G, and TH to evaluate how well the classification G performs It divides the data into N-1 samples as retained part and only one sample as held-out part The advantage of this approach is that all samples are used in the retained and in the held-out part, thus making very efficient use of the existing data In other words, our held-out part TH to evaluate a classification G is the entire set of data points; but when we calculate the probability of the i[th] data point, we assume that our probability distribution pG(yl|xk) was estimated on all the data expect point i The data constitutes the input to a clustering algorithm and a language model, both of which are described in section  Let Ti denote the data without the pair (X[i Y[i and pG,Ti(yl|xk) the probability estimates based on a given classification G and training corpus Ti Given a particular Ti, the probability of the held-out part (X[i Y[i is pG,Ti(yl|xk  The probability of the complete corpus, where each pair is in turn considered the held-out part is the leaving-one-out likelihood LLO In the following, we will derive an optimisation function FLO by specifying how pG,Ti(Y[i X[i is estimated from frequency counts Let n0,Ti be the number of unseen pairs (gx, gy) and n Tithe number of seen pairs (gx, gy leading to the following smoothed estimate Ideally, we would make b depend on the classification, e75 during clustering the number of pairs that will be unseen when used as held-out part  Taking the logarithm, we obtain the final optimisation criterion F LO Given the F LO maximization criterion, we use the algorithm in Figure to find a good clustering function G Furthermore, since the clustering of one word affects the future clustering of other words, the order in which words are moved is important Thus, the assumption we made earlier, when we decided to estimate cluster uni-grams by frequency counts, can be guaranteed