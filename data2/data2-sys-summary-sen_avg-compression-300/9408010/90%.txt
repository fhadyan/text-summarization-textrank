 The data contains about 19,000different direct object tokens, about 10,000 different verb tokens and about 140,000 different token pairs We use of the data as training and the rest as testing data In other words, the data contains pairs like (is, chairman which would usually not be considered as a verb-direct object pair It is possible, that more accurate data (e fewer, but only correct pairs) would lead to a different result The automaton then outputs a sequence of verb-object pairs, which constitute our training and testing data However, because of sparse training data, it is often difficult to estimate this distribution directly The conditional probability distribution is then calculated as which generally requires less training data  Given these probability estimates pG(yl|xk the likelihood FMLof the training data, e the probability of the training data being generated by our probability estimates pG(yl|xk measures how well the training data is represented by the estimates and can be used as optimisation criterion (  In the following, we will derive an optimisation function FML in terms of frequency counts observed in the training data The likelihood of the training data FML is simply Assuming that the classification is unique, e We begin by presenting in section the process we use to obtain training and testing data from unrestricted English text It divides the data into N-1 samples as retained part and only one sample as held-out part In other words, our held-out part TH to evaluate a classification G is the entire set of data points; but when we calculate the probability of the i[th] data point, we assume that our probability distribution pG(yl|xk) was estimated on all the data expect point i Let Ti denote the data without the pair (X[i Y[i and pG,Ti(yl|xk) the probability estimates based on a given classification G and training corpus Ti75 during clustering the number of pairs that will be unseen when used as held-out part 