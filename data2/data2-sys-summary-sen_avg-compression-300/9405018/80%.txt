 In a lazy learning approach, on the other hand, knowledge acquisition is automatic In constructive induction, completely new feature dimensions may be introduced for separating the different category areas better in feature space Lazy Learning is fundamentally a classification paradigmg shift and different types of reduce as categories in a shift-reduce parser (see for such an approach outside the context of Machine Learning  In the lazy learning approach ( ; we used the windowing approach referred to earlier to formulate the task as a classification problem (more specifically, a segmentation problem  The lazy learning approach produced results which were more accurate than both a connectionist approach (backpropagation learning in a recurrent multi-layer perceptron) and a knowledge-based approach Again, in the knowledge-based approach, the lexical requirements for such a system are extensive In a typical knowledge-based system solving the problem, morphological analysis (with lexicon phonotactic knowledge, and syllable structure determination modules are designed and implemented In a lazy learning approach ( ; again a windowing approach was used to formulate the task as a classification problem (identification this time: given a set of possible phonemes, determine which phoneme should be used to translate a target spelling symbol taking into account its context  Results were highly similar to the syllable boundary prediction task: the lazy learning approach resulted in systems which were more accurate than both a connectionist approach and a linguistically motivated approach Another task we applied the lazy learning algorithm to, was stress assignment in Dutch monomorphematic, polysyllabic words ( ,  There were three categories: final stress, penultimate stress, and antepenultimate stress (an identification problem  For the actual tagging problem, a moving window approach was again used, using patterns of ambiguous categories (a target and a left and right context  Section 3 introduces lazy learning, the symbolic machine learning paradigm which we have used in experiments in lexical acquisition Instead of concentrating on linguistic engineering of theory-neutral, poly-theoretic, multi-applicable lexical representations combined with semi-automatic migration of lexical knowledge between different formats, we propose an approach in which a single inductive learning method is reused on different corpora representing useful linguistic mappings, acquiring the necessary lexical information automatically and implicitly These processes implement lexical performance In a broader context, the results described here argue for an empiricist approach to language acquisition, and for exemplars rather than rules in linguistic knowledge representation (see and Gillis et al Also, information gain or other feature weighting techniques can be used to automatically reduce the dimensionality of the problem, sometimes effectively solving the sparse data problem Section 5 gives an overview of research results in applying lazy learning to the acquisition of lexical knowledge, and Section 6 concludes with a discussion of advantages and limitations of the approach A possible solution for this problem is the cascading of different lazy learning systems, one working on the output of the other For example, a learning system for part of speech tagging could be combined with a learning system taking patterns of disambiguated tags as input, and producing constituent types as output Taking patterns of constituent types as input, a third learning system should have no problem assigning long-distance dependencies: given the right representation, all dependencies are local One of the central intuitions in current knowledge-based NLP research is that in solving a linguistic task (like text-to-speech conversion, parsing, or translation the more linguistic knowledge is explicitly modeled in terms of rules and knowledge bases, the better the performance Current lexical research in language technology is eminently knowledge-based in this respect As far as lexical knowledge is concerned, this knowledge is represented in a lexical knowledge base, introduced either by hand or semi-automatically using machine-readable dictionaries The problem of reusability is dealt with by imposing standards on the representation of the knowledge, or by applying filters or translators to the lexical knowledge In this approach, emphasis shifts from knowledge representation (competence) to induction of systems exposing useful behaviour (performance and from knowledge engineering to the simpler process of data collection It is useful in Machine Learning to make a distinction between a learning component and a performance component The learning component implements a learning method There are several ways in which domain bias (a priori knowledge about the task to be learned) can be used to optimize learning Other evaluation criteria include learning and performance speed, memory requirements, clarity of learned representations, etc Recently, there has been an increased interest in Machine Learning for lazy learning methods In this type of similarity-based learning, classifiers keep in memory (a selection of) examples without creating abstractions in the form of rules or decision trees (hence lazy learning  Different tasks require different lexical information Examples are represented as a vector of feature values with an associated category label Also, different theoretical formalisms, domains, and languages require different types of lexical information and therefore possibly also different types of lexical knowledge representation and different acquisition methods In lazy learning, performance crucially depends on the distance metric used Elsewhere ( ; ) we introduced the concept of information gain (also used in decision tree learning, ) into lazy learning to weigh the importance of different features in a domain-independent way Linguistic tasks (including lexical tasks) are context-sensitive mappings from one representation to another (e To illustrate the difference between the traditional knowledge-based approach with the lazy learning approach, consider Fig