 Word vectors reflecting word meanings are expected to enable numerical approaches to semantics For the word sense disambiguation based on the context similarity, co-occurrence vectors from the 1987 Wall Street Journal (20M total words) was advantageous over distance vectors from the Collins English Dictionary ( head words + definition words  For learning or meanings from example words, distance vectors gave remarkably higher precision than co-occurrence vectors ) is used to measure the distance between words The word dictionary is thus linked to the words book, word, language, and alphabetical The words in Fig using co-occurrence statistics We used the same set of origin words as for the distance vectors Co-occurrence Vector With WSD, the precision by using co-occurrence vectors from a 20M words corpus was higher than by using distance vectors from the CED The results using distance vectors are shown by dots ( and using co-occurrence vectors from the 1987 WSJ (20M words) by circles (  A context size (x-axis) of, for example, 10 means 10 words before the target word and 10 words after the target word Corpus size (for co-occurrence vectors) Figure shows the change in disambiguation precision as the corpus size for co-occurrence statistics increases from 200 words to 20M words